{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion\n",
    "### Using FastText Word Embedding\n",
    "Based on this paper: https://arxiv.org/pdf/1606.07608.pdf\n",
    "\n",
    "Pre-made vector models: https://fasttext.cc/docs/en/aligned-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:16.676369Z",
     "start_time": "2019-06-12T13:31:15.880009Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from itertools import islice\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "\n",
    "# import natural language toolkit\n",
    "from nltk.corpus   import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:16.676369Z",
     "start_time": "2019-06-12T13:31:15.880009Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare stopword list\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'document_embeddings.ipynb',\n",
       " 'enviroLENS-deliverable-D4.2-images.ipynb',\n",
       " 'query-expansion.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T07:16:14.874574Z",
     "start_time": "2019-06-12T07:06:52.184229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\sarab\\AppData\\Local\\conda\\conda\\envs\\EnviroLens\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english words 2519370\n"
     ]
    }
   ],
   "source": [
    "wiki_en_align = '../../data/fasttext/wiki.en.align.vec'\n",
    "# get fasttext wiki embeddings for english\n",
    "wv_wiki_en = KeyedVectors.load_word2vec_format(wiki_en_align)\n",
    "print('english words {}'.format(len(list(wv_wiki_en.vocab.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-retrieval kNN Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:17.961109Z",
     "start_time": "2019-06-12T13:31:17.954389Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of terms\n",
    "def tokenize(text, stopwords):\n",
    "    \"\"\"Tokenizes and removes stopwords from the document\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered = [w.lower() for w in tokens if not w in stopwords]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extended list of terms ###\n",
    "def extend_tokens(token_list, wv):\n",
    "    \"\"\"Extends token list summing vector pairs\"\"\"\n",
    "    tokens = []\n",
    "    for token in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "        if token in wv.vocab.keys():\n",
    "            tokens.append(token)\n",
    "    extention = set()\n",
    "    for i in range(len(tokens)-1):\n",
    "        new_token = wv_wiki_en.most_similar(positive=[tokens[i], tokens[i+1]])[0][0]\n",
    "        extention.add(new_token)\n",
    "    extention = list(extention)\n",
    "    return extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n"
     ]
    }
   ],
   "source": [
    "test = tokenize('water pollution underground', stop_words)\n",
    "print(test)\n",
    "ext = extend_tokens(test,wv_wiki_en)\n",
    "print(ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n"
     ]
    }
   ],
   "source": [
    "test1 = tokenize('annex fishing agreement europe', stop_words)\n",
    "print(test1)\n",
    "ext1 = extend_tokens(test1,wv_wiki_en)\n",
    "print(ext1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:18.473214Z",
     "start_time": "2019-06-12T13:31:18.465157Z"
    }
   },
   "outputs": [],
   "source": [
    "# knn nearest\n",
    "def get_candidate_expansion_terms(tokens, k, wv):\n",
    "    \"\"\"Gets the candidate expansion terms\"\"\"\n",
    "    candidates = set()\n",
    "    for token in tokens:\n",
    "        # check if the token is in the vocabulary\n",
    "        if token in wv.vocab.keys():\n",
    "            result = wv.similar_by_word(token)\n",
    "            limit = k if len(result) > k else len(result)\n",
    "            # iterate through the most similar words\n",
    "            for i in range(limit):\n",
    "                candidates.add(result[i][0])\n",
    "    # return list of candidates\n",
    "    candidates = list(candidates)\n",
    "    return candidates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:20.226899Z",
     "start_time": "2019-06-12T13:31:19.569959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potable', 'water—', 'undergrounded', 'undergrounder', 'undergrounders', 'sewage', 'undergrounds', 'biopollution', 'seawater', 'groundwater', 'pollution', 'earpollution', 'undergroun', '#pollution', 'undergrounding', 'pollutants', 'pollution,', 'undergroung', 'pollutions']\n",
      "['groundwater', 'sewage', 'biopollution', 'undergrounds', 'potable', 'undergrounding', 'water—', 'pollutions', 'earpollution', 'undergrounded', 'undergroun', 'pollution,', 'undergroung', 'seawater', '#pollution']\n"
     ]
    }
   ],
   "source": [
    "candidates = get_candidate_expansion_terms(test+ext, 5, wv_wiki_en)\n",
    "print(candidates)\n",
    "witout = get_candidate_expansion_terms(test, 5, wv_wiki_en)\n",
    "print(witout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between word and list of words\n",
    "def similarity(token, token_list, wv ):\n",
    "    \"\"\"calculates the similarity between word and list of words\"\"\"\n",
    "    # calculate the similarity of the token to all tokens\n",
    "    similarity = 0\n",
    "    num_of_tokens = 0\n",
    "    for toks in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "        if toks in wv.vocab.keys():\n",
    "            num_of_tokens += 1\n",
    "            similarity += wv.similarity(toks, token)\n",
    "    return similarity/num_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:13.725242Z",
     "start_time": "2019-06-12T13:33:13.716880Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculates similarity and sorts\n",
    "def get_top_expansion_terms(tokens, candidates, wv):\n",
    "    \"\"\"Gets the actual expansion terms\"\"\"\n",
    "    similarity_pairs = []\n",
    "    for candidate in candidates:\n",
    "        sim = similarity(candidate, tokens, wv)\n",
    "        similarity_pairs.append((candidate, sim))\n",
    "    # return the list of expansion terms with their similarities\n",
    "    return similarity_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:14.317627Z",
     "start_time": "2019-06-12T13:33:14.308832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pollution', 0.6260276407951794), ('pollutions', 0.5989783010567384), ('undergrounding', 0.5868486694404182), ('earpollution', 0.5791309410113681), ('pollution,', 0.5584437076938438), ('pollutants', 0.5473505877035749), ('groundwater', 0.5472185974670384), ('sewage', 0.5438533174483885), ('undergrounds', 0.5373294534380542), ('#pollution', 0.5307803259871704), ('biopollution', 0.5239432296935493), ('undergrounded', 0.5166503920961191), ('undergrounders', 0.5048834686641379), ('undergroun', 0.4968187167322256), ('undergrounder', 0.4930006599112927), ('undergroung', 0.48966882540846307), ('seawater', 0.48062588166948944), ('potable', 0.47213486261999227), ('water—', 0.43395093386930084)]\n",
      "[('pollution', 0.6073097696558457), ('groundwater', 0.5722256140853779), ('sewage', 0.5672777675468184), ('earpollution', 0.5479508482970044), ('pollutions', 0.5392823009654661), ('pollution,', 0.5361565112564385), ('pollutants', 0.5332377192240293), ('seawater', 0.5219145986771884), ('undergrounding', 0.5190662482715993), ('potable', 0.5137930541544308), ('#pollution', 0.5053773015402238), ('biopollution', 0.504703593451706), ('undergrounds', 0.4843079595214148), ('water—', 0.47646895745070106), ('undergrounded', 0.46550011202029024), ('undergrounders', 0.4524525797301971), ('undergroun', 0.4511787727249055), ('undergroung', 0.44847479246473937), ('undergrounder', 0.44571173169707395)]\n"
     ]
    }
   ],
   "source": [
    "# get actual expansion terms for test set; with and without extension\n",
    "top = get_top_expansion_terms(test+ext, candidates,  wv_wiki_en)\n",
    "topwithout = get_top_expansion_terms(test, candidates,  wv_wiki_en)\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "top = sorted(top, key=takeSecond)[::-1]\n",
    "topw = sorted(topwithout, key=takeSecond)[::-1]\n",
    "print((top))\n",
    "print((topw))\n",
    "top = top[0:5]\n",
    "topw = topw[0:5]\n",
    "top_list = []\n",
    "for tupl in top:\n",
    "    top_list.append(tupl[0])\n",
    "topw_list = []\n",
    "for tupl in topw:\n",
    "    topw_list.append(tupl[0])\n",
    "\n",
    "# get actual expansion terms for test1 set; with and without extension\n",
    "top1 = get_top_expansion_terms(test1+ext1, candidates,  wv_wiki_en)\n",
    "topwithout1 = get_top_expansion_terms(test1, candidates,  wv_wiki_en)\n",
    "\n",
    "top1 = sorted(top1, key=takeSecond)[::-1]\n",
    "topw1 = sorted(topwithout1, key=takeSecond)[::-1]\n",
    "top1 = top1[0:5]\n",
    "topw1 = topw1[0:5]\n",
    "top_list1 = []\n",
    "for tupl in top1:\n",
    "    top_list1.append(tupl[0])\n",
    "topw_list1 = []\n",
    "for tupl in topw1:\n",
    "    topw_list1.append(tupl[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:17.453260Z",
     "start_time": "2019-06-12T13:33:17.445772Z"
    }
   },
   "outputs": [],
   "source": [
    "# all functions together, finds k nearest for each term, returns top n\n",
    "def pre_retrieval_KNN(string, k, wv, n):\n",
    "    \"\"\"Find the most similar tokens to the given query\"\"\"\n",
    "    tokens = tokenize(string, stop_words)\n",
    "    candidates = get_candidate_expansion_terms(tokens, k, wv)\n",
    "    candidates_sim = get_top_expansion_terms(tokens, candidates, wv)\n",
    "    def takeSecond(elem):\n",
    "        return elem[1]\n",
    "    sort = sorted(candidates_sim, key=takeSecond)[::-1]\n",
    "    return sort[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:18.114793Z",
     "start_time": "2019-06-12T13:33:17.927772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('learning,', 0.5336429871558637),\n",
       " ('learnings', 0.5210396371333685),\n",
       " ('relearning', 0.509084270159704),\n",
       " ('#learning', 0.507341799782255),\n",
       " ('learning—in', 0.5062408798333075),\n",
       " ('deeper', 0.49509854997328506),\n",
       " ('deepest', 0.42268526313403443),\n",
       " ('deeps', 0.4007843076134384),\n",
       " ('depths', 0.3836683940147054),\n",
       " ('shallow', 0.3727379655276737)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_retrieval_KNN('deep learning', 5, wv_wiki_en, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import postgresql\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.library.postgresql import PostgresQL\n",
    "# connect to the postgresql database\n",
    "pg = PostgresQL() \n",
    "pg.connect(database=\"eurlex_env_only\", user=\"postgres\", password=\"solata.2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import documents \n",
    "documents = pg.execute(\"\"\"\n",
    "    SELECT * FROM documents;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_id': 96,\n",
       " 'document_celex_num': '21987A0130(03)',\n",
       " 'document_title': 'Agreement between the European Economic Community and the Government of the Republic of Guinea amending the Agreement between the European Economic Community and the Government of the Revolutionary Peoples Republic of Guinea on fishing off the coast of Guinea, signed at Conakry on 7 February 1983 - Protocol establishing the fishing rights and financial compensation for the period 8 August 1986 to 7 August 1989',\n",
       " 'document_author': 'European Economic Community',\n",
       " 'document_form': 'International agreement',\n",
       " 'document_date': datetime.date(1987, 7, 29),\n",
       " 'document_text': '30.1.1987\\xa0\\xa0\\xa0ENOfficial Journal of the European CommunitiesL 29/10AGREEMENTbetween the European Economic Community and the Government of the Republic of Guinea amending the Agreement between the European Economic Community and the Government of the Revolutionary Peoples Republic of Guinea on fishing off the coast of Guinea, signed at Conakry on 7 February 1983Article 1The Agreement between the European Economic Community and the Government of the Republic of Guinea on fishing off the coast of Guinea, signed on 7 February 1983, shall be amended as follows:(1)In the title and text of the Agreement the term ‘Revolutionary Peoples Republic of Guinea’ shall be replaced by ‘Republic of Guinea’;(2)(This amendment is not relevant to the English text);(3)Article 8 (3) shall be replaced by the following:‘The financial compensation shall be used solely to finance projects and services relating to fishing’;(4)Annex I, referred to in Articles 2 and 5 of the Agreement, and Annexes to it, shall be replaced by the text annexed hereto;(5)The Protocol referred to in Article 8 of the Agreement shall be replaced by the text annexed hereto.Article 21.\\xa0\\xa0\\xa0This Agreement, drawn up in duplicate in the Danish, German, Greek, English, French, Italian, Dutch, Portuguese and Spanish languages, each of these texts being equally authentic, shall enter into force on the date of signature.2.\\xa0\\xa0\\xa0It shall apply from 8 August 1986.ANNEXCONDITIONS FOR THE PURSUIT OF FISHING ACTIVITIES IN GUINEAS FISHING ZONE BY COMMUNITY VESSELSA.\\xa0\\xa0\\xa0Licence application and issuing formalitiesThe procedure for applications for, and issue of, the licences enabling Community vessels to fish in Guineas fishing zone shall be as follows:The relevant Community authorities shall present to the Office of the Secretary of State for Fisheries of the Republic of Guinea, via the Delegation of the Commission in Guinea, an application for each vessel that wishes to fish under this Agreement, at least 10 days before the date of commencement of the period of validity requested.The applications shall be made on the forms provided for that purpose by the Government of the Republic of Guinea, a specimen of which is annexed hereto.Each licence application shall be accompanied by proof of payment for the period of the licences validity.Licences must be held on board at all times.I.\\xa0\\xa0\\xa0Provisions applicable to trawlers1.Before receiving a licence, each vessel must be presented at the port of Conakry for inspection in accordance with the rules and regulations in force. Should the licence be renewed in the same calendar year, vessels shall be exempt from inspection.2.Each vessel must be represented by a factor approved by the Office of the Secretary of State for Fisheries.3.The licence fees shall be equivalent to the following annual amounts:—110 ECU/grt for fin fish trawlers, or 250 kg/grt of fish landed at a Guinean port,—130 ECU/grt for cephalopod vessels,—133 ECU/grt for shrimp trawlers and trawlers taking mixed catches including over 30 % of shrimps by weight.These fees shall be paid in the currency indicated by the Guinean authorities and fixed on a pro rata basis relating to the period of validity of the licence.The chosen fee is indicated by the shipowner when introducing the licence application.Deliveries of fish shall be made according to a programme established when the licences are issued, at least every other month, each delivery being declared to the Guinean authorities at least five days in advance.II.\\xa0\\xa0\\xa0Provisions applicable to tuna vessels and longliners1.The fees shall be set at 20 ECU per tonne caught within Guineas fishing zone.2.Applications for licences for tuna vessels and longliners shall be issued following payment to the Office of the Secretary of State for Fisheries of a lump sum of 1\\xa0000 ECU a year for each tuna seiner, 200 ECU a year for each pole-and-line tuna vessel and 200 ECU a year for each longliner, equivalent to the fees for:—50 tonnes of tuna caught per year in the case of seiners,—10 tonnes of tuna caught per year in the case of pole-and-line vessels,—10 tonnes of swordfish caught per year in the case of longliners.A provisional statement of the fees due for the fishing year shall be drawn up by the Commission of the European Communities at the end of each calendar year on the basis of the catch statements made by the shipowners and forwarded simultaneously to the Guinean authorities and the Commission departments responsible. The corresponding amount shall be paid by the shipowners to the Office of the Secretary of State for Fisheries no later than 31 March of the following year.The final statement of the fees due shall be drawn up by the Commission following verification of the volume of catch by a specialist scientific body in the region. The final statement shall be communicated to the Guinean authorities and notified to the shipowners, who shall have 30 days to discharge their financial obligations.However, if the amount of the final statement is lower than the abovementioned advance, the resulting balance shall not be reimbursable.B.\\xa0\\xa0\\xa0Statement of catchAll vessels authorized to fish in Guineas waters under the Agreement shall be obliged to forward to the Office of the Secretary of State for Fisheries, via the Commission delegation at Conakry, a statement of their catch made out according to the specimen in Annex II to the Agreement.These statements of catch must be drawn up for each month and presented at least once every quarter.C.\\xa0\\xa0\\xa0Signing-on of seamenShipowners who have been issued fishing licences under the Agreement shall contribute to the on-the-job vocational training of Guinean nationals subject to the conditions and limits set out below:1.Each trawler owner shall undertake to employ:—two fishermen, including one fisherman/observer, on vessels of up to 300 grt and on all cephalopod vessels,—a number, including one observer/fisherman, equivalent to 25 % of the fishermen on board vessels of more than 300 grt.2.Six Guinean seamen shall be signed on permanently for the fleet of tuna seiners.In the case of the pole-and-line tuna vessels, eight Guinean seamen shall be signed on for the tuna fishing season in Guinean waters. There may not, however, be more than one Guinean seaman per vessel.These obligations may instead take the form of an annual lump sum equivalent to the seamens wages; this sum will be used for the training of Guinean fishermen.3.The seamens wages, set in accordance with Guinean scales, and other forms of remuneration shall be borne by the shipowners.D.\\xa0\\xa0\\xa0Fishing zonesThe fishing zones accessible to Community vessels shall comprise all waters under Guinea jurisdiction beyond:(1)Three nautical miles as regards shrimp vessels not exceeding 135 grt;(2)Six nautical miles as regards shrimp vessels of between 135 and 300 grt;(3)Six nautical miles as regards cephalopod vessels during the first years application of the current Protocol.At the end of this period specific provisions on access for cephalopod vessels may be adopted by the Joint Committee;(4)12 nautical miles as regards shrimp vessels exceeding 300 grt;(5)15 nautical miles as regards fin fish trawlers.E.\\xa0\\xa0\\xa0Meshes authorized1.The mesh authorized for the trawl body (mesh fully extended) shall be:(a)60 mm for fin fish vessels;(b)40 mm for cephalopod vessels;(c)25 mm for shrimp vessels.2.These mesh sizes apply under Guinean regulations to all ships flying the Guinean or any other flag and may be changed in the light of recommendations formulated by international scientific organizations.F.\\xa0\\xa0\\xa0Inspection and monitoring of fishing activitiesAny Community vessel fishing in Guineas fishing zone shall allow on board, and assist in the accomplishment of his duties, any official of Guinea responsible for inspection and monitoring.G.\\xa0\\xa0\\xa0PenaltiesInfringements shall be penalized as follows:(1)payment of a fine of 500\\xa0000 to 1\\xa0500\\xa0000 Guinean francs, payable in ECU, for non-compliance with mesh size or fishing zones;(2)non-renewal of fishing licence for failure to supply statements of catch;(3)payment of a fine of 1\\xa0000 ECU per tonne of fish not landed.Specimen provided for in A I\\xa0(1)(1)\\xa0\\xa0The application must be submitted on a form in French.PROTOCOLestablishing fishing rights and financial compensation for the period from 8 August 1986 to 7 August 1989Article 1From 8 August 1986, for a period of three years, the fishing authorizations granted pursuant to Article 2 of the Agreement shall be as follows:1.Trawlers — 12\\xa0000 (twelve thousand) grt per month, annual average;2.Freezer tuna seiners — 45 vessels;3.Wet pole-and-line tuna vessels — 25 vessels;4.Longliners — six vessels.Article 21.\\xa0\\xa0\\xa0The financial compensation referred to in Article 8 of the Agreement shall be, for the period referred to in Article 1, 8\\xa0600\\xa0000 (eight million six hundred thousand) ECU, payable in three annual instalments.2.\\xa0\\xa0\\xa0The use to which this compensation is put shall be the sole responsibility ot the Government of the Republic of Guinea.3.\\xa0\\xa0\\xa0The compensation shall be paid into an account opened at a financial institution or any other body designated by the Government of the Republic of Guinea.Article 3At the request of the Community, the fishing rights referred to in Article 1 (1) may be increased by successive instalments of 1\\xa0000 grt a month on annual average. In this case, the financial compensation referred to in Article 2 shall be increased proportionately pro rata temporis.Article 41.\\xa0\\xa0\\xa0The Community shall also contribute during the period referred to in Article 1 up to 350\\xa0000 (three hundred and fifty thousand) ECU towards the financing of Guinean scientific and technical programmes (equipment, infrastructure, etc.) to improve information on the fishery resources within the exclusive economic zone of Guinea.2.\\xa0\\xa0\\xa0The competent Guinean authorities shall send to the Commission a report on the utilization of the funds.3.\\xa0\\xa0\\xa0The Communitys contribution to the scientific and technical programmes shall be paid on each occasion into an account specified by the Office of the Secretary of State for Fisheries.Article 5The Community shall make it easier for nationals of Guinea to find places in establishments in its Member States or in the ACP States and shall provide for that purpose, during the period referred to Article 1,11 (eleven) three-year study and training grants in the various scientific, technical and economic subjects connected with fisheries.Two of these three-year grants, equivalent to a sum of no more than 55\\xa0000 (fifty-five thousand) ECU may be used to finance study trips and cover the expenses of participation by officials of the Office of the Secretary of State for Fisheries in conferences and seminars held in the Member States and the ACP States.Article 6Should the Community fail to make the payments provided for in this Protocol, the Agreement on fishing may be suspended.Top'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = documents\n",
    "# some docs are empty !!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# for doc in docs:\n",
    "#     idd= doc.get('document_id')\n",
    "#     if idd == 39722:\n",
    "#         print(doc)\n",
    "\n",
    "delete = []\n",
    "for doc in docs:\n",
    "    n = len(doc.get('document_text'))\n",
    "    if n == 0:\n",
    "        id_doc = doc.get('document_id')\n",
    "        delete.append(id_doc)\n",
    "            \n",
    "# remove empty docs\n",
    "for doc in docs:\n",
    "    id_doc = doc.get('document_id')\n",
    "    if id_doc in delete:\n",
    "        docs.remove(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99369\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tokenzized documents (texts), texts, tokenzized titles and titles\n",
    "tokenized_docs = {}\n",
    "tokenized_titles = {}\n",
    "texts = {}\n",
    "titles = {}\n",
    "for document in docs:\n",
    "    doc_id = document.get('document_id')\n",
    "    text = document.get('document_text')\n",
    "    texts.update({doc_id: text})\n",
    "    title = document.get('document_title')\n",
    "    titles.update({doc_id: title})\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized = tokenize(text, stop_words)\n",
    "    title = title.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized_title = tokenize(title, stop_words)\n",
    "    for token in tokenized:\n",
    "        if len(token) == 1:\n",
    "            if token.isalpha():\n",
    "                tokenized.remove(token)\n",
    "    tokenized_docs.update({doc_id: tokenized})\n",
    "    for title in tokenized_title:\n",
    "        if len(title) == 1:\n",
    "            if title.isalpha():\n",
    "                tokenized_title.remove(title)\n",
    "    tokenized_titles.update({doc_id: tokenized_title})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agreement', 'relating', 'principally', 'chemicals', 'supplementary', 'geneva', '1967', 'protocol', 'general', 'agreement', 'tariffs', 'trade', 'negotiated', 'geneva', '30', 'june', '1967']\n",
      "/* Agreement relating principally to chemicals, supplementary to the Geneva (1967) Protocol to the General Agreement on Tariffs and Trade, negotiated in Geneva on 30 June 1967 */\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenized_titles.get(3))\n",
    "print(titles.get(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_docs.get(39703))\n",
    "print(texts.get(39703))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99369\n",
      "23108\n"
     ]
    }
   ],
   "source": [
    "# still some empty documents\n",
    "print(len(tokenized_docs))\n",
    "#print(take(1, tokenized_docs.items()))\n",
    "empt=[]\n",
    "for k,v in tokenized_docs.items():\n",
    "    l =len(v)\n",
    "    if l==0:\n",
    "        empt.append(k)\n",
    "print(len(empt))\n",
    "#print((empt))\n",
    "\n",
    "for k in empt:\n",
    "    del tokenized_docs[k]\n",
    "    del tokenized_titles[k]\n",
    "    del texts[k]\n",
    "    del titles[k]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76261\n",
      "76261\n",
      "76261\n",
      "76261\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_docs))\n",
    "print(len(tokenized_titles))\n",
    "print(len(texts))\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just making smaller document set for faster testing, can delete later\n",
    "tokenized_docs1 = {}\n",
    "tokenized_titles1 = {}\n",
    "texts1= {}\n",
    "titles1={}\n",
    "for k in range(1,1000):\n",
    "    vtd = tokenized_docs.get(k)\n",
    "    vtt = tokenized_titles.get(k)\n",
    "    vx = texts.get(k)\n",
    "    vt =titles.get(k)\n",
    "    tokenized_docs1.update({k:vtd})\n",
    "    tokenized_titles1.update({k:vtt})\n",
    "    texts1.update({k:vx})\n",
    "    titles1.update({k:vt})\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "999\n",
      "999\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_docs1))\n",
    "print(len(tokenized_titles1))\n",
    "print(len(texts1))\n",
    "print(len(titles1))\n",
    "tokenized_docs1 = {k:v for k,v in tokenized_docs1.items() if v is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### search full words (not lemmatized), search as substrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. probability scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability scoring\n",
    "### all query words have to be in the document (multiplying)\n",
    "\n",
    "def probab_score(tokens,tokenized_docs,texts):\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 1\n",
    "        text = texts.get(k)\n",
    "        for token in tokens:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability*(token_frequency/n)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(120739, 2.2778939503692463e-06), (90952, 1.4623827626019007e-06), (98346, 9.60986510312026e-07), (100875, 9.116079910329329e-07), (96934, 7.795624765214125e-07), (98891, 4.7381201508301593e-07), (99214, 4.374815382790846e-07), (53800, 2.5508770567849454e-07), (101429, 2.4695734439852766e-07), (101872, 2.433802400069899e-07)]\n",
      "[]\n",
      "[(72, 4.866706628529354e-11), (4098, 3.9980157168428714e-11), (31030, 1.0620609744608273e-11), (85, 6.56566844179315e-12), (47616, 4.413577090077561e-12), (59689, 3.662677012225006e-12), (2146, 2.529433698703274e-12), (25303, 2.2094496103487563e-12), (57414, 2.1926876323265894e-12), (31131, 1.3631354904463345e-12)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# only original query\n",
    "score =probab_score(test,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "print(sorted_positives_top)\n",
    "\n",
    "# original query + extension\n",
    "score =probab_score(test+ext,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "print(([(k,v) for k,v in score.items() if v > 0]))\n",
    "\n",
    "\n",
    "# only original query\n",
    "score =probab_score(test1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "print(sorted_positives_top)\n",
    "\n",
    "# original query + extension\n",
    "score =probab_score(test1+ext1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "print(([(k,v) for k,v in score.items() if v > 0]))\n",
    "\n",
    "\n",
    "# no point having an extention, empty results are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titles.get(80))\n",
    "# print(texts.get(80))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## query words summation\n",
    "def probab_score_sum(tokens,tokenized_docs,texts):\n",
    "    '''assigns score to document based on summation of probabilities'''\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        text = texts.get(k)\n",
    "        for token in tokens:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability+(token_frequency/n)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zavedaj se:\n",
    "\"gabla is bla2\".count(\"bla\")\n",
    "# kar pomeni da bi bilo bolje uporabiti lemmatized words! popravi!! neke stvari zdaj 2x stejes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_positives(dictionary,n):\n",
    "    \"\"\"Takes dict and returns first n tuples of k,v sorted by v\"\"\"\n",
    "    positives = {} \n",
    "    for k,v in dictionary.items():\n",
    "        if v > 0:\n",
    "            positives.update({k: v})\n",
    "    sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "    sorted_positives_top = sorted_positives[0:n]\n",
    "    return sorted_positives_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n"
     ]
    }
   ],
   "source": [
    "# only original query\n",
    "score_sum =probab_score_sum(test,tokenized_docs,texts)\n",
    "\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>0.116567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>0.111821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>0.106627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>0.105425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30565</td>\n",
       "      <td>0.103206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36068</td>\n",
       "      <td>0.103186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3867</td>\n",
       "      <td>0.102941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94467</td>\n",
       "      <td>0.098425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38921</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original     score\n",
       "0            32476  0.116567\n",
       "1            33546  0.111821\n",
       "2            37122  0.106627\n",
       "3            34869  0.105425\n",
       "4            30565  0.103206\n",
       "5            36068  0.103186\n",
       "6             3867  0.102941\n",
       "7            95196  0.099099\n",
       "8            94467  0.098425\n",
       "9            38921  0.097561"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df_sum_original = pd.DataFrame(sorted_positives_top, columns =['id_sum_original', 'score'])\n",
    "df_sum_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titles.get(565))\n",
    "# print(texts.get(565))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n"
     ]
    }
   ],
   "source": [
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test+ext,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df_sum_original_ext = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(72, 4.866706628529354e-11), (4098, 3.9980157168428714e-11), (31030, 1.0620609744608273e-11), (85, 6.56566844179315e-12), (47616, 4.413577090077561e-12), (59689, 3.662677012225006e-12), (2146, 2.529433698703274e-12), (25303, 2.2094496103487563e-12), (57414, 2.1926876323265894e-12), (31131, 1.3631354904463345e-12)]\n",
      "[(94870, 0.1276595744680851), (11790, 0.09090909090909091), (100258, 0.08527131782945736), (97436, 0.08280254777070063), (28599, 0.08163833937029813), (92702, 0.07514450867052024), (97265, 0.07430340557275542), (50112, 0.07235621521335807), (62459, 0.07103825136612021), (49539, 0.07056113902847572)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>0.085271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>0.082803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>0.081638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>0.075145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>0.074303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>0.072356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>0.071038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>0.070561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original1     score\n",
       "0             94870  0.127660\n",
       "1             11790  0.090909\n",
       "2            100258  0.085271\n",
       "3             97436  0.082803\n",
       "4             28599  0.081638\n",
       "5             92702  0.075145\n",
       "6             97265  0.074303\n",
       "7             50112  0.072356\n",
       "8             62459  0.071038\n",
       "9             49539  0.070561"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only original query\n",
    "score =probab_score(test1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score,10)\n",
    "print(sorted_positives_top)\n",
    "\n",
    "\n",
    "\n",
    "## original query\n",
    "score_sum =probab_score_sum(test1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original1', 'score'])\n",
    "df_sum_original1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original_ext1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92702</td>\n",
       "      <td>0.121387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93604</td>\n",
       "      <td>0.116959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97781</td>\n",
       "      <td>0.114583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93549</td>\n",
       "      <td>0.104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14571</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97436</td>\n",
       "      <td>0.101911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100258</td>\n",
       "      <td>0.100775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44382</td>\n",
       "      <td>0.100151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98394</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original_ext1     score\n",
       "0                 94870  0.127660\n",
       "1                 92702  0.121387\n",
       "2                 93604  0.116959\n",
       "3                 97781  0.114583\n",
       "4                 93549  0.104348\n",
       "5                 14571  0.102041\n",
       "6                 97436  0.101911\n",
       "7                100258  0.100775\n",
       "8                 44382  0.100151\n",
       "9                 98394  0.099099"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test1+ext1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score_sum.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "#dataframe\n",
    "df_sum_original_ext1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext1', 'score'])\n",
    "df_sum_original_ext1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12744, 0.15163934426229508), (92986, 0.1473429951690821), (92988, 0.14669421487603304), (9649, 0.13286713286713286), (93921, 0.11695906432748537), (32476, 0.11656671664167916), (62937, 0.11578947368421053), (94936, 0.11494252873563218), (97319, 0.11363636363636363), (95196, 0.11261261261261261)]\n",
      "[(94936, 0.12643678160919541), (3453, 0.11875000000000001), (32476, 0.11656671664167916), (97319, 0.11363636363636363), (33546, 0.11182108626198083), (95196, 0.10810810810810811), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686)]\n",
      "[(94870, 0.1276595744680851), (11790, 0.09090909090909091), (100258, 0.08527131782945736), (97436, 0.08280254777070063), (28599, 0.08163833937029813), (92702, 0.07514450867052024), (97265, 0.07430340557275542), (50112, 0.07235621521335807), (62459, 0.07103825136612021), (49539, 0.07056113902847572)]\n",
      "[(94870, 0.1276595744680851), (92702, 0.12138728323699421), (93604, 0.11695906432748537), (97781, 0.11458333333333334), (93549, 0.10434782608695653), (14571, 0.10204081632653061), (97436, 0.1019108280254777), (100258, 0.10077519379844961), (44382, 0.10015060240963855), (98394, 0.0990990990990991)]\n"
     ]
    }
   ],
   "source": [
    "# adding candidates\n",
    "## without weights\n",
    "# no point using multiplication\n",
    "\n",
    "# summation:\n",
    "## original query\n",
    "score_sum =probab_score_sum(test+topw_list,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_cand = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_cand', 'score'])\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test+ext+top_list,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_ext_cand = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext_cand', 'score'])\n",
    "\n",
    "\n",
    "## original query\n",
    "score_sum =probab_score_sum(test1+topw_list1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_cand1', 'score'])\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test1+ext1+top_list1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_ext_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext_cand1', 'score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_value(word, alpha, original_tokens, top_expansion, wv):\n",
    "    \"\"\"values word based on whether is in original token set or expanded, if alpha -1 value equals to cosine similarity\"\"\"\n",
    "    only_expanded = []\n",
    "    for token in top_expansion:\n",
    "        if token not in original_tokens:\n",
    "            only_expanded.append(token)\n",
    "            \n",
    "    sum_similarity = 0\n",
    "    for exp_token in only_expanded:\n",
    "            sum_similarity += similarity(exp_token,original_tokens, wv)\n",
    "            \n",
    "    if alpha == -1:\n",
    "        if word in original_tokens:\n",
    "            value = 1\n",
    "        else:\n",
    "            value = similarity(word, original_tokens, wv)/sum_similarity\n",
    "\n",
    "\n",
    "    else:\n",
    "        if word in original_tokens:\n",
    "            value = alpha\n",
    "        else:\n",
    "            value = (1-alpha)*similarity(word, original_tokens, wv)/sum_similarity\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "0.28172557133554\n",
      "0.7\n",
      "0.27141179615367744\n"
     ]
    }
   ],
   "source": [
    "# ce ni ext zraven je so cudni rezultati, zamenja vrstni red pomembnsti med sewage in undergrounding??\n",
    "top = top[0:4]\n",
    "top_words = [i[0] for i in top]\n",
    "print(word_value(\"water\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"sewage\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"undergrounding\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"biopollution\", 0.7, test+ext ,top_words, wv_wiki_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probab_score_sum_weights(original_tokens, top_expansion,tokenized_docs,texts, wv, alpha): \n",
    "    '''As probab_score_sum only weighted; usually extention added to original tokens, candidates = top_expansion - have weights'''\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        text = texts.get(k)\n",
    "        for token in original_tokens+top_expansion:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability+(token_frequency/n)*word_value(token, alpha, original_tokens, top_expansion, wv)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.33091025022915893,\n",
       " 0.31908974977084104]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check word values\n",
    "wvals = []\n",
    "for token in test+ext+top_list:\n",
    "    wvals.append(word_value(token, 0.35, test+ext, top_list, wv_wiki_en))\n",
    "wvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n"
     ]
    }
   ],
   "source": [
    "#check word frequences\n",
    "n = len(tokenized_docs1)\n",
    "print(n)\n",
    "t_freqs = []\n",
    "for k, v in tokenized_docs1.items():\n",
    "    n = len(v)\n",
    "    text = texts1.get(k)\n",
    "    for token in test+ext+top_list:\n",
    "        token_frequency = text.count(token)\n",
    "        t_freqs.append(token_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with weights\n",
    "# summation \n",
    "original_query_cand = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    ## original query\n",
    "    score_sum = probab_score_sum_weights(test, topw_list,tokenized_docs, texts, wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_cand = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_cand.append(df_wsum_original_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original query plus ext\n",
    "original_query_ext_cand = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum =probab_score_sum_weights(test+ext, top_list,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_ext_cand = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_ext_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_ext_cand.append(df_wsum_original_ext_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sorting for each alpha\n",
    "doubleframes =[]\n",
    "for i in range(len(original_query_cand)):\n",
    "    frst = original_query_cand[i].take([0], axis=1)\n",
    "    snd = original_query_ext_cand[i].take([0], axis=1)\n",
    "    con = pd.concat([frst,snd], axis=1)\n",
    "    doubleframes.append(con)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94936</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97319</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92986</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33546</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9649</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37122</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand0.4  id_wsum_original_ext_cand0.4\n",
       "0                     32476                         94936\n",
       "1                     12744                         32476\n",
       "2                     92988                          3453\n",
       "3                     94936                         97319\n",
       "4                     97319                         33546\n",
       "5                     92986                         95196\n",
       "6                     33546                         37122\n",
       "7                     95196                         34869\n",
       "8                      9649                         30565\n",
       "9                     37122                         36068"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleframes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand-1</th>\n",
       "      <th>id_wsum_original_cand0.35</th>\n",
       "      <th>id_wsum_original_cand0.4</th>\n",
       "      <th>id_wsum_original_cand0.45</th>\n",
       "      <th>id_wsum_original_cand0.5</th>\n",
       "      <th>id_wsum_original_cand0.6</th>\n",
       "      <th>id_wsum_original_cand0.7</th>\n",
       "      <th>id_wsum_original_cand0.8</th>\n",
       "      <th>id_wsum_original_cand0.9</th>\n",
       "      <th>id_wsum_original_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "      <td>12744</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "      <td>92988</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33546</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92988</td>\n",
       "      <td>94936</td>\n",
       "      <td>97319</td>\n",
       "      <td>12744</td>\n",
       "      <td>92988</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95196</td>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "      <td>33546</td>\n",
       "      <td>95196</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12744</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>95196</td>\n",
       "      <td>12744</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37122</td>\n",
       "      <td>9649</td>\n",
       "      <td>95196</td>\n",
       "      <td>92986</td>\n",
       "      <td>37122</td>\n",
       "      <td>92988</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "      <td>9649</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "      <td>34869</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92986</td>\n",
       "      <td>93921</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "      <td>92986</td>\n",
       "      <td>12744</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand-1  id_wsum_original_cand0.35  \\\n",
       "0                    32476                      12744   \n",
       "1                    94936                      92988   \n",
       "2                    97319                      92986   \n",
       "3                    33546                      32476   \n",
       "4                    92988                      94936   \n",
       "5                    95196                      97319   \n",
       "6                    12744                      33546   \n",
       "7                    37122                       9649   \n",
       "8                     3453                      95196   \n",
       "9                    92986                      93921   \n",
       "\n",
       "   id_wsum_original_cand0.4  id_wsum_original_cand0.45  \\\n",
       "0                     32476                      32476   \n",
       "1                     12744                      94936   \n",
       "2                     92988                      97319   \n",
       "3                     94936                      92988   \n",
       "4                     97319                      12744   \n",
       "5                     92986                      33546   \n",
       "6                     33546                      95196   \n",
       "7                     95196                      92986   \n",
       "8                      9649                      37122   \n",
       "9                     37122                       3453   \n",
       "\n",
       "   id_wsum_original_cand0.5  id_wsum_original_cand0.6  \\\n",
       "0                     32476                     32476   \n",
       "1                     94936                     94936   \n",
       "2                     97319                     97319   \n",
       "3                     33546                     33546   \n",
       "4                     92988                     95196   \n",
       "5                     95196                     37122   \n",
       "6                     12744                      3453   \n",
       "7                     37122                     92988   \n",
       "8                      3453                     34869   \n",
       "9                     92986                     12744   \n",
       "\n",
       "   id_wsum_original_cand0.7  id_wsum_original_cand0.8  \\\n",
       "0                     32476                     32476   \n",
       "1                     94936                     94936   \n",
       "2                     97319                     97319   \n",
       "3                     33546                     33546   \n",
       "4                     95196                     95196   \n",
       "5                     37122                     37122   \n",
       "6                      3453                      3453   \n",
       "7                     34869                     34869   \n",
       "8                     30565                     30565   \n",
       "9                     36068                     36068   \n",
       "\n",
       "   id_wsum_original_cand0.9  id_wsum_original_cand1  \n",
       "0                     32476                   32476  \n",
       "1                     94936                   94936  \n",
       "2                     97319                   97319  \n",
       "3                     33546                   33546  \n",
       "4                     95196                   95196  \n",
       "5                     37122                   37122  \n",
       "6                      3453                    3453  \n",
       "7                     34869                   34869  \n",
       "8                     30565                   30565  \n",
       "9                     36068                   36068  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_cand)):\n",
    "    dataf = original_query_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "con = pd.concat(frames, axis=1)\n",
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha 1 - 0.5 first 4 docs the same, 0.45 first 3 the same, 0.4 1st the same\n",
    "- alpha -1 same as alpha 0.5\n",
    "- alpha 0.35 even 1st doc different than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 10, 94936: 10, 97319: 10, 33546: 10, 95196: 10, 37122: 9, 3453: 8, 12744: 6, 92988: 6, 92986: 5, 34869: 5, 30565: 4, 36068: 4, 9649: 2, 93921: 1})\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "values = con.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 docs in every column \n",
    "- 11 of 15 different docs appear at least in half of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_ext_cand-1</th>\n",
       "      <th>id_wsum_original_ext_cand0.35</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.45</th>\n",
       "      <th>id_wsum_original_ext_cand0.5</th>\n",
       "      <th>id_wsum_original_ext_cand0.6</th>\n",
       "      <th>id_wsum_original_ext_cand0.7</th>\n",
       "      <th>id_wsum_original_ext_cand0.8</th>\n",
       "      <th>id_wsum_original_ext_cand0.9</th>\n",
       "      <th>id_wsum_original_ext_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32476</td>\n",
       "      <td>3453</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>32476</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3453</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>3453</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_ext_cand-1  id_wsum_original_ext_cand0.35  \\\n",
       "0                        94936                          94936   \n",
       "1                        32476                           3453   \n",
       "2                        97319                          32476   \n",
       "3                         3453                          97319   \n",
       "4                        33546                          33546   \n",
       "5                        95196                          95196   \n",
       "6                        37122                          37122   \n",
       "7                        34869                          34869   \n",
       "8                        30565                          30565   \n",
       "9                        36068                          36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.4  id_wsum_original_ext_cand0.45  \\\n",
       "0                         94936                          94936   \n",
       "1                         32476                          32476   \n",
       "2                          3453                           3453   \n",
       "3                         97319                          97319   \n",
       "4                         33546                          33546   \n",
       "5                         95196                          95196   \n",
       "6                         37122                          37122   \n",
       "7                         34869                          34869   \n",
       "8                         30565                          30565   \n",
       "9                         36068                          36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.5  id_wsum_original_ext_cand0.6  \\\n",
       "0                         94936                         94936   \n",
       "1                         32476                         32476   \n",
       "2                         97319                         97319   \n",
       "3                          3453                         33546   \n",
       "4                         33546                          3453   \n",
       "5                         95196                         95196   \n",
       "6                         37122                         37122   \n",
       "7                         34869                         34869   \n",
       "8                         30565                         30565   \n",
       "9                         36068                         36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.7  id_wsum_original_ext_cand0.8  \\\n",
       "0                         94936                         32476   \n",
       "1                         32476                         94936   \n",
       "2                         97319                         97319   \n",
       "3                         33546                         33546   \n",
       "4                          3453                         95196   \n",
       "5                         95196                          3453   \n",
       "6                         37122                         37122   \n",
       "7                         34869                         34869   \n",
       "8                         30565                         30565   \n",
       "9                         36068                         36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.9  id_wsum_original_ext_cand1  \n",
       "0                         32476                       32476  \n",
       "1                         94936                       94936  \n",
       "2                         97319                       97319  \n",
       "3                         33546                       33546  \n",
       "4                         95196                       95196  \n",
       "5                          3453                       37122  \n",
       "6                         37122                        3453  \n",
       "7                         34869                       34869  \n",
       "8                         30565                       30565  \n",
       "9                         36068                       36068  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original +ext + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_ext_cand)):\n",
    "    dataf = original_query_ext_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "conex = pd.concat(frames, axis=1)\n",
    "conex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.8 - 1 1st doc 32476, rest 1st doc 94936\n",
    "- 0.8 - 1 first 5 docs the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94936: 10, 32476: 10, 3453: 10, 97319: 10, 33546: 10, 95196: 10, 37122: 10, 34869: 10, 30565: 10, 36068: 10})\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "values = conex.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all columns contain same documents, just order is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n",
      "['pollution', 'pollutions', 'undergrounding', 'earpollution', 'pollution,']\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(ext)\n",
    "print(top_list)\n",
    "# 94936 light pollution -, 32476 fishing quotas o, 97319 light pollution - , 3453 marine pollution o\n",
    "# without weighted sum (below): \n",
    "# 32476 already appeared, 33546 fishing quotas o,37122 fishing quotas o,12744 groundwater protection +,92988 groundwater protection +\n",
    "# 33546 fishing quotas o, 92986 groundwater protection +\n",
    "# id_sum_original_cand best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E1892WRITTEN QUESTION No. 1892/97 by Amedeo AMADEO to the Commission. Integrated groundwater protection and managementOfficial Journal C 045 , 10/02/1998 P. 0120 WRITTEN QUESTION E-1892/97 by Amedeo Amadeo (NI) to the Commission (4 June 1997)Subject: Integrated groundwater protection and managementWith reference to the Commission Proposal for a European Parliament and Council Decision on an action programme for integrated groundwater protection and management (COM(96) 0315 final - 96/0181 COD) ((OJ C 355, 25.11.1996, p. 1.)),the proposed action programme comprises four main lines of action: planning and management of groundwater protection, creating a regulatory framework for fresh water abstraction, development of instruments for control of groundwater polution from diffuse sources and development of instruments for control of point source emissions and discharges.With regard to the first line of action, will the Commission:1. Classify waters according to their use, their different characteristics and the original water table?2. Take measures to reduce the waterproofing of the ground in suburban areas and take preventive measures against earth creep in areas intended for agricultural use?3. Restrict pumping capacities as far as possible to replenishing the water table and encourage the rational use and the re-use of water?4. Cooperate with the third countries preparing to accede to the European Union with the aim of helping them adapt to European quality standards?Answer given by Mrs Bjerregaard on behalf of the Commission (10 July 1997)The objective of the proposal for a Parliament and Council decision on an action programme for integrated groundwater protection and management is to ensure that protection and use of groundwater takes place as part of an integrated management of fresh water resources and that groundwaters on a long term basis will be managed with surface waters within a river basin management approach.In February 1997, the Commission adopted a proposal for a Council directive establishing a framework for Community action in the field of water policy ((COM(97) 49 final. )) which lays down the basic principles for integrated protection and use of groundwaters and surface waters within such a river basin management approach. Whilst part of the actions presented in the proposed groundwater action programme may be pursued through a variety of instruments, some may be strengthened through appropriate legal provisions. The proposed water framework directive is intended as a framework within which inter alia the protection and sustainable use of groundwater may be ensured through such legal provisions.1. It is the objective of the proposed groundwater action programme to ensure protection of all groundwaters and in line with this the proposed groundwater action programme does not classify groundwaters according to their use. On the contrary, in order to ensure appropriate protection and sustainable use the characteristics of a particular groundwater have to be taken into account and therefore the proposed groundwater action programme requires Member States to identify the environmental pressures as well as the particular vulnerability of groundwaters. Such designation of zones therefore is to be used to decide upon the nature of the measures which should be taken to protect a particular groundwater in a particular area.2. The proposed groundwater action programme requests Member States to take into consideration in the planning process that urban development may impair natural replenishment of groundwaters. In order to be targeted, measures to reduce the waterproofing of the ground in suburban areas and to prevent land subsidence due to a lowering of the water table should be adopted as appropriate in response to local circumstances.3. The proposed groundwater action programme requires a sustainable use of groundwaters in order to avoid overexploitation. Controls on abstraction as well as water saving, reuse and general good house-keeping of fresh water resources are encouraged as important elements in achieving this objective. Where appropriate either transiently or permanently restrictions on abstraction could be introduced depending on the local availability and characteristics of the aquifers.4. Approximation of legislation and standards is an integral part of the process within which the Community is preparing the potential enlargement. A wide range of activities and programmes target these questions in the approximation process. Top'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(92986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test1:\n",
    "## original query\n",
    "original_query_cand1 = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum = probab_score_sum_weights(test1, topw_list1,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_cand1'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_cand1.append(df_wsum_original_cand1)\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "original_query_ext_cand1 = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum =probab_score_sum_weights(test1+ext1, top_list1,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_ext_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_ext_cand1'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_ext_cand1.append(df_wsum_original_ext_cand1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sorting for each alpha\n",
    "doubleframes1 =[]\n",
    "for i in range(len(original_query_cand1)):\n",
    "    frst = original_query_cand1[i].take([0], axis=1)\n",
    "    snd = original_query_ext_cand1[i].take([0], axis=1)\n",
    "    con = pd.concat([frst,snd], axis=1)\n",
    "    doubleframes1.append(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand1-1</th>\n",
       "      <th>id_wsum_original_ext_cand1-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand1-1  id_wsum_original_ext_cand1-1\n",
       "0                     94870                         94870\n",
       "1                     11790                         92702\n",
       "2                    100258                         93604\n",
       "3                     97436                         97781\n",
       "4                     28599                         93549\n",
       "5                     92702                         14571\n",
       "6                     97265                         97436\n",
       "7                     50112                        100258\n",
       "8                     62459                         44382\n",
       "9                     49539                         98394"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleframes1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand1-1</th>\n",
       "      <th>id_wsum_original_cand10.35</th>\n",
       "      <th>id_wsum_original_cand10.4</th>\n",
       "      <th>id_wsum_original_cand10.45</th>\n",
       "      <th>id_wsum_original_cand10.5</th>\n",
       "      <th>id_wsum_original_cand10.6</th>\n",
       "      <th>id_wsum_original_cand10.7</th>\n",
       "      <th>id_wsum_original_cand10.8</th>\n",
       "      <th>id_wsum_original_cand10.9</th>\n",
       "      <th>id_wsum_original_cand11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand1-1  id_wsum_original_cand10.35  \\\n",
       "0                     94870                       94870   \n",
       "1                     11790                       11790   \n",
       "2                    100258                      100258   \n",
       "3                     97436                       97436   \n",
       "4                     28599                       28599   \n",
       "5                     92702                       92702   \n",
       "6                     97265                       97265   \n",
       "7                     50112                       50112   \n",
       "8                     62459                       62459   \n",
       "9                     49539                       49539   \n",
       "\n",
       "   id_wsum_original_cand10.4  id_wsum_original_cand10.45  \\\n",
       "0                      94870                       94870   \n",
       "1                      11790                       11790   \n",
       "2                     100258                      100258   \n",
       "3                      97436                       97436   \n",
       "4                      28599                       28599   \n",
       "5                      92702                       92702   \n",
       "6                      97265                       97265   \n",
       "7                      50112                       50112   \n",
       "8                      62459                       62459   \n",
       "9                      49539                       49539   \n",
       "\n",
       "   id_wsum_original_cand10.5  id_wsum_original_cand10.6  \\\n",
       "0                      94870                      94870   \n",
       "1                      11790                      11790   \n",
       "2                     100258                     100258   \n",
       "3                      97436                      97436   \n",
       "4                      28599                      28599   \n",
       "5                      92702                      92702   \n",
       "6                      97265                      97265   \n",
       "7                      50112                      50112   \n",
       "8                      62459                      62459   \n",
       "9                      49539                      49539   \n",
       "\n",
       "   id_wsum_original_cand10.7  id_wsum_original_cand10.8  \\\n",
       "0                      94870                      94870   \n",
       "1                      11790                      11790   \n",
       "2                     100258                     100258   \n",
       "3                      97436                      97436   \n",
       "4                      28599                      28599   \n",
       "5                      92702                      92702   \n",
       "6                      97265                      97265   \n",
       "7                      50112                      50112   \n",
       "8                      62459                      62459   \n",
       "9                      49539                      49539   \n",
       "\n",
       "   id_wsum_original_cand10.9  id_wsum_original_cand11  \n",
       "0                      94870                    94870  \n",
       "1                      11790                    11790  \n",
       "2                     100258                   100258  \n",
       "3                      97436                    97436  \n",
       "4                      28599                    28599  \n",
       "5                      92702                    92702  \n",
       "6                      97265                    97265  \n",
       "7                      50112                    50112  \n",
       "8                      62459                    62459  \n",
       "9                      49539                    49539  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_cand1)):\n",
    "    dataf = original_query_cand1[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "con1 = pd.concat(frames, axis=1)\n",
    "con1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all columns the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n",
      "['earpollution', 'pollution', 'pollutants', 'biopollution', 'potable']\n"
     ]
    }
   ],
   "source": [
    "print(test1)\n",
    "print(ext1)\n",
    "print(top_list1)\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E3072WRITTEN QUESTION No. 3072/97 by Amedeo AMADEO to the Commission. Environmental agreementsOfficial Journal C 117 , 16/04/1998 P. 0146 WRITTEN QUESTION E-3072/97 by Amedeo Amadeo (NI) to the Commission (2 October 1997)Subject: Environmental agreementsThe main objective of the Commissions communication on environmental agreements (COM(96) 561 final) is to promote and facilitate the use of effective and acceptable environmental agreements. These agreements are instruments for the integration or implementation of environment law in the Community. The communication should be seen in the light of the strategy outlined in the fifth action programme to extend the range of environment policy instruments and put into practice the concept of shared responsibility.The communication also seeks to clarify certain aspects of how environmental agreements can be used to implement certain provisions of Community directives in the Member States and how environmental agreements can be used at Community level.Does the Commission recommendation on environmental agreements refer only to their transposal into national law or does it also cover the application of the provisions once transposed?Answer given by Mrs Bjerregaard on behalf of the Commission (31 October 1997)The Commission Recommendation concerning environmental agreements implementing Community directives ((OJ L 333, 21.12.1996. )) not only concerns the transposition of certain provisions of directives into national law but also the implementation of the transposed law. The word implementation includes both the transposition into national law and the application of the transposed provisions. Clearly, where national legislation is in place to ensure compliance with a directive, the form of implementing these rules is less important. Nevertheless, the Commission considers the legal status of agreements as an important element of their success and therefore recommends that they be concluded in a legally-binding form. Top'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(93604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original</th>\n",
       "      <th>id_sum_original_cand</th>\n",
       "      <th>id_sum_original_ext</th>\n",
       "      <th>id_sum_original_ext_cand</th>\n",
       "      <th>id_wsum_original_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>92986</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>92988</td>\n",
       "      <td>37122</td>\n",
       "      <td>32476</td>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>9649</td>\n",
       "      <td>34869</td>\n",
       "      <td>97319</td>\n",
       "      <td>94936</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30565</td>\n",
       "      <td>93921</td>\n",
       "      <td>30565</td>\n",
       "      <td>33546</td>\n",
       "      <td>97319</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36068</td>\n",
       "      <td>32476</td>\n",
       "      <td>36068</td>\n",
       "      <td>95196</td>\n",
       "      <td>92986</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3867</td>\n",
       "      <td>62937</td>\n",
       "      <td>3867</td>\n",
       "      <td>37122</td>\n",
       "      <td>33546</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>94936</td>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94467</td>\n",
       "      <td>97319</td>\n",
       "      <td>94467</td>\n",
       "      <td>30565</td>\n",
       "      <td>9649</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38921</td>\n",
       "      <td>95196</td>\n",
       "      <td>38921</td>\n",
       "      <td>36068</td>\n",
       "      <td>37122</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original  id_sum_original_cand  id_sum_original_ext  \\\n",
       "0            32476                 12744                32476   \n",
       "1            33546                 92986                33546   \n",
       "2            37122                 92988                37122   \n",
       "3            34869                  9649                34869   \n",
       "4            30565                 93921                30565   \n",
       "5            36068                 32476                36068   \n",
       "6             3867                 62937                 3867   \n",
       "7            95196                 94936                95196   \n",
       "8            94467                 97319                94467   \n",
       "9            38921                 95196                38921   \n",
       "\n",
       "   id_sum_original_ext_cand  id_wsum_original_cand0.4  \\\n",
       "0                     94936                     32476   \n",
       "1                      3453                     12744   \n",
       "2                     32476                     92988   \n",
       "3                     97319                     94936   \n",
       "4                     33546                     97319   \n",
       "5                     95196                     92986   \n",
       "6                     37122                     33546   \n",
       "7                     34869                     95196   \n",
       "8                     30565                      9649   \n",
       "9                     36068                     37122   \n",
       "\n",
       "   id_wsum_original_ext_cand0.4  \n",
       "0                         94936  \n",
       "1                         32476  \n",
       "2                          3453  \n",
       "3                         97319  \n",
       "4                         33546  \n",
       "5                         95196  \n",
       "6                         37122  \n",
       "7                         34869  \n",
       "8                         30565  \n",
       "9                         36068  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of summation method versions on test set\n",
    "frms = [df_sum_original[\"id_sum_original\"], df_sum_original_cand[\"id_sum_original_cand\"], df_sum_original_ext['id_sum_original_ext'],df_sum_original_ext_cand['id_sum_original_ext_cand'],doubleframes[2]]\n",
    "sum_result = pd.concat(frms, axis=1)\n",
    "sum_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 6, 95196: 6, 33546: 5, 37122: 5, 94936: 4, 34869: 4, 97319: 4, 30565: 4, 36068: 4, 12744: 2, 92986: 2, 3453: 2, 92988: 2, 9649: 2, 3867: 2, 94467: 2, 38921: 2, 93921: 1, 62937: 1})\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "values = sum_result.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- same results for sum original and sum original_ext\n",
    "- slight diff. between original ext cand and original ext cand wsum  \n",
    "- ..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original1</th>\n",
       "      <th>id_sum_original_cand1</th>\n",
       "      <th>id_sum_original_ext1</th>\n",
       "      <th>id_sum_original_ext_cand1</th>\n",
       "      <th>id_wsum_original_cand10.4</th>\n",
       "      <th>id_wsum_original_ext_cand10.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original1  id_sum_original_cand1  id_sum_original_ext1  \\\n",
       "0             94870                  94870                 94870   \n",
       "1             11790                  11790                 92702   \n",
       "2            100258                 100258                 93604   \n",
       "3             97436                  97436                 97781   \n",
       "4             28599                  28599                 93549   \n",
       "5             92702                  92702                 14571   \n",
       "6             97265                  97265                 97436   \n",
       "7             50112                  50112                100258   \n",
       "8             62459                  62459                 44382   \n",
       "9             49539                  49539                 98394   \n",
       "\n",
       "   id_sum_original_ext_cand1  id_wsum_original_cand10.4  \\\n",
       "0                      94870                      94870   \n",
       "1                      92702                      11790   \n",
       "2                      93604                     100258   \n",
       "3                      97781                      97436   \n",
       "4                      93549                      28599   \n",
       "5                      14571                      92702   \n",
       "6                      97436                      97265   \n",
       "7                     100258                      50112   \n",
       "8                      44382                      62459   \n",
       "9                      98394                      49539   \n",
       "\n",
       "   id_wsum_original_ext_cand10.4  \n",
       "0                          94870  \n",
       "1                          92702  \n",
       "2                          93604  \n",
       "3                          97781  \n",
       "4                          93549  \n",
       "5                          14571  \n",
       "6                          97436  \n",
       "7                         100258  \n",
       "8                          44382  \n",
       "9                          98394  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of summation method versions on test1 set\n",
    "frames = [df_sum_original1[\"id_sum_original1\"], df_sum_original_cand1[\"id_sum_original_cand1\"], df_sum_original_ext1['id_sum_original_ext1'],df_sum_original_ext_cand1['id_sum_original_ext_cand1'],doubleframes1[2]]\n",
    "sum_result1 = pd.concat(frames, axis=1)\n",
    "sum_result1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st place the same\n",
    "- sum original, sum original cand, wsum original cand same\n",
    "- sum original ext, sum original ext cand, wsum original ext  cand the same\n",
    "  --> having ext or not gives different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94870: 6, 92702: 6, 100258: 6, 97436: 6, 11790: 3, 93604: 3, 97781: 3, 28599: 3, 93549: 3, 14571: 3, 97265: 3, 50112: 3, 62459: 3, 44382: 3, 49539: 3, 98394: 3})\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "values = sum_result1.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter1=collections.Counter(flat_vals)\n",
    "print((counter1))\n",
    "print(len(counter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4 values appear in all columns, rest of the values appear in half columns (ext/not ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first 5 returned docs no difference between weighted and unweighted for alpha = 0.6,  alpha = 0.8, 1 #if all weight the same is same as\n",
    "# if expansion would not exist\n",
    "# only tokens / tokens + ext\n",
    "# [(99, 0.048582995951417005), (380, 0.046610169491525424), (244, 0.04477611940298507), (89, 0.04371584699453552), (376, 0.04034065441506051)]\n",
    "# [(244, 0.08955223880597014), (243, 0.08), (903, 0.04964539007092198), (99, 0.048582995951417005), (380, 0.046610169491525424)]\n",
    "# unweighted with candidate exp:\n",
    "# [(565, 0.048730964467005075), (1219, 0.0461864406779661), (12, 0.04042348411934552), (226, 0.039756782039289056), (22, 0.03749147920927062)]\n",
    "# [(565, 0.05177664974619289), (1219, 0.04745762711864407), (12, 0.04138594802694899), (226, 0.04069223573433115), (22, 0.03953646898432175)]\n",
    "# [(99, 0.048582995951417005), (380, 0.046610169491525424), (244, 0.04477611940298507), (89, 0.04371584699453552), (376, 0.04034065441506051)]\n",
    "# [(244, 0.08955223880597014), (243, 0.08), (903, 0.04964539007092198), (99, 0.048582995951417005), (380, 0.046610169491525424)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 10\n",
    "# alpha 0.8, 1\n",
    "# [(161, 0.027947874459039665), (313, 0.027129979796553974), (73, 0.025445292620865142), (402, 0.022429906542056073)]\n",
    "# [(161, 0.027915369391449767), (313, 0.02712754175646111), (73, 0.025570205421714953), (402, 0.022429906542056073)]\n",
    "# [(243, 0.032), (925, 0.031578947368421054), (1212, 0.03118536197295147), (910, 0.031168831168831172), (108, 0.03114754098360656)]\n",
    "# [(1212, 0.036276849642004776), (89, 0.034972677595628415), (376, 0.032989690721649485), (925, 0.031578947368421054), (910, 0.031168831168831172)]\n",
    "# for alpha 0.6 one change in one case\n",
    "# only tokens/tokens+ext\n",
    "# [(243, 0.04), (925, 0.039473684210526314), (1212, 0.03898170246618934), (910, 0.03896103896103896), (108, 0.0389344262295082)]\n",
    "# [(1212, 0.045346062052505964), (89, 0.04371584699453552), (376, 0.041237113402061855), (925, 0.039473684210526314), (910, 0.03896103896103896)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 2.TFIDF evaluation\n",
    "# texts_keys = []\n",
    "# texts_values = []\n",
    "# for key in sorted(texts.keys()) :\n",
    "#     texts_keys.append(key)\n",
    "#     texts_values.append(texts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "# vectors_t = vectorizer.fit_transform(texts_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first vector out (for the first document)\n",
    "# vector_t = vectors_t[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # place tf-idf values in a pandas data frame\n",
    "# vector_dframe_t = pd.DataFrame(vector_t.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "# vector_dframe_t = vector_dframe_t.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dframe_t.head(50) #treaty ne sesteje lepo, lahko bi text olepsal preden gre v vectorizer, a pojavitev pomeni istost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to solve with transformation into string of tokenized text:\n",
    "# strings_keys = []\n",
    "# strings = []\n",
    "# for key in sorted(tokenized_docs.keys()) :\n",
    "#     strings_keys.append(key)\n",
    "#     list_tokens = tokenized_docs[key]\n",
    "#     corrected = \" \".join(list_tokens)\n",
    "#     strings.append(corrected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = vectorizer.fit_transform(strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first vector out (for the first document)\n",
    "# vector = vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # place tf-idf values in a pandas data frame\n",
    "# vector_dframe = pd.DataFrame(vector.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "# vector_dframe = vector_dframe.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dframe.head(50) #not much difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tfidf only for query words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_docs_tokens_appear(tokensI,tokenized_docsI,textsI):\n",
    "    docs_per_token = []\n",
    "    for i in range(len(tokensI)):\n",
    "        docs_per_token.append(0)\n",
    "    for k, v in tokenized_docsI.items():\n",
    "        content = tokenized_docsI.get(k)\n",
    "        text = textsI.get(k)\n",
    "        for i in range(len(tokensI)):\n",
    "            token = tokensI[i]\n",
    "            if token in text:\n",
    "                docs_per_token[i] = docs_per_token[i]+1\n",
    "    return docs_per_token\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_sum(tokensI,tokenized_docsI, textsI):\n",
    "    '''First tuple argument similar to probab_score_sum function but different metric - tfidf, second returns words that did not occure in any document'''\n",
    "    nb_docs_tokens_appeared = nb_docs_tokens_appear(tokensI,tokenized_docsI,textsI)\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokensI[i])\n",
    "        else:\n",
    "            appear.append(tokensI[i])    \n",
    "    l = len(tokenized_docsI)\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docsI.items():\n",
    "        n = len(v)\n",
    "        text = textsI.get(k)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = text.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            probability = probability+((token_frequency/n)*idf)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab, not_appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>0.197593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>0.189548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>0.180744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>0.178706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>0.178279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30565</td>\n",
       "      <td>0.174945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36068</td>\n",
       "      <td>0.174911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3867</td>\n",
       "      <td>0.174496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63388</td>\n",
       "      <td>0.167434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94467</td>\n",
       "      <td>0.166841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original     score\n",
       "0                  32476  0.197593\n",
       "1                  33546  0.189548\n",
       "2                  37122  0.180744\n",
       "3                  34869  0.178706\n",
       "4                  95196  0.178279\n",
       "5                  30565  0.174945\n",
       "6                  36068  0.174911\n",
       "7                   3867  0.174496\n",
       "8                  63388  0.167434\n",
       "9                  94467  0.166841"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test,tokenized_docs, texts)\n",
    "df_tfidf_sum_original = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original', 'score'])\n",
    "tf[1] #query words that did not appear in any doc\n",
    "df_tfidf_sum_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+ext,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_ext = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earpollution']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+ext+top_list,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_ext_cand = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext_cand', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_ext_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earpollution']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+topw_list,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_cand = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_cand', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original</th>\n",
       "      <th>id_tfidf_sum_original_ext</th>\n",
       "      <th>id_tfidf_sum_original_ext_cand</th>\n",
       "      <th>id_tfidf_sum_original_cand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>12744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>93533</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>97320</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>4505</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>94953</td>\n",
       "      <td>92987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3867</td>\n",
       "      <td>3867</td>\n",
       "      <td>59175</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63388</td>\n",
       "      <td>63388</td>\n",
       "      <td>93921</td>\n",
       "      <td>47944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94467</td>\n",
       "      <td>94467</td>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original  id_tfidf_sum_original_ext  \\\n",
       "0                  32476                      32476   \n",
       "1                  33546                      33546   \n",
       "2                  37122                      37122   \n",
       "3                  34869                      34869   \n",
       "4                  95196                      95196   \n",
       "5                  30565                      30565   \n",
       "6                  36068                      36068   \n",
       "7                   3867                       3867   \n",
       "8                  63388                      63388   \n",
       "9                  94467                      94467   \n",
       "\n",
       "   id_tfidf_sum_original_ext_cand  id_tfidf_sum_original_cand  \n",
       "0                           94936                       92988  \n",
       "1                            3453                       12744  \n",
       "2                           97319                       92986  \n",
       "3                           93533                        9649  \n",
       "4                           97320                       94936  \n",
       "5                            4505                       97319  \n",
       "6                           94953                       92987  \n",
       "7                           59175                       93921  \n",
       "8                           93921                       47944  \n",
       "9                           92988                        3453  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_tfidf_sum_original['id_tfidf_sum_original'], df_tfidf_sum_original_ext['id_tfidf_sum_original_ext'], df_tfidf_sum_original_ext_cand['id_tfidf_sum_original_ext_cand'],df_tfidf_sum_original_cand['id_tfidf_sum_original_cand']]\n",
    "tfidf_sum_result = pd.concat(frames, axis=1)\n",
    "tfidf_sum_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tfifd sum original and tfidf sum original ext the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 2, 94936: 2, 92988: 2, 33546: 2, 3453: 2, 37122: 2, 97319: 2, 34869: 2, 95196: 2, 30565: 2, 36068: 2, 3867: 2, 93921: 2, 63388: 2, 94467: 2, 12744: 1, 92986: 1, 93533: 1, 9649: 1, 97320: 1, 4505: 1, 94953: 1, 92987: 1, 59175: 1, 47944: 1})\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "values = tfidf_sum_result.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "countertf=collections.Counter(flat_vals)\n",
    "print((countertf))\n",
    "print(len(countertf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n",
      "['pollution', 'pollutions', 'undergrounding', 'earpollution', 'pollution,']\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(ext)\n",
    "print(top_list)\n",
    "##############################################\n",
    "#SUM\n",
    "###############################################\n",
    "# 94936 light pollution -, 32476 fishing quotas o, 97319 light pollution - , 3453 marine pollution o\n",
    "# without weighted sum (below): \n",
    "# 32476 already appeared, 33546 fishing quotas o,37122 fishing quotas o,12744 groundwater protection +,92988 groundwater protection +\n",
    "# 33546 fishing quotas o, 92986 groundwater protection +\n",
    "# id_sum_original_cand best choice\n",
    "##############################################\n",
    "# TFIDF\n",
    "##########################################\n",
    "# 32476, 94936, 92988, 33546, 3453, 12744, ... \n",
    "# id_tfidf_sum_original_ext_cand -, id_tfidf_sum_original_cand +, id_tfidf_sum_original and id_tfidf_sum_original_ext o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91998E2572WRITTEN QUESTION No. 2572/98 by John McCARTIN Fishing agreement with the Comores 1994-1997Official Journal C 320 , 06/11/1999 P. 0008 WRITTEN QUESTION E-2572/98by John McCartin (PPE) to the Commission(1 September 1998)Subject: Fishing agreement with the Comores 1994-1997Can the Commission state how many fishing vessels were involved in the 1994-1997 EU fishing agreement with the Comores, what was the tonnage of these vessels and how many days they fished under the agreement? Top'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(94870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original_cand</th>\n",
       "      <th>id_sum_original_cand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92988</td>\n",
       "      <td>12744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12744</td>\n",
       "      <td>92986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92986</td>\n",
       "      <td>92988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9649</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94936</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97319</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>92987</td>\n",
       "      <td>62937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93921</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47944</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original_cand  id_sum_original_cand\n",
       "0                       92988                 12744\n",
       "1                       12744                 92986\n",
       "2                       92986                 92988\n",
       "3                        9649                  9649\n",
       "4                       94936                 93921\n",
       "5                       97319                 32476\n",
       "6                       92987                 62937\n",
       "7                       93921                 94936\n",
       "8                       47944                 97319\n",
       "9                        3453                 95196"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test = pd.concat([tfidf_sum_result['id_tfidf_sum_original_cand'], sum_result['id_sum_original_cand']], axis=1)\n",
    "best_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({92988: 2, 12744: 2, 92986: 2, 9649: 2, 94936: 2, 93921: 2, 97319: 2, 32476: 1, 92987: 1, 62937: 1, 47944: 1, 3453: 1, 95196: 1})\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "values = best_test.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "countbestTest=collections.Counter(flat_vals)\n",
    "print((countbestTest))\n",
    "print(len(countbestTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different:\n",
    "# sum probab:32476 o, 62937 +, 95196 o+\n",
    "# tfidf sum :92987 +,47944 +, 3453 o,\n",
    "# tfidf better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91998E3492WRITTEN QUESTION No. 3492/98 by Luigi MORETTI to the Commission. Pollution of surface waterOfficial Journal C 207 , 21/07/1999 P. 0077 WRITTEN QUESTION E-3492/98by Luigi Moretti (NI) to the Commission(25 November 1998)Subject: Pollution of surface waterThe drainage systems in built-up areas are often not designed to convey surface water, or water from recent rainfall, to water treatment plants. As a result, these waters flow into rivers, streams and lakes.To my knowledge there are currently no laws or provisions requiring these waters to be treated before they enter waterways.In view of the fact that surface water and water from recent rainfall are more polluted than sewage, since they contain over 2010 exhaust gases and heavy metals, can the Commission say what measures it intends to adopt in this area?Answer given by Mrs Bjerregaard on behalf of the Commission(12 January 1999)Rainwater on impermeable urban surfaces can be collected either separately from the domestic and industrial waste water of the built-up area (this is known as a separate sewer system) or in the same sewer as the waste water (a combined system). Two-thirds of urban areas have combined systems. Council Directive 91/271/EEC of 21 May 1991 concerning urban waste-water treatment(1) requires Member States to provide for the collection and treatment of the mixture of waste water and run-off rainwater in a combined sewer system. However, given that it is not possible in practice to construct collecting systems and treatment plants in a way such that all waste water can be treated during situations such as unusually heavy rainfall, the Directive lays down that Member States must decide on measures to limit pollution from storm water overflows. Such measures could be based on dilution rates or capacity in relation to dry weather flow, or could specify a certain acceptable number of overflows per year.As regards direct discharges of run-off water from separate sewer systems, the proposal for a Directive establishing a framework for Community action in the field of water policy(2), in providing that account should be taken of all major sources of pollution in each catchment area, will make it possible to regulate such discharges.(1) OJ L 135, 30.5.1991.(2) OJ C 108, 7.4.1998. Top'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(95196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['flwfishing']\n",
      "['flwfishing', 'earpollution', 'biopollution']\n",
      "['earpollution', 'biopollution']\n"
     ]
    }
   ],
   "source": [
    "tf = tfidf_sum(test1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original1', 'score'])\n",
    "tf = tfidf_sum(test1+ext1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_ext1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext1', 'score'])\n",
    "tf = tfidf_sum(test1+ext1+top_list1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_ext_cand1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext_cand1', 'score'])\n",
    "tf = tfidf_sum(test1+topw_list1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_cand1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_cand1', 'score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original1</th>\n",
       "      <th>id_tfidf_sum_original_ext1</th>\n",
       "      <th>id_tfidf_sum_original_ext_cand1</th>\n",
       "      <th>id_tfidf_sum_original_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97436</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100258</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>38528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50112</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>28599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39238</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49539</td>\n",
       "      <td>96942</td>\n",
       "      <td>96942</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>96093</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>50112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original1  id_tfidf_sum_original_ext1  \\\n",
       "0                   94870                       92702   \n",
       "1                   11790                       94870   \n",
       "2                   97436                       93604   \n",
       "3                  100258                       97781   \n",
       "4                   28599                       97436   \n",
       "5                   50112                       93549   \n",
       "6                   97265                      100258   \n",
       "7                   39238                       14571   \n",
       "8                   49539                       96942   \n",
       "9                   96093                       11790   \n",
       "\n",
       "   id_tfidf_sum_original_ext_cand1  id_tfidf_sum_original_cand1  \n",
       "0                            92702                        94870  \n",
       "1                            94870                        11790  \n",
       "2                            93604                        97436  \n",
       "3                            97781                       100258  \n",
       "4                            97436                        38528  \n",
       "5                            93549                        28599  \n",
       "6                           100258                         3455  \n",
       "7                            14571                        94936  \n",
       "8                            96942                        97319  \n",
       "9                            11790                        50112  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_tfidf_sum_original1['id_tfidf_sum_original1'], df_tfidf_sum_original_ext1['id_tfidf_sum_original_ext1'], df_tfidf_sum_original_ext_cand1['id_tfidf_sum_original_ext_cand1'],df_tfidf_sum_original_cand1['id_tfidf_sum_original_cand1']]\n",
    "tfidf_sum_result1 = pd.concat(frames, axis=1)\n",
    "tfidf_sum_result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sum_original_ext and sum_original_ext_cand same, the other two columns same in first 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUM\n",
    "############################################################\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention\n",
    "############################################################\n",
    "# TFIDF\n",
    "#94870, 92702, 11790, 94870,97436 overfishing, 93604\n",
    "# better without ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94870: 4, 11790: 4, 97436: 4, 100258: 4, 92702: 2, 93604: 2, 97781: 2, 28599: 2, 50112: 2, 93549: 2, 14571: 2, 96942: 2, 38528: 1, 97265: 1, 3455: 1, 39238: 1, 94936: 1, 49539: 1, 97319: 1, 96093: 1})\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "values = tfidf_sum_result1.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "countertf1=collections.Counter(flat_vals)\n",
    "print((countertf1))\n",
    "print(len(countertf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n",
      "['earpollution', 'pollution', 'pollutants', 'biopollution', 'potable']\n"
     ]
    }
   ],
   "source": [
    "print(test1)\n",
    "print(ext1)\n",
    "print(top_list1)\n",
    "############\n",
    "#SUM\n",
    "############################################################\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention\n",
    "############################################################\n",
    "# TFIDF\n",
    "#94870 already, 92702 fishing already, 93604 environmental agreement\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|92000E3661WRITTEN QUESTION E-3661/00 by Glenys Kinnock (PSE) to the Commission. Coastal fishing in ACP countries.Official Journal 174 E , 19/06/2001 P. 0104 - 0105 WRITTEN QUESTION E-3661/00by Glenys Kinnock (PSE) to the Commission(27 November 2000)Subject: Coastal fishing in ACP countriesWould the Commission outline what measures it is taking to ensure that Community fishing vessels, operating under EU-ACP fishing agreements, respect the needs and rights of small-scale, coastal fishing communities in ACP countries and do not damage the local ACP fisheries sector?What action is the Commission taking to improve the capacity of ACP countries to patrol the waters under their jurisdiction, so as to control the activities of both Community and ACP fishing fleets and thereby prevent overfishing?Answer given by Mr Fischler on behalf of the Commission(5 January 2001)The Commission thanks the Honourable Member for her question and informs her that, in order to avoid clashes with small-scale traditional fishermen, protocols to fisheries agreements specify fishing zones for the Community which differ from those for local vessels.As for improving the capacity of African, Caribbean and Pacific (ACP) countries to control fishing activities, the Commission is pleased to inform the Honourable Member that, since 1997 the majority of fisheries agreements concluded between the Community and third countries (namely ACP countries) stipulate that an important part of the financial compensation paid in exchange for fishing possibilities be devoted to targeted actions, amongst which are monitoring, control and surveillance activities, including the setting up of satellite based vessel monitoring systems. Top'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(97436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_sum_weights(original_tokens, top_expansion,tokenized_docs,texts, wv, alpha): \n",
    "    tokens_together = original_tokens+top_expansion\n",
    "    nb_docs_tokens_appeared = nb_docs_tokens_appear(tokens_together,tokenized_docs,texts)\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokens_together[i])\n",
    "        else:\n",
    "            appear.append(tokens_together[i])  \n",
    "    l = len(tokenized_docs)\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        text = texts.get(k)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = text.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            probability = probability+((token_frequency/n)*idf)*word_value(appear[i], alpha, original_tokens, top_expansion, wv)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab,not_appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_original_query_ext_cand = []\n",
    "for alpha in [0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    tfw = tfidf_sum_weights(test+ext, top_list,tokenized_docs,texts, wv_wiki_en, alpha)\n",
    "    df_tfidf_wsum_original_ext_cand = pd.DataFrame(top_positives(tfw[0],10), columns =['id_tfidf_wsum_original_ext_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    tfidf_original_query_ext_cand.append(df_tfidf_wsum_original_ext_cand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.5</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.6</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.7</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.8</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.9</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4505</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59175</td>\n",
       "      <td>4505</td>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "      <td>4505</td>\n",
       "      <td>4505</td>\n",
       "      <td>4505</td>\n",
       "      <td>4505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_wsum_original_ext_cand0.5  id_tfidf_wsum_original_ext_cand0.6  \\\n",
       "0                               94936                               94936   \n",
       "1                               97319                               97319   \n",
       "2                                3453                                3453   \n",
       "3                               93533                               93533   \n",
       "4                               97320                               97320   \n",
       "5                                4505                               59175   \n",
       "6                               59175                                4505   \n",
       "7                               93921                               93921   \n",
       "8                               94953                               94953   \n",
       "9                               62286                               62286   \n",
       "\n",
       "   id_tfidf_wsum_original_ext_cand0.7  id_tfidf_wsum_original_ext_cand0.8  \\\n",
       "0                               94936                               94936   \n",
       "1                               97319                               97319   \n",
       "2                                3453                                3453   \n",
       "3                               93533                               93533   \n",
       "4                               97320                               97320   \n",
       "5                               59175                               59175   \n",
       "6                               93921                               93921   \n",
       "7                                4505                                4505   \n",
       "8                               94953                               94953   \n",
       "9                               62286                               62286   \n",
       "\n",
       "   id_tfidf_wsum_original_ext_cand0.9  id_tfidf_wsum_original_ext_cand1  \n",
       "0                               94936                             94936  \n",
       "1                               97319                             97319  \n",
       "2                                3453                              3453  \n",
       "3                               93533                             93533  \n",
       "4                               97320                             97320  \n",
       "5                               59175                             59175  \n",
       "6                               93921                             93921  \n",
       "7                                4505                              4505  \n",
       "8                               94953                             94953  \n",
       "9                               62286                             62286  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + ext + cand\n",
    "frames =[]\n",
    "for i in range(len(tfidf_original_query_ext_cand)):\n",
    "    dataf = tfidf_original_query_ext_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "tfidfcon = pd.concat(frames, axis=1)\n",
    "tfidfcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################\n",
    "# #set json format in readable form (starting wih multiple objec format, need list)\n",
    "# annotation_dir='D:/Users/sarab/work/enviroLens/files/'\n",
    "# print('Loading annotations')\n",
    "# annotations=[]\n",
    "# for filename in os.listdir(annotation_dir):\n",
    "#     print('loading file ',filename)\n",
    "#     lines = [line.rstrip('\\n') for line in open(annotation_dir+filename,encoding='utf-8')]\n",
    "#     for line in lines:\n",
    "#         js=json.loads(line)\n",
    "#         annotations.append(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
