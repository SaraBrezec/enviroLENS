{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion\n",
    "### Using FastText Word Embedding\n",
    "Based on this paper: https://arxiv.org/pdf/1606.07608.pdf\n",
    "\n",
    "Pre-made vector models: https://fasttext.cc/docs/en/aligned-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:16.676369Z",
     "start_time": "2019-06-12T13:31:15.880009Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from itertools import islice\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "\n",
    "# import natural language toolkit\n",
    "from nltk.corpus   import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# prepare stopword list\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'data', 'modules', 'query-expansion.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T07:16:14.874574Z",
     "start_time": "2019-06-12T07:06:52.184229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarab\\Miniconda3\\envs\\envirolens\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english words 2519370\n"
     ]
    }
   ],
   "source": [
    "wiki_en_align = '../../data/fasttext/wiki.en.align.vec'\n",
    "# get fasttext wiki embeddings for english\n",
    "wv_wiki_en = KeyedVectors.load_word2vec_format(wiki_en_align)\n",
    "print('english words {}'.format(len(list(wv_wiki_en.vocab.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-retrieval kNN Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:17.961109Z",
     "start_time": "2019-06-12T13:31:17.954389Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of terms\n",
    "def tokenize(text, stopwords):\n",
    "    \"\"\"Tokenizes and removes stopwords from the document\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered = [w.lower() for w in tokens if not w in stopwords]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extended list of terms ###\n",
    "def extend_tokens(token_list, wv):\n",
    "    \"\"\"Extends token list summing vector pairs\"\"\"\n",
    "    tokens = []\n",
    "    for token in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "        if token in wv.vocab.keys():\n",
    "            tokens.append(token)\n",
    "    extention = set()\n",
    "    for i in range(len(tokens)-1):\n",
    "        new_token = wv_wiki_en.most_similar(positive=[tokens[i], tokens[i+1]])[0][0]\n",
    "        extention.add(new_token)\n",
    "    extention = list(extention)\n",
    "    return extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n"
     ]
    }
   ],
   "source": [
    "test = tokenize('water pollution underground', stop_words)\n",
    "print(test)\n",
    "ext = extend_tokens(test,wv_wiki_en)\n",
    "print(ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n"
     ]
    }
   ],
   "source": [
    "test1 = tokenize('annex fishing agreement europe', stop_words)\n",
    "print(test1)\n",
    "ext1 = extend_tokens(test1,wv_wiki_en)\n",
    "print(ext1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:18.473214Z",
     "start_time": "2019-06-12T13:31:18.465157Z"
    }
   },
   "outputs": [],
   "source": [
    "# knn nearest\n",
    "def get_candidate_expansion_terms(tokens, k, wv):\n",
    "    \"\"\"Gets the candidate expansion terms\"\"\"\n",
    "    candidates = set()\n",
    "    for token in tokens:\n",
    "        # check if the token is in the vocabulary\n",
    "        if token in wv.vocab.keys():\n",
    "            result = wv.similar_by_word(token)\n",
    "            limit = k if len(result) > k else len(result)\n",
    "            # iterate through the most similar words\n",
    "            for i in range(limit):\n",
    "                candidates.add(result[i][0])\n",
    "    # return list of candidates\n",
    "    candidates = list(candidates)\n",
    "    return candidates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:20.226899Z",
     "start_time": "2019-06-12T13:31:19.569959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pollutions', 'undergrounders', 'potable', 'undergroun', 'undergroung', 'biopollution', 'earpollution', 'pollution', 'undergrounder', 'undergrounded', 'groundwater', 'undergrounding', '#pollution', 'seawater', 'sewage', 'water—', 'undergrounds', 'pollution,', 'pollutants']\n",
      "['biopollution', 'groundwater', 'earpollution', 'undergrounding', '#pollution', 'undergrounds', 'seawater', 'pollutions', 'pollution,', 'undergrounded', 'sewage', 'potable', 'undergroun', 'undergroung', 'water—']\n"
     ]
    }
   ],
   "source": [
    "candidates = get_candidate_expansion_terms(test+ext, 5, wv_wiki_en)\n",
    "print(candidates)\n",
    "witout = get_candidate_expansion_terms(test, 5, wv_wiki_en)\n",
    "print(witout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between word and list of words\n",
    "def similarity(token, token_list, wv ):\n",
    "    \"\"\"calculates the similarity between word and list of words\"\"\"\n",
    "    # calculate the similarity of the token to all tokens\n",
    "    similarity = 0\n",
    "    num_of_tokens = 0\n",
    "    for toks in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "        if toks in wv.vocab.keys():\n",
    "            num_of_tokens += 1\n",
    "            similarity += wv.similarity(toks, token)\n",
    "    return similarity/num_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:13.725242Z",
     "start_time": "2019-06-12T13:33:13.716880Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculates similarity and sorts\n",
    "def get_top_expansion_terms(tokens, candidates, wv):\n",
    "    \"\"\"Gets the actual expansion terms\"\"\"\n",
    "    similarity_pairs = []\n",
    "    for candidate in candidates:\n",
    "        sim = similarity(candidate, tokens, wv)\n",
    "        similarity_pairs.append((candidate, sim))\n",
    "    # return the list of expansion terms with their similarities\n",
    "    return similarity_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:14.317627Z",
     "start_time": "2019-06-12T13:33:14.308832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pollution', 0.6260276407951795), ('pollutions', 0.5989783010567384), ('undergrounding', 0.5868486694404182), ('earpollution', 0.5791309410113682), ('pollution,', 0.5584437076938438), ('pollutants', 0.5473505877035749), ('groundwater', 0.5472185974670385), ('sewage', 0.5438533174483885), ('undergrounds', 0.5373294534380543), ('#pollution', 0.5307803259871704), ('biopollution', 0.5239432296935493), ('undergrounded', 0.5166503920961191), ('undergrounders', 0.5048834686641379), ('undergroun', 0.4968187167322256), ('undergrounder', 0.4930006599112927), ('undergroung', 0.489668825408463), ('seawater', 0.48062588166948944), ('potable', 0.47213486261999227), ('water—', 0.4339509338693007)]\n",
      "[('pollution', 0.6073097696558459), ('groundwater', 0.572225614085378), ('sewage', 0.5672777675468184), ('earpollution', 0.5479508482970045), ('pollutions', 0.5392823009654663), ('pollution,', 0.5361565112564385), ('pollutants', 0.5332377192240293), ('seawater', 0.5219145986771884), ('undergrounding', 0.5190662482715993), ('potable', 0.5137930541544308), ('#pollution', 0.5053773015402238), ('biopollution', 0.504703593451706), ('undergrounds', 0.48430795952141487), ('water—', 0.47646895745070106), ('undergrounded', 0.46550011202029024), ('undergrounders', 0.4524525797301971), ('undergroun', 0.4511787727249055), ('undergroung', 0.4484747924647392), ('undergrounder', 0.44571173169707395)]\n"
     ]
    }
   ],
   "source": [
    "top = get_top_expansion_terms(test+ext, candidates,  wv_wiki_en)\n",
    "topwithout = get_top_expansion_terms(test, candidates,  wv_wiki_en)\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "top = sorted(top, key=takeSecond)[::-1]\n",
    "topw = sorted(topwithout, key=takeSecond)[::-1]\n",
    "print((top))\n",
    "print((topw))\n",
    "top = top[0:5]\n",
    "topw = topw[0:5]\n",
    "top_list = []\n",
    "for tupl in top:\n",
    "    top_list.append(tupl[0])\n",
    "topw_list = []\n",
    "for tupl in topw:\n",
    "    topw_list.append(tupl[0])\n",
    "\n",
    "top1 = get_top_expansion_terms(test1+ext1, candidates,  wv_wiki_en)\n",
    "topwithout1 = get_top_expansion_terms(test1, candidates,  wv_wiki_en)\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "top1 = sorted(top1, key=takeSecond)[::-1]\n",
    "topw1 = sorted(topwithout1, key=takeSecond)[::-1]\n",
    "top1 = top1[0:5]\n",
    "topw1 = topw1[0:5]\n",
    "top_list1 = []\n",
    "for tupl in top1:\n",
    "    top_list1.append(tupl[0])\n",
    "topw_list1 = []\n",
    "for tupl in topw1:\n",
    "    topw_list1.append(tupl[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:17.453260Z",
     "start_time": "2019-06-12T13:33:17.445772Z"
    }
   },
   "outputs": [],
   "source": [
    "# all functions together, finds k nearest for each term, returns top n\n",
    "def pre_retrieval_KNN(string, k, wv, n):\n",
    "    \"\"\"Find the most similar tokens to the given query\"\"\"\n",
    "    tokens = tokenize(string, stop_words)\n",
    "    candidates = get_candidate_expansion_terms(tokens, k, wv)\n",
    "    candidates_sim = get_top_expansion_terms(tokens, candidates, wv)\n",
    "    def takeSecond(elem):\n",
    "        return elem[1]\n",
    "    sort = sorted(candidates_sim, key=takeSecond)[::-1]\n",
    "    return sort[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:18.114793Z",
     "start_time": "2019-06-12T13:33:17.927772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('learning,', 0.5336429871558637),\n",
       " ('learnings', 0.5210396371333685),\n",
       " ('relearning', 0.509084270159704),\n",
       " ('#learning', 0.5073417997822549),\n",
       " ('learning—in', 0.5062408798333076),\n",
       " ('deeper', 0.49509854997328506),\n",
       " ('deepest', 0.42268526313403443),\n",
       " ('deeps', 0.4007843076134384),\n",
       " ('depths', 0.38366839401470537),\n",
       " ('shallow', 0.37273796552767363)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_retrieval_KNN('deep learning', 5, wv_wiki_en, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import postgresql\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.library.postgresql import PostgresQL\n",
    "# connect to the postgresql database\n",
    "pg = PostgresQL() \n",
    "pg.connect(database=\"eurlex_env_only\", user=\"postgres\", password=\"solata.2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import documents \n",
    "documents = pg.execute(\"\"\"\n",
    "    SELECT * FROM documents;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_id': 97,\n",
       " 'document_celex_num': '21987A0305(01)',\n",
       " 'document_title': 'Agreement in the form of an exchange of letters between the European Economic Community and the United States of America - Side Letters I-III',\n",
       " 'document_author': 'European Economic Community',\n",
       " 'document_form': 'International agreement',\n",
       " 'document_date': datetime.date(1986, 11, 3),\n",
       " 'document_text': '5.3.1987\\xa0\\xa0\\xa0ENOfficial Journal of the European CommunitiesL 62/23AGREEMENTin the form of an Exchange of Letters between the European Economic Community and the United States of AmericaSir,I hereby enclose the text of the Agreement between the United States and the European Community which was reached ad referendum on 10 August 1986. I believe this text includes all the necessary technical elements meeting the needs of both sides. I can confirm the acceptance of the Agreement by the United States Government, subject to the enactment of necessary legislation to implement the United States tariff concessions set out in Annex B. My Government further understands that, except as provided in footnote 3 of the Agreement, the implementation of Parts A and B of the Annex will take place simultaneously upon enactment of this necessary implementing authority.I would be grateful if you could confirm the acceptance of the Agreement by the European Community. This would then conclude the Agreement between the United States and the European Community, as set out in the enclosed text and subject to the above understandings.For the Government of the United States of AmericaBrussels,Sir,I acknowledge receipt of your letter accepting the Agreement between the United States and the European Community which we reached on 10 August 1986 of which the text is as follows:‘I hereby enclose the text of the Agreement between the United States and the European Community which was reached ad referendum on 10 August 1986. I believe this text includes all the necessary technical elements meeting the needs of both sides. I can confirm the acceptance of the Agreement by the United States Government, subject to the enactment of necessary legislation to implement the United States tariff concessions set out in Annex B. My Government further understands that, except as provided in Footnote 3 of the Agreement, the implementation of Parts A and B of the Annex will take place simultaneously upon enactment of this necessary implementing authority.I would be grateful if you could confirm the acceptance of the Agreement by the European Community. This would then conclude the Agreement between the United States and the European Community, as set out in the enclosed text and subject to the above understandings.’.I have the honour to confirm acceptance of the Agreement by the Community. This therefore concludes the Agreement between the United States and the European Community in accordance with the terms of your letter and attached text, and on the understandings contained therein.Please accept, Sir, the assurance of my highest consideration.On behalf of the Council of the European CommunitiesAGREEMENTTHE UNITED STATES AND THE EUROPEAN COMMUNITY,CONSCIOUS of the important role which continued improvements in their bilateral trading relations play in the effective working of the open multilateral trading system;and DETERMINED to settle in a mutually satisfactory way the long-standing dispute over the effects of the European Communitys preferential agreements in the Mediterranean region (referred to as ‘the Agreements’)\\xa0(1), as they pertain to access to the Community market for citrus\\xa0(2),AGREE ON THE FOLLOWING ARRANGEMENT:A.The United States recognizes that the Agreements provide important opportunities for economic development and political stability in the Mediterranean region.Consequently, the United States expresses its support for the Agreements, and agrees not to challenge them (including further preferences the European Community is prepared to grant to these countries under the additional protocols to these Agreements now under negotiation) as inconsistent with Article XXIV of the GATT.B.The United States agrees not to present additional claims in relation to Mediterranean preferences on citrus taking into account future preferential treatment on these products provided for through the additional protocols now under negotiation.Subject to the completion of internal legal procedures by both parties\\xa0(3):—the European Community will put into effect and bind in the GATT the import measures as provided for in Part A of the Annex;—the United States will put into effect and bind in the GATT the import measures as provided for in Part B of the Annex.C.On completion of internal procedures by both parties, the United States will eliminate the increase in the rates of duty on Community pasta imposed since 1 November 1985, and the Community will eliminate the increase in the rates of duty on United States lemons and walnuts applied since 4 November 1985.D.Both parties agree to proceed in good faith in seeking a prompt solution to their dispute over pasta refunds. Should a mutually satisfactory solution to the dispute not be found prior to the later of (1) United States congressional approval of the duty reductions delineated in Part B of the Annex, or (2) 1 July 1987, then either party may, at its discretion, choose not to put into effect and/or not to bind in the GATT the import measures in the Annex, as would otherwise be required by paragraph B. If the discretion not to bind in the GATT were exercised, and should the import measures in the Annex not be implemented or maintained or should new restrictions be introduced on pasta from the European Community then the other party would have the right to pursue re-negotiation of this agreement, or to terminate it.During the interim, the United States Government will refrain from initiating unilateral action against pasta from the European Community and will not pursue the GATT panel case on this product.E.The United States and the European Community agree that the Arrangement as specified above resolves definitively the dispute on citrus. On the entry into effect of this Agreement, they will both inform the GATT Council that they have resolved the citrus dispute in a mutually satisfactory way.(1)\\xa0\\xa0Algeria, Cyprus, Egypt, Israel, Jordan, Lebanon, Malta, Morocco, Syrie, Tunisia, Turkey, Yugoslavia.(2)\\xa0\\xa0For the purposes of this understanding citrus means the following products: fresh sweet oranges, fresh lemons, fresh grapefruit, fresh tangerines, orange juice, lemon juice, grapefruit juice, grapefruit segments, dry pectin.(3)\\xa0\\xa0Without prejudice to paragraph (D), as soon as the United States Government increases the Community quota for cheese falling under TSUS Item 950.10 by 1\\xa0572 metric tonnes and increases the quota for the Community (reserved Portugal) under TSUS Item 950.10 D by 353 metric tonnes, the Community will provisionally apply the autonomous trade measures laid down in the Annex for sweet oranges, minneolas and frozen concentrated orange juice. These new quotas for European Community cheese and for United States frozen concentrated orange juice will be applied pro rata on a calendar year basis.ANNEXIMPORT MEASURES REFERRED TO IN PARAGRAPH BPART A — EUROPEAN COMMUNITYTariff ItemArticleex 08.02 A ISweet oranges, high quality:The duty will be reduced to 10 % ad valorem for an aggregate quantity of 20\\xa0000 metric tonnes entered during the months of February, March and April, inclusive.ex 08.02 B IIGrapefruit hybrids known as ‘Minneolas’:The duty will be reduced to 2 % ad valorem for an aggregate quantity of 15\\xa0000 metric tonnes entered during the months of February, March and April, inclusive.08.02 CLemons:The duty will be reduced to 6 % ad valorem for an aggregate quantity of 10\\xa0000 metric tonnes entered during the period 15 January to 14 June, inclusive.08.02 DGrapefruit:The duty will be reduced to 1,5 % ad valorem during the months of November to April, inclusive.08.05 A IIAlmonds, other than bitter almonds:The duty will be reduced to 2 % ad valorem for an aggregate quantity of 45\\xa0000 metric tonnes entered in any calendar year.ex 20.06 A IGroundnuts, roasted, in immediate packings of a net capacity of more than 1 kg:The duty will be reduced to 12 % ad valorem.ex 20.06 A IIGroundnuts, roasted, in immediate packings of a net capacity of 1 kg or less:The duty will be reduced to 14 % ad valorem.ex 20.07 B II a) 1Frozen concentrated orange juice, without added sugar, having a degree of concentration of up to 50 degrees Brix, in containers of 2 litres or less, not containing blood orange concentrate:The duty will be reduced to 13 % ad valorem for an aggregate quantity of 1\\xa0500 metric tonnes, entered in any calendar year.PART B — UNITED STATESTariff ItemArticle112.40Anchovies, prepared or preserved in any manner, in oil, in airtight containers:The duty will be reduced to 3 % ad valorem for an aggregate quantity of 3\\xa0000 metric tonnes entered in any calendar year.117.55 pt.Romano made from cows milk, Reggiano, Parmesano, Provolone, and Provelette cheeses provided for in TSUS Item 950.10:The quota for the European Economic Community will be increased by 1\\xa0572 metric tonnes entered in any calendar year.117.65Cheese made from sheeps milk, in original loaves and suitable for grating:The duty will be reduced to free.117.67Pecorino cheese made from sheeps milk, in original loaves, not suitable for grating:The duty will be reduced to free.117.8855 pt.Cheeses, provided for in TSUS Item 950.10 D:The quota for the European Economic Community will be increased by the amount of cheese transferred because of the accession of Portugal, including 353 metric tonnes to be reserved for Portugal entered in any calendar year.147.29 pt.Satsumas, packed in airtight containers:The duty will be reduced to free for an aggregate quantity of 40\\xa0000 metric tonnes entered in any calendar year.148.4440 pt.Olives, in brine, not ripe and not pitted or stuffed, green in colour, in containers holding three gallons or more each to be used for re-packing or sale as green olives:The duty will be reduced to 10 cents per gallon for an aggregate quantity of 4\\xa0400 metric tonnes entered in any calendar year.148.48 pt.Olives, in brine, ripe, but not pitted or stuffed, green in colour, in containers holding five gallons or less each:The duty will be reduced to 15 cents per gallon for an aggregate quantity of 730 metric tonnes entered in any calendar year.148.5065Olives, in brine, stuffed, placed packed, in containers each holding not more than 0,3 gallon:The duty will be reduced to 15 cents per gallon for an aggregate quantity of 2\\xa0700 metric tonnes entered in any calendar year.148.52Olives, dried, not ripe:The duty will be reduced to 2,5 cents per pound.148.56.00 pt.Olives, prepared or preserved other than in brine or dried, green in colour, in containers holding five gallons or less each:The duty will be reduced to 2,5 cents per pound for an aggregate quantity of 550 metric tonnes entered in any calendar year.161.06Capers, in immediate containers holding more than 7,5 pounds:The duty will be reduced to 8 % ad valorem.161.08Capers, other:The duty will be reduced to 8 % ad valorem.161.71Paprika, ground or not round:The duty will be reduced to 1,35 cents per pound.167.15Cider, fermented, whether still or sparkling:The duty will be reduced to 1,5 cents per gallon.176.29Olive oil, weighing with the immediate container under 40 pounds:The duty will be reduced to 2,28 cents per pound on contents and container.176.30Olive oil, weighing with the immediate container 40 pounds or over:The duty will be reduced to 1,56 cents per pound.Side Letter I: from the Community to the United StatesSir,The reference to ‘future preferential treatment’ in paragraph (B) of the European Community/United States arrangement includes treatment through tariffs or tariff quotas. In addition, for the 1990 marketing year and for each subsequent year, the Commission will decide whether the entry price for certain products should be differentiated in order to maintain the traditional trade patterns as among the various Mediterranean exporting countries. Any such differentiation would be carried out within quantified limits and would not be operated so as to impair access under the European Communities/United States arrangement.Side Letter II: from the United States to the CommunitySir,I am pleased we have at long last reached an agreement which resolves the citrus dispute. I appreciate your great personal efforts and those of your team. We can take pride that our solution will liberalize trade on both sides.I understand that there has been some concern within the Community that the United States has additional claims with respect to other products beyond the citrus issue that may be brought forward now that we have resolved citrus. I am certainly not aware of any such claims at this time. Given that, over the long history of your agreements, the citrus industry is the only United States industry that has put forward claims based on the effects of European Community preferences for these Mediterranean countries, I have no expectation that we will be encountering new complaints in the foreseeable future.As you noted during our discussions, it is clear that, except as otherwise provided in our arrangement, both parties reserve their rights. If disputes should arise in the future, either from our concerns or yours, we should first seek solutions through timely consultations.Side Letter III: from the Community to the United StatesSir,With reference to paragraph (D) of the European Community/United States Agreement on Citrus/Pasta, this is to inform you that, should the United States Government be unable to fulfill the undertakings in the final sentence of the paragraph, or the United States Government actually apply new trade restrictions on European Community pasta exports, then the Commission would introduce the necessary Community procedures to terminate the Agreement.Top'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = documents\n",
    "# some docs are empty !!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# for doc in docs:\n",
    "#     idd= doc.get('document_id')\n",
    "#     if idd == 39722:\n",
    "#         print(doc)\n",
    "\n",
    "delete = []\n",
    "for doc in docs:\n",
    "    n = len(doc.get('document_text'))\n",
    "    if n == 0:\n",
    "        id_doc = doc.get('document_id')\n",
    "        delete.append(id_doc)\n",
    "            \n",
    "# remove empty docs\n",
    "for doc in docs:\n",
    "    id_doc = doc.get('document_id')\n",
    "    if id_doc in delete:\n",
    "        docs.remove(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81992\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tokenzized documents (texts), texts, tokenzized titles and titles\n",
    "tokenized_docs = {}\n",
    "tokenized_titles = {}\n",
    "texts = {}\n",
    "titles = {}\n",
    "for document in docs:\n",
    "    doc_id = document.get('document_id')\n",
    "    text = document.get('document_text')\n",
    "    texts.update({doc_id: text})\n",
    "    title = document.get('document_title')\n",
    "    titles.update({doc_id: title})\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized = tokenize(text, stop_words)\n",
    "    title = title.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized_title = tokenize(title, stop_words)\n",
    "    for token in tokenized:\n",
    "        if len(token) == 1:\n",
    "            if token.isalpha():\n",
    "                tokenized.remove(token)\n",
    "    tokenized_docs.update({doc_id: tokenized})\n",
    "    for title in tokenized_title:\n",
    "        if len(title) == 1:\n",
    "            if title.isalpha():\n",
    "                tokenized_title.remove(title)\n",
    "    tokenized_titles.update({doc_id: tokenized_title})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agreement', 'relating', 'principally', 'chemicals', 'supplementary', 'geneva', '1967', 'protocol', 'general', 'agreement', 'tariffs', 'trade', 'negotiated', 'geneva', '30', 'june', '1967']\n",
      "/* Agreement relating principally to chemicals, supplementary to the Geneva (1967) Protocol to the General Agreement on Tariffs and Trade, negotiated in Geneva on 30 June 1967 */\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenized_titles.get(3))\n",
    "print(titles.get(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_docs.get(39703))\n",
    "print(texts.get(39703))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81992\n",
      "5731\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_docs))\n",
    "#print(take(1, tokenized_docs.items()))\n",
    "empt=[]\n",
    "for k,v in tokenized_docs.items():\n",
    "    l =len(v)\n",
    "    if l==0:\n",
    "        empt.append(k)\n",
    "print(len(empt))\n",
    "#print((empt))\n",
    "\n",
    "for k in empt:\n",
    "    del tokenized_docs[k]\n",
    "    del tokenized_titles[k]\n",
    "    del texts[k]\n",
    "    del titles[k]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76261\n",
      "76261\n",
      "76261\n",
      "76261\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_docs))\n",
    "print(len(tokenized_titles))\n",
    "print(len(texts))\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs1 = {}\n",
    "tokenized_titles1 = {}\n",
    "texts1= {}\n",
    "titles1={}\n",
    "for k in range(1,1000):\n",
    "    vtd = tokenized_docs.get(k)\n",
    "    vtt = tokenized_titles.get(k)\n",
    "    vx = texts.get(k)\n",
    "    vt =titles.get(k)\n",
    "    tokenized_docs1.update({k:vtd})\n",
    "    tokenized_titles1.update({k:vtt})\n",
    "    texts1.update({k:vx})\n",
    "    titles1.update({k:vt})\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "999\n",
      "999\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_docs1))\n",
    "print(len(tokenized_titles1))\n",
    "print(len(texts1))\n",
    "print(len(titles1))\n",
    "tokenized_docs1 = {k:v for k,v in tokenized_docs1.items() if v is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### search full words (not lemmatized), search as substrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. probability scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability scoring\n",
    "### all query words have to be in the document (multiplying)\n",
    "\n",
    "def probab_score(tokens,tokenized_docs,texts):\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 1\n",
    "        text = texts.get(k)\n",
    "        for token in tokens:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability*(token_frequency/n)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(120739, 2.2778939503692463e-06), (90952, 1.4623827626019007e-06), (98346, 9.60986510312026e-07), (100875, 9.116079910329329e-07), (96934, 7.795624765214125e-07), (98891, 4.7381201508301593e-07), (99214, 4.374815382790846e-07), (53800, 2.5508770567849454e-07), (101429, 2.4695734439852766e-07), (101872, 2.433802400069899e-07)]\n",
      "[]\n",
      "[(72, 4.866706628529354e-11), (4098, 3.9980157168428714e-11), (31030, 1.0620609744608273e-11), (85, 6.56566844179315e-12), (47616, 4.413577090077561e-12), (59689, 3.662677012225006e-12), (2146, 2.529433698703274e-12), (25303, 2.2094496103487563e-12), (57414, 2.1926876323265894e-12), (31131, 1.3631354904463345e-12)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# only original query\n",
    "score =probab_score(test,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "print(sorted_positives_top)\n",
    "\n",
    "# original query + extension\n",
    "score =probab_score(test+ext,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "print(([(k,v) for k,v in score.items() if v > 0]))\n",
    "\n",
    "\n",
    "# only original query\n",
    "score =probab_score(test1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "print(sorted_positives_top)\n",
    "\n",
    "# original query + extension\n",
    "score =probab_score(test1+ext1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "print(([(k,v) for k,v in score.items() if v > 0]))\n",
    "\n",
    "\n",
    "# no point having an extention, empty results are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no point having an extention, empty results are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titles.get(80))\n",
    "# print(texts.get(80))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "## query words summation\n",
    "def probab_score_sum(tokens,tokenized_docs,texts):\n",
    "    '''assigns score to document based on summation of probabilities'''\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        text = texts.get(k)\n",
    "        for token in tokens:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability+(token_frequency/n)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zavedaj se:\n",
    "\"gabla is bla2\".count(\"bla\")\n",
    "# kar pomeni da bi bilo bolje uporabiti lemmatized words! popravi!! neke stvari zdaj 2x stejes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_positives(dictionary,n):\n",
    "    \"\"\"Takes dict and returns first n tuples of k,v sorted by v\"\"\"\n",
    "    positives = {} \n",
    "    for k,v in dictionary.items():\n",
    "        if v > 0:\n",
    "            positives.update({k: v})\n",
    "    sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "    sorted_positives_top = sorted_positives[0:n]\n",
    "    return sorted_positives_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n"
     ]
    }
   ],
   "source": [
    "# only original query\n",
    "score_sum =probab_score_sum(test,tokenized_docs,texts)\n",
    "\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>0.116567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>0.111821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>0.106627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>0.105425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30565</td>\n",
       "      <td>0.103206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36068</td>\n",
       "      <td>0.103186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3867</td>\n",
       "      <td>0.102941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94467</td>\n",
       "      <td>0.098425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38921</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original     score\n",
       "0            32476  0.116567\n",
       "1            33546  0.111821\n",
       "2            37122  0.106627\n",
       "3            34869  0.105425\n",
       "4            30565  0.103206\n",
       "5            36068  0.103186\n",
       "6             3867  0.102941\n",
       "7            95196  0.099099\n",
       "8            94467  0.098425\n",
       "9            38921  0.097561"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df_sum_original = pd.DataFrame(sorted_positives_top, columns =['id_sum_original', 'score'])\n",
    "df_sum_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titles.get(565))\n",
    "# print(texts.get(565))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n"
     ]
    }
   ],
   "source": [
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test+ext,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df_sum_original_ext = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n",
      "[(94870, 0.1276595744680851), (11790, 0.09090909090909091), (100258, 0.08527131782945736), (97436, 0.08280254777070063), (28599, 0.08163833937029813), (92702, 0.07514450867052024), (97265, 0.07430340557275542), (50112, 0.07235621521335807), (62459, 0.07103825136612021), (49539, 0.07056113902847572)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>0.085271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>0.082803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>0.081638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>0.075145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>0.074303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>0.072356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>0.071038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>0.070561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original1     score\n",
       "0             94870  0.127660\n",
       "1             11790  0.090909\n",
       "2            100258  0.085271\n",
       "3             97436  0.082803\n",
       "4             28599  0.081638\n",
       "5             92702  0.075145\n",
       "6             97265  0.074303\n",
       "7             50112  0.072356\n",
       "8             62459  0.071038\n",
       "9             49539  0.070561"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only original query\n",
    "score =probab_score(test1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score,10)\n",
    "print(sorted_positives_top)\n",
    "\n",
    "\n",
    "\n",
    "## original query\n",
    "score_sum =probab_score_sum(test1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original1', 'score'])\n",
    "df_sum_original1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original_ext1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92702</td>\n",
       "      <td>0.121387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93604</td>\n",
       "      <td>0.116959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97781</td>\n",
       "      <td>0.114583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93549</td>\n",
       "      <td>0.104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14571</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97436</td>\n",
       "      <td>0.101911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100258</td>\n",
       "      <td>0.100775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44382</td>\n",
       "      <td>0.100151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98394</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original_ext1     score\n",
       "0                 94870  0.127660\n",
       "1                 92702  0.121387\n",
       "2                 93604  0.116959\n",
       "3                 97781  0.114583\n",
       "4                 93549  0.104348\n",
       "5                 14571  0.102041\n",
       "6                 97436  0.101911\n",
       "7                100258  0.100775\n",
       "8                 44382  0.100151\n",
       "9                 98394  0.099099"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test1+ext1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score_sum.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "#dataframe\n",
    "df_sum_original_ext1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext1', 'score'])\n",
    "df_sum_original_ext1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12744, 0.15163934426229508), (92986, 0.1473429951690821), (92988, 0.14669421487603304), (9649, 0.13286713286713286), (93921, 0.11695906432748537), (32476, 0.11656671664167916), (62937, 0.11578947368421053), (94936, 0.11494252873563218), (97319, 0.11363636363636363), (95196, 0.11261261261261261)]\n",
      "[(94936, 0.12643678160919541), (3453, 0.11875000000000001), (32476, 0.11656671664167916), (97319, 0.11363636363636363), (33546, 0.11182108626198083), (95196, 0.10810810810810811), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686)]\n",
      "[(94870, 0.1276595744680851), (11790, 0.09090909090909091), (100258, 0.08527131782945736), (97436, 0.08280254777070063), (28599, 0.08163833937029813), (92702, 0.07514450867052024), (97265, 0.07430340557275542), (50112, 0.07235621521335807), (62459, 0.07103825136612021), (49539, 0.07056113902847572)]\n",
      "[(94870, 0.1276595744680851), (92702, 0.12138728323699421), (93604, 0.11695906432748537), (97781, 0.11458333333333334), (93549, 0.10434782608695653), (14571, 0.10204081632653061), (97436, 0.1019108280254777), (100258, 0.10077519379844961), (44382, 0.10015060240963855), (98394, 0.0990990990990991)]\n"
     ]
    }
   ],
   "source": [
    "# adding candidates\n",
    "## without weights\n",
    "# no point using multiplication\n",
    "\n",
    "# summation:\n",
    "## original query\n",
    "score_sum =probab_score_sum(test+topw_list,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_cand = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_cand', 'score'])\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test+ext+top_list,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_ext_cand = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext_cand', 'score'])\n",
    "\n",
    "\n",
    "## original query\n",
    "score_sum =probab_score_sum(test1+topw_list1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_cand1', 'score'])\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test1+ext1+top_list1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_ext_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext_cand1', 'score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_value(word, alpha, original_tokens, top_expansion, wv):\n",
    "    \"\"\"values word based on whether is in original token set or expanded, if alpha -1 value equals to cosine similarity\"\"\"\n",
    "    only_expanded = []\n",
    "    for token in top_expansion:\n",
    "        if token not in original_tokens:\n",
    "            only_expanded.append(token)\n",
    "            \n",
    "    sum_similarity = 0\n",
    "    for exp_token in only_expanded:\n",
    "            sum_similarity += similarity(exp_token,original_tokens, wv)\n",
    "            \n",
    "    if alpha == -1:\n",
    "        if word in original_tokens:\n",
    "            value = 1\n",
    "        else:\n",
    "            value = similarity(word, original_tokens, wv)/sum_similarity\n",
    "\n",
    "\n",
    "    else:\n",
    "        if word in original_tokens:\n",
    "            value = alpha\n",
    "        else:\n",
    "            value = (1-alpha)*similarity(word, original_tokens, wv)/sum_similarity\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "0.28172557133553994\n",
      "0.7\n",
      "0.2714117961536774\n"
     ]
    }
   ],
   "source": [
    "# ce ni ext zraven je so cudni rezultati, zamenja vrstni red pomembnsti med sewage in undergrounding??\n",
    "top = top[0:4]\n",
    "top_words = [i[0] for i in top]\n",
    "print(word_value(\"water\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"sewage\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"undergrounding\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"biopollution\", 0.7, test+ext ,top_words, wv_wiki_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probab_score_sum_weights(original_tokens, top_expansion,tokenized_docs,texts, wv, alpha): \n",
    "    '''As probab_score_sum only weighted; usually extention added to original tokens, candidates = top_expansion - have weights'''\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        text = texts.get(k)\n",
    "        for token in original_tokens+top_expansion:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability+(token_frequency/n)*word_value(token, alpha, original_tokens, top_expansion, wv)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.330910250229159,\n",
       " 0.319089749770841]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check word values\n",
    "wvals = []\n",
    "for token in test+ext+top_list:\n",
    "    wvals.append(word_value(token, 0.35, test+ext, top_list, wv_wiki_en))\n",
    "wvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check word frequences\n",
    "n = len(tokenized_docs1)\n",
    "print(n)\n",
    "t_freqs = []\n",
    "for k, v in tokenized_docs1.items():\n",
    "    n = len(v)\n",
    "    text = texts1.get(k)\n",
    "    for token in test+ext+top_list:\n",
    "        token_frequency = text.count(token)\n",
    "        t_freqs.append(token_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with weights\n",
    "# summation \n",
    "original_query_cand = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    ## original query\n",
    "    score_sum = probab_score_sum_weights(test, topw_list,tokenized_docs, texts, wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_cand = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_cand.append(df_wsum_original_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original query plus ext\n",
    "original_query_ext_cand = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum =probab_score_sum_weights(test+ext, top_list,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_ext_cand = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_ext_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_ext_cand.append(df_wsum_original_ext_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sorting for each alpha\n",
    "doubleframes =[]\n",
    "for i in range(len(original_query_cand)):\n",
    "    frst = original_query_cand[i].take([0], axis=1)\n",
    "    snd = original_query_ext_cand[i].take([0], axis=1)\n",
    "    con = pd.concat([frst,snd], axis=1)\n",
    "    doubleframes.append(con)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand0.7</th>\n",
       "      <th>id_wsum_original_ext_cand0.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37122</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3453</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand0.7  id_wsum_original_ext_cand0.7\n",
       "0                     32476                         94936\n",
       "1                     94936                         32476\n",
       "2                     97319                         97319\n",
       "3                     33546                         33546\n",
       "4                     95196                          3453\n",
       "5                     37122                         95196\n",
       "6                      3453                         37122\n",
       "7                     34869                         34869\n",
       "8                     30565                         30565\n",
       "9                     36068                         36068"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleframes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand0.5</th>\n",
       "      <th>id_wsum_original_cand0.6</th>\n",
       "      <th>id_wsum_original_cand0.7</th>\n",
       "      <th>id_wsum_original_cand0.8</th>\n",
       "      <th>id_wsum_original_cand0.9</th>\n",
       "      <th>id_wsum_original_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92988</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95196</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12744</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37122</td>\n",
       "      <td>92988</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3453</td>\n",
       "      <td>34869</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92986</td>\n",
       "      <td>12744</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand0.5  id_wsum_original_cand0.6  \\\n",
       "0                     32476                     32476   \n",
       "1                     94936                     94936   \n",
       "2                     97319                     97319   \n",
       "3                     33546                     33546   \n",
       "4                     92988                     95196   \n",
       "5                     95196                     37122   \n",
       "6                     12744                      3453   \n",
       "7                     37122                     92988   \n",
       "8                      3453                     34869   \n",
       "9                     92986                     12744   \n",
       "\n",
       "   id_wsum_original_cand0.7  id_wsum_original_cand0.8  \\\n",
       "0                     32476                     32476   \n",
       "1                     94936                     94936   \n",
       "2                     97319                     97319   \n",
       "3                     33546                     33546   \n",
       "4                     95196                     95196   \n",
       "5                     37122                     37122   \n",
       "6                      3453                      3453   \n",
       "7                     34869                     34869   \n",
       "8                     30565                     30565   \n",
       "9                     36068                     36068   \n",
       "\n",
       "   id_wsum_original_cand0.9  id_wsum_original_cand1  \n",
       "0                     32476                   32476  \n",
       "1                     94936                   94936  \n",
       "2                     97319                   97319  \n",
       "3                     33546                   33546  \n",
       "4                     95196                   95196  \n",
       "5                     37122                   37122  \n",
       "6                      3453                    3453  \n",
       "7                     34869                   34869  \n",
       "8                     30565                   30565  \n",
       "9                     36068                   36068  "
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_cand)):\n",
    "    dataf = original_query_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "con = pd.concat(frames, axis=1)\n",
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first 4 rows same values\n",
    "- 5.,6.,7. row only values for alpha 0.5 different\n",
    "- lower than 7. row: values for 0.5 and 0.6 different\n",
    "- half of values lower than 4.place on alpha 0.5 also appear in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_ext_cand-1</th>\n",
       "      <th>id_wsum_original_ext_cand0.35</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.45</th>\n",
       "      <th>id_wsum_original_ext_cand0.5</th>\n",
       "      <th>id_wsum_original_ext_cand0.6</th>\n",
       "      <th>id_wsum_original_ext_cand0.7</th>\n",
       "      <th>id_wsum_original_ext_cand0.8</th>\n",
       "      <th>id_wsum_original_ext_cand0.9</th>\n",
       "      <th>id_wsum_original_ext_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32476</td>\n",
       "      <td>3453</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>32476</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3453</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>3453</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_ext_cand-1  id_wsum_original_ext_cand0.35  \\\n",
       "0                        94936                          94936   \n",
       "1                        32476                           3453   \n",
       "2                        97319                          32476   \n",
       "3                         3453                          97319   \n",
       "4                        33546                          33546   \n",
       "5                        95196                          95196   \n",
       "6                        37122                          37122   \n",
       "7                        34869                          34869   \n",
       "8                        30565                          30565   \n",
       "9                        36068                          36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.4  id_wsum_original_ext_cand0.45  \\\n",
       "0                         94936                          94936   \n",
       "1                         32476                          32476   \n",
       "2                          3453                           3453   \n",
       "3                         97319                          97319   \n",
       "4                         33546                          33546   \n",
       "5                         95196                          95196   \n",
       "6                         37122                          37122   \n",
       "7                         34869                          34869   \n",
       "8                         30565                          30565   \n",
       "9                         36068                          36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.5  id_wsum_original_ext_cand0.6  \\\n",
       "0                         94936                         94936   \n",
       "1                         32476                         32476   \n",
       "2                         97319                         97319   \n",
       "3                          3453                         33546   \n",
       "4                         33546                          3453   \n",
       "5                         95196                         95196   \n",
       "6                         37122                         37122   \n",
       "7                         34869                         34869   \n",
       "8                         30565                         30565   \n",
       "9                         36068                         36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.7  id_wsum_original_ext_cand0.8  \\\n",
       "0                         94936                         32476   \n",
       "1                         32476                         94936   \n",
       "2                         97319                         97319   \n",
       "3                         33546                         33546   \n",
       "4                          3453                         95196   \n",
       "5                         95196                          3453   \n",
       "6                         37122                         37122   \n",
       "7                         34869                         34869   \n",
       "8                         30565                         30565   \n",
       "9                         36068                         36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.9  id_wsum_original_ext_cand1  \n",
       "0                         32476                       32476  \n",
       "1                         94936                       94936  \n",
       "2                         97319                       97319  \n",
       "3                         33546                       33546  \n",
       "4                         95196                       95196  \n",
       "5                          3453                       37122  \n",
       "6                         37122                        3453  \n",
       "7                         34869                       34869  \n",
       "8                         30565                       30565  \n",
       "9                         36068                       36068  "
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original +ext + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_ext_cand)):\n",
    "    dataf = original_query_ext_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "conex = pd.concat(frames, axis=1)\n",
    "conex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n",
      "['pollution', 'pollutions', 'undergrounding', 'earpollution', 'pollution,']\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(ext)\n",
    "print(top_list)\n",
    "# 94936 light pollution -, 32476 fishing quotas o, 97319 light pollution - , 3453 marine pollution o\n",
    "# without weighted sum (below): \n",
    "# 32476 already appeared, 33546 fishing quotas o,37122 fishing quotas o,12744 groundwater protection +,92988 groundwater protection +\n",
    "# id_sum_original_cand best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E1894WRITTEN QUESTION No. 1894/97 by Amedeo AMADEO to the Commission. Integrated groundwater protection and managementOfficial Journal C 021 , 22/01/1998 P. 0113 WRITTEN QUESTION E-1894/97 by Amedeo Amadeo (NI) to the Commission (4 June 1997)Subject: Integrated groundwater protection and managementThe Commission Proposal for a European Parliament and Council Decision on an action programme for integrated groundwater protection and management (COM(96) 0315 final - 96/0181 COD) ((OJ C 355, 25.11.1996, p. 1. ))sets out an action programme comprising four main lines of action: planning and management of groundwater protection, creating a regulatory framework for fresh water abstraction, development of instruments for control of groundwater pollution from diffuse sources and development of instruments for control of point source emissions and discharges.Where groundwater pollution from diffuse sources is concerned, will the Commission pay particular attention to cleaning up soil contaminated by long-standing or accidental pollution, bearing in mind that a Community frame of reference is needed concerning responsibilities and the financing of the measures?Will the Commission turn its attention to the fact that many Member States have failed to announce measures to transpose Directive 91/676/EEC ((OJ L 375, 31.12.1991, p. 1. )) on nitrates? Will it also impose official controls on the substances contained in recycled sewage sludge and consider the advisability of imposing more stringent limit values on atmospheric emissions of substances which contribute to acidification?Answer given by Mrs Bjerregaard on behalf of the Commission (8 July 1997)The objective of the proposal for a Parliament and Council decision on an action programme for integrated groundwater protection and management is to ensure that protection and use of groundwater takes place as part of an integrated management of fresh water resources and that groundwaters on a long term basis will be managed with surface waters within a river basin management approach.In February 1997 the Commission adopted a proposal for a Council directive establishing a framework for Community action in the field of water policy ((COM(97) 49 final. )) which lays down the basic principles for integrated protection and use of groundwaters and surface waters within such a river basin management approach. Whilst part of the actions presented in the proposed groundwater action programme may be pursued through a variety of instruments, some may be strengthened through appropriate legal provisions. The proposed water framework directive is intended as a framework within which inter alia the protection and sustainable use of groundwater may be ensured through such legal provisions.Civil liability for damage caused to soil and groundwater by pollution is not addressed in the proposed groundwater action programme. Appropriate Community action on this particular question is considered in a white paper being prepared by the Commission for presentation by early 1998. However, the proposed groundwater action programme requests Member States to take appropriate action towards contaminated groundwaters to ensure containment of such contaminated groundwaters in order to prevent further contamination, and where appropriate to restore such groundwaters.Contamination of groundwaters may arise from a variety of point and diffuse sources. The proposed groundwater action programme requests the identification of such potential sources. Control of point source pollution has improved considerably through the adoption of Community environment legislation, while diffuse source pollution still calls for better control. The Honourable Member identifies the diffuse sources of nitrates from agricultural use, dangerous substances contained in recycled sewage sludge and acid precipitation. Nitrates pollution from agriculture is regulated through Council Directive 91/676/EEC of 12 December 1991 concerning the protection of waters against pollution caused by nitrates from agricultural sources ((OJ L 375, 31.12.1991. )). Unfortunately, not all Member States have implemented this Directive fully and the Commission is pursuing this lack of implementation through appropriate action including action under Article 169 of the EC Treaty. Control of dangerous substances in sewage sludge is regulated through Council Directive 86/278/EEC of 12 June 1986 on the protection of the environment, and in particular of the soil, when sewage sludge is used in agriculture ((OJ L 181, 4.7.1986. )). Acidification due to atmospheric deposition is addressed through a number of Council directives primarily addressing sources of air pollution, inter alia nitrogen oxides and sulphur oxides emitted from combustion plants, car emissions and incineration of hazardous waste. The basic principles of a common strategy towards air pollution are defined in Council Directive 96/62/EC of 27 September 1996 on ambient air quality assessment and management ((OJ L 296, 21.11.1996. )). As a follow up to this, the Commission adopted a communication to the Council and the Parliament in March 1997 presenting a strategy towards acidification ((COM(97) 88 final. )). Top'"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(92988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-546-2dae7cdd841d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0moriginal_query_ext_cand1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.45\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mscore_sum\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mprobab_score_sum_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mext1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_list1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenized_docs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mwv_wiki_en\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#original + ext gives same score, add global and state gives different score, same order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#how many docs have positive score?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-518-d0a8cb7d338c>\u001b[0m in \u001b[0;36mprobab_score_sum_weights\u001b[1;34m(original_tokens, top_expansion, tokenized_docs, texts, wv, alpha)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moriginal_tokens\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtop_expansion\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mtoken_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mprobability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_frequency\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mword_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_expansion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mdoc_probab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdoc_probab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-511-bf7f02e684f2>\u001b[0m in \u001b[0;36mword_value\u001b[1;34m(word, alpha, original_tokens, top_expansion, wv)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msum_similarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mexp_token\u001b[0m \u001b[1;32min\u001b[0m \u001b[0monly_expanded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0msum_similarity\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_token\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-a6f8246ca9ed>\u001b[0m in \u001b[0;36msimilarity\u001b[1;34m(token, token_list, wv)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtoks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mnum_of_tokens\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0msimilarity\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_of_tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\envirolens\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m         \"\"\"\n\u001b[1;32m--> 828\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test1:\n",
    "## original query\n",
    "original_query_cand1 = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum = probab_score_sum_weights(test1, topw_list1,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_cand1'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_cand1.append(df_wsum_original_cand1)\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "original_query_ext_cand1 = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum =probab_score_sum_weights(test1+ext1, top_list1,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_ext_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_ext_cand1'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_ext_cand1.append(df_wsum_original_ext_cand1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sorting for each alpha\n",
    "doubleframes1 =[]\n",
    "for i in range(len(original_query_cand1)):\n",
    "    frst = original_query_cand1[i].take([0], axis=1)\n",
    "    snd = original_query_ext_cand1[i].take([0], axis=1)\n",
    "    con = pd.concat([frst,snd], axis=1)\n",
    "    doubleframes1.append(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand10.5</th>\n",
       "      <th>id_wsum_original_ext_cand10.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand10.5  id_wsum_original_ext_cand10.5\n",
       "0                      94870                          94870\n",
       "1                      11790                          92702\n",
       "2                     100258                          93604\n",
       "3                      97436                          97781\n",
       "4                      28599                          93549\n",
       "5                      92702                          14571\n",
       "6                      97265                          97436\n",
       "7                      50112                         100258\n",
       "8                      62459                          44382\n",
       "9                      49539                          98394"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleframes1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand10.5</th>\n",
       "      <th>id_wsum_original_cand10.6</th>\n",
       "      <th>id_wsum_original_cand10.7</th>\n",
       "      <th>id_wsum_original_cand10.8</th>\n",
       "      <th>id_wsum_original_cand10.9</th>\n",
       "      <th>id_wsum_original_cand11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand10.5  id_wsum_original_cand10.6  \\\n",
       "0                      94870                      94870   \n",
       "1                      11790                      11790   \n",
       "2                     100258                     100258   \n",
       "3                      97436                      97436   \n",
       "4                      28599                      28599   \n",
       "5                      92702                      92702   \n",
       "6                      97265                      97265   \n",
       "7                      50112                      50112   \n",
       "8                      62459                      62459   \n",
       "9                      49539                      49539   \n",
       "\n",
       "   id_wsum_original_cand10.7  id_wsum_original_cand10.8  \\\n",
       "0                      94870                      94870   \n",
       "1                      11790                      11790   \n",
       "2                     100258                     100258   \n",
       "3                      97436                      97436   \n",
       "4                      28599                      28599   \n",
       "5                      92702                      92702   \n",
       "6                      97265                      97265   \n",
       "7                      50112                      50112   \n",
       "8                      62459                      62459   \n",
       "9                      49539                      49539   \n",
       "\n",
       "   id_wsum_original_cand10.9  id_wsum_original_cand11  \n",
       "0                      94870                    94870  \n",
       "1                      11790                    11790  \n",
       "2                     100258                   100258  \n",
       "3                      97436                    97436  \n",
       "4                      28599                    28599  \n",
       "5                      92702                    92702  \n",
       "6                      97265                    97265  \n",
       "7                      50112                    50112  \n",
       "8                      62459                    62459  \n",
       "9                      49539                    49539  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_cand1)):\n",
    "    dataf = original_query_cand1[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "con1 = pd.concat(frames, axis=1)\n",
    "con1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n",
      "['earpollution', 'pollution', 'pollutants', 'biopollution', 'potable']\n"
     ]
    }
   ],
   "source": [
    "print(test1)\n",
    "print(ext1)\n",
    "print(top_list1)\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E3072WRITTEN QUESTION No. 3072/97 by Amedeo AMADEO to the Commission. Environmental agreementsOfficial Journal C 117 , 16/04/1998 P. 0146 WRITTEN QUESTION E-3072/97 by Amedeo Amadeo (NI) to the Commission (2 October 1997)Subject: Environmental agreementsThe main objective of the Commissions communication on environmental agreements (COM(96) 561 final) is to promote and facilitate the use of effective and acceptable environmental agreements. These agreements are instruments for the integration or implementation of environment law in the Community. The communication should be seen in the light of the strategy outlined in the fifth action programme to extend the range of environment policy instruments and put into practice the concept of shared responsibility.The communication also seeks to clarify certain aspects of how environmental agreements can be used to implement certain provisions of Community directives in the Member States and how environmental agreements can be used at Community level.Does the Commission recommendation on environmental agreements refer only to their transposal into national law or does it also cover the application of the provisions once transposed?Answer given by Mrs Bjerregaard on behalf of the Commission (31 October 1997)The Commission Recommendation concerning environmental agreements implementing Community directives ((OJ L 333, 21.12.1996. )) not only concerns the transposition of certain provisions of directives into national law but also the implementation of the transposed law. The word implementation includes both the transposition into national law and the application of the transposed provisions. Clearly, where national legislation is in place to ensure compliance with a directive, the form of implementing these rules is less important. Nevertheless, the Commission considers the legal status of agreements as an important element of their success and therefore recommends that they be concluded in a legally-binding form. Top'"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(93604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original</th>\n",
       "      <th>id_sum_original_cand</th>\n",
       "      <th>id_sum_original_ext</th>\n",
       "      <th>id_sum_original_ext_cand</th>\n",
       "      <th>id_wsum_original_cand0.7</th>\n",
       "      <th>id_wsum_original_ext_cand0.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>92986</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>92988</td>\n",
       "      <td>37122</td>\n",
       "      <td>32476</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>9649</td>\n",
       "      <td>34869</td>\n",
       "      <td>97319</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30565</td>\n",
       "      <td>93921</td>\n",
       "      <td>30565</td>\n",
       "      <td>33546</td>\n",
       "      <td>95196</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36068</td>\n",
       "      <td>32476</td>\n",
       "      <td>36068</td>\n",
       "      <td>95196</td>\n",
       "      <td>37122</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3867</td>\n",
       "      <td>62937</td>\n",
       "      <td>3867</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>94936</td>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94467</td>\n",
       "      <td>97319</td>\n",
       "      <td>94467</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38921</td>\n",
       "      <td>95196</td>\n",
       "      <td>38921</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original  id_sum_original_cand  id_sum_original_ext  \\\n",
       "0            32476                 12744                32476   \n",
       "1            33546                 92986                33546   \n",
       "2            37122                 92988                37122   \n",
       "3            34869                  9649                34869   \n",
       "4            30565                 93921                30565   \n",
       "5            36068                 32476                36068   \n",
       "6             3867                 62937                 3867   \n",
       "7            95196                 94936                95196   \n",
       "8            94467                 97319                94467   \n",
       "9            38921                 95196                38921   \n",
       "\n",
       "   id_sum_original_ext_cand  id_wsum_original_cand0.7  \\\n",
       "0                     94936                     32476   \n",
       "1                      3453                     94936   \n",
       "2                     32476                     97319   \n",
       "3                     97319                     33546   \n",
       "4                     33546                     95196   \n",
       "5                     95196                     37122   \n",
       "6                     37122                      3453   \n",
       "7                     34869                     34869   \n",
       "8                     30565                     30565   \n",
       "9                     36068                     36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.7  \n",
       "0                         94936  \n",
       "1                         32476  \n",
       "2                         97319  \n",
       "3                         33546  \n",
       "4                          3453  \n",
       "5                         95196  \n",
       "6                         37122  \n",
       "7                         34869  \n",
       "8                         30565  \n",
       "9                         36068  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of summation method versions on test set\n",
    "frms = [df_sum_original[\"id_sum_original\"], df_sum_original_cand[\"id_sum_original_cand\"], df_sum_original_ext['id_sum_original_ext'],df_sum_original_ext_cand['id_sum_original_ext_cand'],doubleframes[2]]\n",
    "sum_result = pd.concat(frms, axis=1)\n",
    "sum_result\n",
    "# error ker wsum samo se z alphami e.g. wsum0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 6, 95196: 6, 33546: 5, 37122: 5, 34869: 5, 30565: 5, 36068: 5, 94936: 4, 97319: 4, 3453: 3, 3867: 2, 94467: 2, 38921: 2, 12744: 1, 92986: 1, 92988: 1, 9649: 1, 93921: 1, 62937: 1})\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "values = sum_result.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- same results for sum original and sum original_ext\n",
    "- slight diff. between original cand and original ext cand in wsum  \n",
    " --> ext impacts on cand  \n",
    "- for top 5 only difference between using cand or not\n",
    "- 5. and 6. place id different wether ext is used or not\n",
    "- 9. place differs in column sum original cand\n",
    "- 8 values occures in all cases, so max 2 differ for each list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original1</th>\n",
       "      <th>id_sum_original_cand1</th>\n",
       "      <th>id_sum_original_ext1</th>\n",
       "      <th>id_sum_original_ext_cand1</th>\n",
       "      <th>id_wsum_original_cand10.7</th>\n",
       "      <th>id_wsum_original_ext_cand10.7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original1  id_sum_original_cand1  id_sum_original_ext1  \\\n",
       "0             94870                  94870                 94870   \n",
       "1             11790                  11790                 92702   \n",
       "2            100258                 100258                 93604   \n",
       "3             97436                  97436                 97781   \n",
       "4             28599                  28599                 93549   \n",
       "5             92702                  92702                 14571   \n",
       "6             97265                  97265                 97436   \n",
       "7             50112                  50112                100258   \n",
       "8             62459                  62459                 44382   \n",
       "9             49539                  49539                 98394   \n",
       "\n",
       "   id_sum_original_ext_cand1  id_wsum_original_cand10.7  \\\n",
       "0                      94870                      94870   \n",
       "1                      92702                      11790   \n",
       "2                      93604                     100258   \n",
       "3                      97781                      97436   \n",
       "4                      93549                      28599   \n",
       "5                      14571                      92702   \n",
       "6                      97436                      97265   \n",
       "7                     100258                      50112   \n",
       "8                      44382                      62459   \n",
       "9                      98394                      49539   \n",
       "\n",
       "   id_wsum_original_ext_cand10.7  \n",
       "0                          94870  \n",
       "1                          92702  \n",
       "2                          93604  \n",
       "3                          97781  \n",
       "4                          93549  \n",
       "5                          14571  \n",
       "6                          97436  \n",
       "7                         100258  \n",
       "8                          44382  \n",
       "9                          98394  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of summation method versions on test1 set\n",
    "frames = [df_sum_original1[\"id_sum_original1\"], df_sum_original_cand1[\"id_sum_original_cand1\"], df_sum_original_ext1['id_sum_original_ext1'],df_sum_original_ext_cand1['id_sum_original_ext_cand1'],doubleframes1[2]]\n",
    "sum_result1 = pd.concat(frames, axis=1)\n",
    "sum_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94870: 6, 92702: 6, 100258: 6, 97436: 6, 11790: 3, 93604: 3, 97781: 3, 28599: 3, 93549: 3, 14571: 3, 97265: 3, 50112: 3, 62459: 3, 44382: 3, 49539: 3, 98394: 3})\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "values = sum_result1.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter1=collections.Counter(flat_vals)\n",
    "print((counter1))\n",
    "print(len(counter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- same results for all without ext and all with ext\n",
    "- rows do not match\n",
    "- 9 values appear in all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first 5 returned docs no difference between weighted and unweighted for alpha = 0.6,  alpha = 0.8, 1 #if all weight the same is same as\n",
    "# if expansion would not exist\n",
    "# only tokens / tokens + ext\n",
    "# [(99, 0.048582995951417005), (380, 0.046610169491525424), (244, 0.04477611940298507), (89, 0.04371584699453552), (376, 0.04034065441506051)]\n",
    "# [(244, 0.08955223880597014), (243, 0.08), (903, 0.04964539007092198), (99, 0.048582995951417005), (380, 0.046610169491525424)]\n",
    "# unweighted with candidate exp:\n",
    "# [(565, 0.048730964467005075), (1219, 0.0461864406779661), (12, 0.04042348411934552), (226, 0.039756782039289056), (22, 0.03749147920927062)]\n",
    "# [(565, 0.05177664974619289), (1219, 0.04745762711864407), (12, 0.04138594802694899), (226, 0.04069223573433115), (22, 0.03953646898432175)]\n",
    "# [(99, 0.048582995951417005), (380, 0.046610169491525424), (244, 0.04477611940298507), (89, 0.04371584699453552), (376, 0.04034065441506051)]\n",
    "# [(244, 0.08955223880597014), (243, 0.08), (903, 0.04964539007092198), (99, 0.048582995951417005), (380, 0.046610169491525424)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 10\n",
    "# alpha 0.8, 1\n",
    "# [(161, 0.027947874459039665), (313, 0.027129979796553974), (73, 0.025445292620865142), (402, 0.022429906542056073)]\n",
    "# [(161, 0.027915369391449767), (313, 0.02712754175646111), (73, 0.025570205421714953), (402, 0.022429906542056073)]\n",
    "# [(243, 0.032), (925, 0.031578947368421054), (1212, 0.03118536197295147), (910, 0.031168831168831172), (108, 0.03114754098360656)]\n",
    "# [(1212, 0.036276849642004776), (89, 0.034972677595628415), (376, 0.032989690721649485), (925, 0.031578947368421054), (910, 0.031168831168831172)]\n",
    "# for alpha 0.6 one change in one case\n",
    "# only tokens/tokens+ext\n",
    "# [(243, 0.04), (925, 0.039473684210526314), (1212, 0.03898170246618934), (910, 0.03896103896103896), (108, 0.0389344262295082)]\n",
    "# [(1212, 0.045346062052505964), (89, 0.04371584699453552), (376, 0.041237113402061855), (925, 0.039473684210526314), (910, 0.03896103896103896)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 2.TFIDF evaluation\n",
    "# texts_keys = []\n",
    "# texts_values = []\n",
    "# for key in sorted(texts.keys()) :\n",
    "#     texts_keys.append(key)\n",
    "#     texts_values.append(texts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "# vectors_t = vectorizer.fit_transform(texts_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first vector out (for the first document)\n",
    "# vector_t = vectors_t[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # place tf-idf values in a pandas data frame\n",
    "# vector_dframe_t = pd.DataFrame(vector_t.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "# vector_dframe_t = vector_dframe_t.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dframe_t.head(50) #treaty ne sesteje lepo, lahko bi text olepsal preden gre v vectorizer, a pojavitev pomeni istost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to solve with transformation into string of tokenized text:\n",
    "# strings_keys = []\n",
    "# strings = []\n",
    "# for key in sorted(tokenized_docs.keys()) :\n",
    "#     strings_keys.append(key)\n",
    "#     list_tokens = tokenized_docs[key]\n",
    "#     corrected = \" \".join(list_tokens)\n",
    "#     strings.append(corrected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = vectorizer.fit_transform(strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first vector out (for the first document)\n",
    "# vector = vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # place tf-idf values in a pandas data frame\n",
    "# vector_dframe = pd.DataFrame(vector.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "# vector_dframe = vector_dframe.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dframe.head(50) #not much difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tfidf only for query words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_docs_tokens_appear(tokensI,tokenized_docsI,textsI):\n",
    "    docs_per_token = []\n",
    "    for i in range(len(tokensI)):\n",
    "        docs_per_token.append(0)\n",
    "    for k, v in tokenized_docsI.items():\n",
    "        content = tokenized_docsI.get(k)\n",
    "        text = textsI.get(k)\n",
    "        for i in range(len(tokensI)):\n",
    "            token = tokensI[i]\n",
    "            if token in text:\n",
    "                docs_per_token[i] = docs_per_token[i]+1\n",
    "    return docs_per_token\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_sum(tokensI,tokenized_docsI, textsI):\n",
    "    '''First tuple argument similar to probab_score_sum function but different metric - tfidf, second returns words that did not occure in any document'''\n",
    "    nb_docs_tokens_appeared = nb_docs_tokens_appear(tokensI,tokenized_docsI,textsI)\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokensI[i])\n",
    "        else:\n",
    "            appear.append(tokensI[i])    \n",
    "    l = len(tokenized_docsI)\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docsI.items():\n",
    "        n = len(v)\n",
    "        text = textsI.get(k)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = text.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            probability = probability+((token_frequency/n)*idf)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab, not_appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>0.197593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>0.189548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>0.180744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>0.178706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>0.178279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30565</td>\n",
       "      <td>0.174945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36068</td>\n",
       "      <td>0.174911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3867</td>\n",
       "      <td>0.174496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63388</td>\n",
       "      <td>0.167434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94467</td>\n",
       "      <td>0.166841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original     score\n",
       "0                  32476  0.197593\n",
       "1                  33546  0.189548\n",
       "2                  37122  0.180744\n",
       "3                  34869  0.178706\n",
       "4                  95196  0.178279\n",
       "5                  30565  0.174945\n",
       "6                  36068  0.174911\n",
       "7                   3867  0.174496\n",
       "8                  63388  0.167434\n",
       "9                  94467  0.166841"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test,tokenized_docs, texts)\n",
    "df_tfidf_sum_original = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original', 'score'])\n",
    "tf[1] #query words that did not appear in any doc\n",
    "df_tfidf_sum_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+ext,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_ext = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earpollution']"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+ext+top_list,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_ext_cand = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext_cand', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_ext_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earpollution']"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+topw_list,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_cand = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_cand', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original</th>\n",
       "      <th>id_tfidf_sum_original_ext</th>\n",
       "      <th>id_tfidf_sum_original_ext_cand</th>\n",
       "      <th>id_tfidf_sum_original_cand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>12744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>93533</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>97320</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>4505</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>94953</td>\n",
       "      <td>92987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3867</td>\n",
       "      <td>3867</td>\n",
       "      <td>59175</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63388</td>\n",
       "      <td>63388</td>\n",
       "      <td>93921</td>\n",
       "      <td>47944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94467</td>\n",
       "      <td>94467</td>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original  id_tfidf_sum_original_ext  \\\n",
       "0                  32476                      32476   \n",
       "1                  33546                      33546   \n",
       "2                  37122                      37122   \n",
       "3                  34869                      34869   \n",
       "4                  95196                      95196   \n",
       "5                  30565                      30565   \n",
       "6                  36068                      36068   \n",
       "7                   3867                       3867   \n",
       "8                  63388                      63388   \n",
       "9                  94467                      94467   \n",
       "\n",
       "   id_tfidf_sum_original_ext_cand  id_tfidf_sum_original_cand  \n",
       "0                           94936                       92988  \n",
       "1                            3453                       12744  \n",
       "2                           97319                       92986  \n",
       "3                           93533                        9649  \n",
       "4                           97320                       94936  \n",
       "5                            4505                       97319  \n",
       "6                           94953                       92987  \n",
       "7                           59175                       93921  \n",
       "8                           93921                       47944  \n",
       "9                           92988                        3453  "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_tfidf_sum_original['id_tfidf_sum_original'], df_tfidf_sum_original_ext['id_tfidf_sum_original_ext'], df_tfidf_sum_original_ext_cand['id_tfidf_sum_original_ext_cand'],df_tfidf_sum_original_cand['id_tfidf_sum_original_cand']]\n",
    "tfidf_sum_result = pd.concat(frames, axis=1)\n",
    "tfidf_sum_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "print(ext)\n",
    "print(top_list)\n",
    "##############################################\n",
    "#SUM\n",
    "###############################################\n",
    "# 94936 light pollution -, 32476 fishing quotas o, 97319 light pollution - , 3453 marine pollution o\n",
    "# without weighted sum (below): \n",
    "# 32476 already appeared, 33546 fishing quotas o,37122 fishing quotas o,12744 groundwater protection +,92988 groundwater protection +\n",
    "# id_sum_original_cand best choice\n",
    "##############################################\n",
    "# TFIDF\n",
    "##########################################\n",
    "# 94870, 92702, 93604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91998E2572WRITTEN QUESTION No. 2572/98 by John McCARTIN Fishing agreement with the Comores 1994-1997Official Journal C 320 , 06/11/1999 P. 0008 WRITTEN QUESTION E-2572/98by John McCartin (PPE) to the Commission(1 September 1998)Subject: Fishing agreement with the Comores 1994-1997Can the Commission state how many fishing vessels were involved in the 1994-1997 EU fishing agreement with the Comores, what was the tonnage of these vessels and how many days they fished under the agreement? Top'"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(94870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['flwfishing']\n",
      "['flwfishing', 'earpollution', 'biopollution']\n",
      "['earpollution', 'biopollution']\n"
     ]
    }
   ],
   "source": [
    "tf = tfidf_sum(test1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original1', 'score'])\n",
    "tf = tfidf_sum(test1+ext1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_ext1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext1', 'score'])\n",
    "tf = tfidf_sum(test1+ext1+top_list1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_ext_cand1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext_cand1', 'score'])\n",
    "tf = tfidf_sum(test1+topw_list1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_cand1 = pd.DataFrame(top_positives(tf,10), columns =['id_tfidf_sum_original_cand1', 'score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original1</th>\n",
       "      <th>id_tfidf_sum_original_ext1</th>\n",
       "      <th>id_tfidf_sum_original_ext_cand1</th>\n",
       "      <th>id_tfidf_sum_original_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original1  id_tfidf_sum_original_ext1  \\\n",
       "0                   94870                       94870   \n",
       "1                   92702                       92702   \n",
       "2                   93604                       93604   \n",
       "3                   97781                       97781   \n",
       "4                   93549                       93549   \n",
       "5                   14571                       14571   \n",
       "6                   97436                       97436   \n",
       "7                  100258                      100258   \n",
       "8                   44382                       44382   \n",
       "9                   98394                       98394   \n",
       "\n",
       "   id_tfidf_sum_original_ext_cand1  id_tfidf_sum_original_cand1  \n",
       "0                            94870                        94870  \n",
       "1                            92702                        92702  \n",
       "2                            93604                        93604  \n",
       "3                            97781                        97781  \n",
       "4                            93549                        93549  \n",
       "5                            14571                        14571  \n",
       "6                            97436                        97436  \n",
       "7                           100258                       100258  \n",
       "8                            44382                        44382  \n",
       "9                            98394                        98394  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_tfidf_sum_original1['id_tfidf_sum_original1'], df_tfidf_sum_original_ext1['id_tfidf_sum_original_ext1'], df_tfidf_sum_original_ext_cand1['id_tfidf_sum_original_ext_cand1'],df_tfidf_sum_original_cand1['id_tfidf_sum_original_cand1']]\n",
    "tfidf_sum_result1 = pd.concat(frames, axis=1)\n",
    "tfidf_sum_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n",
      "['earpollution', 'pollution', 'pollutants', 'biopollution', 'potable']\n"
     ]
    }
   ],
   "source": [
    "print(test1)\n",
    "print(ext1)\n",
    "print(top_list1)\n",
    "############\n",
    "#SUM\n",
    "############################################################\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention\n",
    "############################################################\n",
    "# TFIDF\n",
    "#94870 already, 92702 fishing already, 93604 environmental agreement\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E3072WRITTEN QUESTION No. 3072/97 by Amedeo AMADEO to the Commission. Environmental agreementsOfficial Journal C 117 , 16/04/1998 P. 0146 WRITTEN QUESTION E-3072/97 by Amedeo Amadeo (NI) to the Commission (2 October 1997)Subject: Environmental agreementsThe main objective of the Commissions communication on environmental agreements (COM(96) 561 final) is to promote and facilitate the use of effective and acceptable environmental agreements. These agreements are instruments for the integration or implementation of environment law in the Community. The communication should be seen in the light of the strategy outlined in the fifth action programme to extend the range of environment policy instruments and put into practice the concept of shared responsibility.The communication also seeks to clarify certain aspects of how environmental agreements can be used to implement certain provisions of Community directives in the Member States and how environmental agreements can be used at Community level.Does the Commission recommendation on environmental agreements refer only to their transposal into national law or does it also cover the application of the provisions once transposed?Answer given by Mrs Bjerregaard on behalf of the Commission (31 October 1997)The Commission Recommendation concerning environmental agreements implementing Community directives ((OJ L 333, 21.12.1996. )) not only concerns the transposition of certain provisions of directives into national law but also the implementation of the transposed law. The word implementation includes both the transposition into national law and the application of the transposed provisions. Clearly, where national legislation is in place to ensure compliance with a directive, the form of implementing these rules is less important. Nevertheless, the Commission considers the legal status of agreements as an important element of their success and therefore recommends that they be concluded in a legally-binding form. Top'"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(93604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_sum_weights(original_tokens, top_expansion,tokenized_docs,texts, wv, alpha): \n",
    "    tokens_together = original_tokens+top_expansion\n",
    "    nb_docs_tokens_appeared = nb_docs_tokens_appear(tokens_together,tokenized_docs,texts)\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokens_together[i])\n",
    "        else:\n",
    "            appear.append(tokens_together[i])  \n",
    "    l = len(tokenized_docs)\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        text = texts.get(k)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = text.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            probability = probability+((token_frequency/n)*idf)*word_value(appear[i], alpha, original_tokens, top_expansion, wv)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab,not_appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_original_query_ext_cand = []\n",
    "for alpha in [0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    tfw = tfidf_sum_weights(test+ext, top_list,tokenized_docs,texts, wv_wiki_en, alpha)\n",
    "    df_tfidf_wsum_original_ext_cand = pd.DataFrame(top_positives(tfw[0],10), columns =['id_tfidf_wsum_original_ext_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    tfidf_original_query_ext_cand.append(df_tfidf_wsum_original_ext_cand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.5</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.6</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.7</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.8</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.9</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_wsum_original_ext_cand0.5  id_tfidf_wsum_original_ext_cand0.6  \\\n",
       "0                               94870                               94870   \n",
       "1                               92702                               92702   \n",
       "2                               93604                               93604   \n",
       "3                               97781                               97781   \n",
       "4                               93549                               93549   \n",
       "5                               14571                               14571   \n",
       "6                               97436                               97436   \n",
       "7                              100258                              100258   \n",
       "8                               44382                               44382   \n",
       "9                               98394                               98394   \n",
       "\n",
       "   id_tfidf_wsum_original_ext_cand0.7  id_tfidf_wsum_original_ext_cand0.8  \\\n",
       "0                               94870                               94870   \n",
       "1                               92702                               92702   \n",
       "2                               93604                               93604   \n",
       "3                               97781                               97781   \n",
       "4                               93549                               93549   \n",
       "5                               14571                               14571   \n",
       "6                               97436                               97436   \n",
       "7                              100258                              100258   \n",
       "8                               44382                               44382   \n",
       "9                               98394                               98394   \n",
       "\n",
       "   id_tfidf_wsum_original_ext_cand0.9  id_tfidf_wsum_original_ext_cand1  \n",
       "0                               94870                             94870  \n",
       "1                               92702                             92702  \n",
       "2                               93604                             93604  \n",
       "3                               97781                             97781  \n",
       "4                               93549                             93549  \n",
       "5                               14571                             14571  \n",
       "6                               97436                             97436  \n",
       "7                              100258                            100258  \n",
       "8                               44382                             44382  \n",
       "9                               98394                             98394  "
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + ext + cand\n",
    "frames =[]\n",
    "for i in range(len(tfidf_original_query_ext_cand)):\n",
    "    dataf = tfidf_original_query_ext_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "tfidfcon = pd.concat(frames, axis=1)\n",
    "tfidfcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
