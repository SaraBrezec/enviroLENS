{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Expansion\n",
    "### Using FastText Word Embedding\n",
    "Based on this paper: https://arxiv.org/pdf/1606.07608.pdf\n",
    "\n",
    "Pre-made vector models: https://fasttext.cc/docs/en/aligned-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:16.676369Z",
     "start_time": "2019-06-12T13:31:15.880009Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from itertools import islice\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "\n",
    "# import natural language toolkit\n",
    "from nltk.corpus   import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:16.676369Z",
     "start_time": "2019-06-12T13:31:15.880009Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare stopword list\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'document_embeddings.ipynb',\n",
       " 'enviroLENS-deliverable-D4.2-images.ipynb',\n",
       " 'query-expansion.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T07:16:14.874574Z",
     "start_time": "2019-06-12T07:06:52.184229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english words 2519370\n"
     ]
    }
   ],
   "source": [
    "wiki_en_align = './../data/fasttext/wiki.en.align.vec' #'../../data/fasttext/wiki.en.align.vec'\n",
    "# get fasttext wiki embeddings for english\n",
    "wv_wiki_en = KeyedVectors.load_word2vec_format(wiki_en_align)\n",
    "print('english words {}'.format(len(list(wv_wiki_en.vocab.keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-retrieval kNN Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:17.961109Z",
     "start_time": "2019-06-12T13:31:17.954389Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of terms\n",
    "def tokenize(text, stopwords):\n",
    "    \"\"\"Tokenizes and removes stopwords from the document\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered = [w.lower() for w in tokens if not w in stopwords]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extended list of terms ###\n",
    "def extend_tokens(token_list, wv):\n",
    "    \"\"\"Extends token list summing vector pairs\"\"\"\n",
    "    tokens = []\n",
    "    for token in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "        if token in wv.vocab.keys():\n",
    "            tokens.append(token)\n",
    "    extention = set()\n",
    "    for i in range(len(tokens)-1):\n",
    "        new_token = wv.most_similar(positive=[tokens[i], tokens[i+1]])[0][0]\n",
    "        extention.add(new_token)\n",
    "    extention = list(extention)\n",
    "    return extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n"
     ]
    }
   ],
   "source": [
    "test = tokenize('water pollution underground', stop_words)\n",
    "print(test)\n",
    "ext = extend_tokens(test,wv_wiki_en)\n",
    "print(ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n"
     ]
    }
   ],
   "source": [
    "test1 = tokenize('annex fishing agreement europe', stop_words)\n",
    "print(test1)\n",
    "ext1 = extend_tokens(test1,wv_wiki_en)\n",
    "print(ext1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:18.473214Z",
     "start_time": "2019-06-12T13:31:18.465157Z"
    }
   },
   "outputs": [],
   "source": [
    "# knn nearest\n",
    "def get_candidate_expansion_terms(tokens, k, wv):\n",
    "    \"\"\"Gets the candidate expansion terms\"\"\"\n",
    "    candidates = set()\n",
    "    for token in tokens:\n",
    "        # check if the token is in the vocabulary\n",
    "        if token in wv.vocab.keys():\n",
    "            result = wv.similar_by_word(token)\n",
    "            limit = k if len(result) > k else len(result)\n",
    "            # iterate through the most similar words\n",
    "            for i in range(limit):\n",
    "                candidates.add(result[i][0])\n",
    "    # return list of candidates\n",
    "    candidates = list(candidates)\n",
    "    return candidates\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:31:20.226899Z",
     "start_time": "2019-06-12T13:31:19.569959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sewage', 'undergrounder', 'earpollution', 'pollutions', '#pollution', 'pollution', 'biopollution', 'water—', 'undergroun', 'potable', 'undergrounders', 'undergrounding', 'pollutants', 'seawater', 'undergrounds', 'undergroung', 'pollution,', 'undergrounded', 'groundwater']\n",
      "['undergrounds', 'undergroung', 'undergroun', 'potable', 'undergrounding', 'sewage', 'pollution,', 'earpollution', 'undergrounded', 'biopollution', 'pollutions', 'water—', '#pollution', 'seawater', 'groundwater']\n"
     ]
    }
   ],
   "source": [
    "candidates = get_candidate_expansion_terms(test+ext, 5, wv_wiki_en)\n",
    "print(candidates)\n",
    "witout = get_candidate_expansion_terms(test, 5, wv_wiki_en)\n",
    "print(witout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between word and list of words\n",
    "def similarity(token, token_list, wv ):\n",
    "    \"\"\"calculates the similarity between word and list of words\"\"\"\n",
    "    # calculate the similarity of the token to all tokens\n",
    "    similarity = 0\n",
    "    num_of_tokens = 0\n",
    "    for toks in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "        if toks in wv.vocab.keys():\n",
    "            num_of_tokens += 1\n",
    "            similarity += wv.similarity(toks, token)\n",
    "    return similarity/num_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:13.725242Z",
     "start_time": "2019-06-12T13:33:13.716880Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculates similarity and sorts\n",
    "def get_top_expansion_terms(tokens, candidates, wv):\n",
    "    \"\"\"Gets the actual expansion terms\"\"\"\n",
    "    similarity_pairs = []\n",
    "    for candidate in candidates:\n",
    "        sim = similarity(candidate, tokens, wv)\n",
    "        similarity_pairs.append((candidate, sim))\n",
    "    # return the list of expansion terms with their similarities\n",
    "    return similarity_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:14.317627Z",
     "start_time": "2019-06-12T13:33:14.308832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pollution', 0.6260276407951795), ('pollutions', 0.5989783010567384), ('undergrounding', 0.5868486694404182), ('earpollution', 0.5791309410113682), ('pollution,', 0.5584437076938438), ('pollutants', 0.5473505877035749), ('groundwater', 0.5472185974670385), ('sewage', 0.5438533174483885), ('undergrounds', 0.5373294534380543), ('#pollution', 0.5307803259871704), ('biopollution', 0.5239432296935493), ('undergrounded', 0.5166503920961191), ('undergrounders', 0.5048834686641379), ('undergroun', 0.4968187167322256), ('undergrounder', 0.4930006599112927), ('undergroung', 0.489668825408463), ('seawater', 0.48062588166948944), ('potable', 0.47213486261999227), ('water—', 0.4339509338693007)]\n",
      "[('pollution', 0.6073097696558459), ('groundwater', 0.572225614085378), ('sewage', 0.5672777675468184), ('earpollution', 0.5479508482970045), ('pollutions', 0.5392823009654663), ('pollution,', 0.5361565112564385), ('pollutants', 0.5332377192240293), ('seawater', 0.5219145986771884), ('undergrounding', 0.5190662482715993), ('potable', 0.5137930541544308), ('#pollution', 0.5053773015402238), ('biopollution', 0.504703593451706), ('undergrounds', 0.48430795952141487), ('water—', 0.47646895745070106), ('undergrounded', 0.46550011202029024), ('undergrounders', 0.4524525797301971), ('undergroun', 0.4511787727249055), ('undergroung', 0.4484747924647392), ('undergrounder', 0.44571173169707395)]\n"
     ]
    }
   ],
   "source": [
    "# get actual expansion terms for test set; with and without extension\n",
    "top = get_top_expansion_terms(test+ext, candidates,  wv_wiki_en)\n",
    "topwithout = get_top_expansion_terms(test, candidates,  wv_wiki_en)\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "top = sorted(top, key=takeSecond)[::-1]\n",
    "topw = sorted(topwithout, key=takeSecond)[::-1]\n",
    "print((top))\n",
    "print((topw))\n",
    "top = top[0:5]\n",
    "topw = topw[0:5]\n",
    "top_list = []\n",
    "for tupl in top:\n",
    "    top_list.append(tupl[0])\n",
    "topw_list = []\n",
    "for tupl in topw:\n",
    "    topw_list.append(tupl[0])\n",
    "\n",
    "# get actual expansion terms for test1 set; with and without extension\n",
    "top1 = get_top_expansion_terms(test1+ext1, candidates,  wv_wiki_en)\n",
    "topwithout1 = get_top_expansion_terms(test1, candidates,  wv_wiki_en)\n",
    "\n",
    "top1 = sorted(top1, key=takeSecond)[::-1]\n",
    "topw1 = sorted(topwithout1, key=takeSecond)[::-1]\n",
    "top1 = top1[0:5]\n",
    "topw1 = topw1[0:5]\n",
    "top_list1 = []\n",
    "for tupl in top1:\n",
    "    top_list1.append(tupl[0])\n",
    "topw_list1 = []\n",
    "for tupl in topw1:\n",
    "    topw_list1.append(tupl[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:17.453260Z",
     "start_time": "2019-06-12T13:33:17.445772Z"
    }
   },
   "outputs": [],
   "source": [
    "# all functions together, finds k nearest for each term, returns top n\n",
    "def pre_retrieval_KNN(string, k, wv, n):\n",
    "    \"\"\"Find the most similar tokens to the given query\"\"\"\n",
    "    tokens = tokenize(string, stop_words)\n",
    "    candidates = get_candidate_expansion_terms(tokens, k, wv)\n",
    "    candidates_sim = get_top_expansion_terms(tokens, candidates, wv)\n",
    "    def takeSecond(elem):\n",
    "        return elem[1]\n",
    "    sort = sorted(candidates_sim, key=takeSecond)[::-1]\n",
    "    return sort[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T13:33:18.114793Z",
     "start_time": "2019-06-12T13:33:17.927772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('learning,', 0.5336429871558637),\n",
       " ('learnings', 0.5210396371333685),\n",
       " ('relearning', 0.509084270159704),\n",
       " ('#learning', 0.507341799782255),\n",
       " ('learning—in', 0.5062408798333075),\n",
       " ('deeper', 0.49509854997328506),\n",
       " ('deepest', 0.42268526313403443),\n",
       " ('deeps', 0.4007843076134384),\n",
       " ('depths', 0.3836683940147054),\n",
       " ('shallow', 0.3727379655276737)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_retrieval_KNN('deep learning', 5, wv_wiki_en, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import postgresql\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.library.postgresql import PostgresQL\n",
    "# connect to the postgresql database\n",
    "pg = PostgresQL() \n",
    "pg.connect(database=\"eurlex_environment_only\", user=\"postgres\", password=\"dbpass\") #\"eurlex_env_only\" \"solata.2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import documents \n",
    "documents = pg.execute(\"\"\"\n",
    "    SELECT * FROM documents;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(documents))\n",
    "documents[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = documents\n",
    "# some docs are empty !!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "# for doc in docs:\n",
    "#     idd= doc.get('document_id')\n",
    "#     if idd == 39722:\n",
    "#         print(doc)\n",
    "\n",
    "delete = []\n",
    "for doc in docs:\n",
    "    n = len(doc.get('document_text'))\n",
    "    if n == 0:\n",
    "        id_doc = doc.get('document_id')\n",
    "        delete.append(id_doc)\n",
    "            \n",
    "# remove empty docs\n",
    "for doc in docs:\n",
    "    id_doc = doc.get('document_id')\n",
    "    if id_doc in delete:\n",
    "        docs.remove(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99369\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tokenzized documents (texts), texts, tokenzized titles and titles\n",
    "tokenized_docs = {}\n",
    "tokenized_titles = {}\n",
    "texts = {}\n",
    "titles = {}\n",
    "for document in docs:\n",
    "    doc_id = document.get('document_id')\n",
    "    text = document.get('document_text')\n",
    "    texts.update({doc_id: text})\n",
    "    title = document.get('document_title')\n",
    "    titles.update({doc_id: title})\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized = tokenize(text, stop_words)\n",
    "    title = title.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized_title = tokenize(title, stop_words)\n",
    "    for token in tokenized:\n",
    "        if len(token) == 1:\n",
    "            if token.isalpha():\n",
    "                tokenized.remove(token)\n",
    "    tokenized_docs.update({doc_id: tokenized})\n",
    "    for title in tokenized_title:\n",
    "        if len(title) == 1:\n",
    "            if title.isalpha():\n",
    "                tokenized_title.remove(title)\n",
    "    tokenized_titles.update({doc_id: tokenized_title})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agreement', 'relating', 'principally', 'chemicals', 'supplementary', 'geneva', '1967', 'protocol', 'general', 'agreement', 'tariffs', 'trade', 'negotiated', 'geneva', '30', 'june', '1967']\n",
      "/* Agreement relating principally to chemicals, supplementary to the Geneva (1967) Protocol to the General Agreement on Tariffs and Trade, negotiated in Geneva on 30 June 1967 */\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tokenized_titles.get(3))\n",
    "print(titles.get(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_docs.get(39703))\n",
    "print(texts.get(39703))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99412\n",
      "23151\n"
     ]
    }
   ],
   "source": [
    "# still some empty documents\n",
    "print(len(tokenized_docs))\n",
    "#print(take(1, tokenized_docs.items()))\n",
    "empt=[]\n",
    "for k,v in tokenized_docs.items():\n",
    "    l =len(v)\n",
    "    if l==0:\n",
    "        empt.append(k)\n",
    "print(len(empt))\n",
    "#print((empt))\n",
    "\n",
    "for k in empt:\n",
    "    del tokenized_docs[k]\n",
    "    del tokenized_titles[k]\n",
    "    del texts[k]\n",
    "    del titles[k]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76261\n",
      "76261\n",
      "76261\n",
      "76261\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_docs))\n",
    "print(len(tokenized_titles))\n",
    "print(len(texts))\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just making smaller document set for faster testing, can delete later\n",
    "tokenized_docs1 = {}\n",
    "tokenized_titles1 = {}\n",
    "texts1= {}\n",
    "titles1={}\n",
    "for k in range(1,1000):\n",
    "    vtd = tokenized_docs.get(k)\n",
    "    vtt = tokenized_titles.get(k)\n",
    "    vx = texts.get(k)\n",
    "    vt =titles.get(k)\n",
    "    tokenized_docs1.update({k:vtd})\n",
    "    tokenized_titles1.update({k:vtt})\n",
    "    texts1.update({k:vx})\n",
    "    titles1.update({k:vt})\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenized_docs1))\n",
    "print(len(tokenized_titles1))\n",
    "print(len(texts1))\n",
    "print(len(titles1))\n",
    "tokenized_docs1 = {k:v for k,v in tokenized_docs1.items() if v is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### search full words (not lemmatized), search as substrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1. probability scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability scoring\n",
    "### all query words have to be in the document (multiplying)\n",
    "\n",
    "def probab_score(tokens,tokenized_docs,texts):\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 1\n",
    "        text = texts.get(k)\n",
    "        for token in tokens:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability*(token_frequency/n)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(120739, 2.2778939503692463e-06), (90952, 1.4623827626019007e-06), (98346, 9.60986510312026e-07), (100875, 9.116079910329329e-07), (96934, 7.795624765214125e-07), (98891, 4.7381201508301593e-07), (99214, 4.374815382790846e-07), (53800, 2.5508770567849454e-07), (101429, 2.4695734439852766e-07), (101872, 2.433802400069899e-07)]\n",
      "[]\n",
      "[(72, 4.866706628529354e-11), (4098, 3.9980157168428714e-11), (31030, 1.0620609744608273e-11), (85, 6.56566844179315e-12), (47616, 4.413577090077561e-12), (59689, 3.662677012225006e-12), (2146, 2.529433698703274e-12), (25303, 2.2094496103487563e-12), (57414, 2.1926876323265894e-12), (31131, 1.3631354904463345e-12)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# only original query\n",
    "score =probab_score(test,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "print(sorted_positives_top)\n",
    "\n",
    "# original query + extension\n",
    "score =probab_score(test+ext,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "print(([(k,v) for k,v in score.items() if v > 0]))\n",
    "\n",
    "\n",
    "# only original query\n",
    "score =probab_score(test1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "print(sorted_positives_top)\n",
    "\n",
    "# original query + extension\n",
    "score =probab_score(test1+ext1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "print(([(k,v) for k,v in score.items() if v > 0]))\n",
    "\n",
    "\n",
    "# no point having an extention, empty results are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titles.get(80))\n",
    "# print(texts.get(80))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## query words summation\n",
    "def probab_score_sum(tokens,tokenized_docs,texts):\n",
    "    '''assigns score to document based on summation of probabilities'''\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        text = texts.get(k)\n",
    "        for token in tokens:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability+(token_frequency/n)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zavedaj se:\n",
    "\"gabla is bla2\".count(\"bla\")\n",
    "# kar pomeni da bi bilo bolje uporabiti lemmatized words! popravi!! neke stvari zdaj 2x stejes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_positives(dictionary,n):\n",
    "    \"\"\"Takes dict and returns first n tuples of k,v sorted by v\"\"\"\n",
    "    positives = {} \n",
    "    for k,v in dictionary.items():\n",
    "        if v > 0:\n",
    "            positives.update({k: v})\n",
    "    sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "    sorted_positives_top = sorted_positives[0:n]\n",
    "    return sorted_positives_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n"
     ]
    }
   ],
   "source": [
    "# only original query\n",
    "score_sum =probab_score_sum(test,tokenized_docs,texts)\n",
    "\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>0.116567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>0.111821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>0.106627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>0.105425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30565</td>\n",
       "      <td>0.103206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36068</td>\n",
       "      <td>0.103186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3867</td>\n",
       "      <td>0.102941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94467</td>\n",
       "      <td>0.098425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38921</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original     score\n",
       "0            32476  0.116567\n",
       "1            33546  0.111821\n",
       "2            37122  0.106627\n",
       "3            34869  0.105425\n",
       "4            30565  0.103206\n",
       "5            36068  0.103186\n",
       "6             3867  0.102941\n",
       "7            95196  0.099099\n",
       "8            94467  0.098425\n",
       "9            38921  0.097561"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "df_sum_original = pd.DataFrame(sorted_positives_top, columns =['id_sum_original', 'score'])\n",
    "df_sum_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titles.get(565))\n",
    "# print(texts.get(565))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32476, 0.11656671664167916), (33546, 0.11182108626198083), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686), (3867, 0.10294117647058823), (95196, 0.0990990990990991), (94467, 0.0984251968503937), (38921, 0.0975609756097561)]\n"
     ]
    }
   ],
   "source": [
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test+ext,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df_sum_original_ext = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(72, 4.866706628529354e-11), (4098, 3.9980157168428714e-11), (31030, 1.0620609744608273e-11), (85, 6.56566844179315e-12), (47616, 4.413577090077561e-12), (59689, 3.662677012225006e-12), (2146, 2.529433698703274e-12), (25303, 2.2094496103487563e-12), (57414, 2.1926876323265894e-12), (31131, 1.3631354904463345e-12)]\n",
      "[(94870, 0.1276595744680851), (11790, 0.09090909090909091), (100258, 0.08527131782945736), (97436, 0.08280254777070063), (28599, 0.08163833937029813), (92702, 0.07514450867052024), (97265, 0.07430340557275542), (50112, 0.07235621521335807), (62459, 0.07103825136612021), (49539, 0.07056113902847572)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>0.085271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>0.082803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>0.081638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>0.075145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>0.074303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>0.072356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>0.071038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>0.070561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original1     score\n",
       "0             94870  0.127660\n",
       "1             11790  0.090909\n",
       "2            100258  0.085271\n",
       "3             97436  0.082803\n",
       "4             28599  0.081638\n",
       "5             92702  0.075145\n",
       "6             97265  0.074303\n",
       "7             50112  0.072356\n",
       "8             62459  0.071038\n",
       "9             49539  0.070561"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only original query\n",
    "score =probab_score(test1,tokenized_docs,texts)\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score,10)\n",
    "print(sorted_positives_top)\n",
    "\n",
    "\n",
    "\n",
    "## original query\n",
    "score_sum =probab_score_sum(test1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original1', 'score'])\n",
    "df_sum_original1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original_ext1</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92702</td>\n",
       "      <td>0.121387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93604</td>\n",
       "      <td>0.116959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97781</td>\n",
       "      <td>0.114583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93549</td>\n",
       "      <td>0.104348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14571</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97436</td>\n",
       "      <td>0.101911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100258</td>\n",
       "      <td>0.100775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44382</td>\n",
       "      <td>0.100151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98394</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original_ext1     score\n",
       "0                 94870  0.127660\n",
       "1                 92702  0.121387\n",
       "2                 93604  0.116959\n",
       "3                 97781  0.114583\n",
       "4                 93549  0.104348\n",
       "5                 14571  0.102041\n",
       "6                 97436  0.101911\n",
       "7                100258  0.100775\n",
       "8                 44382  0.100151\n",
       "9                 98394  0.099099"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test1+ext1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "positives = dict([(k,v) for k,v in score_sum.items() if v > 0])\n",
    "sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "sorted_positives_top = sorted_positives[0:10]\n",
    "#dataframe\n",
    "df_sum_original_ext1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext1', 'score'])\n",
    "df_sum_original_ext1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12744, 0.15163934426229508), (92986, 0.1473429951690821), (92988, 0.14669421487603304), (9649, 0.13286713286713286), (93921, 0.11695906432748537), (32476, 0.11656671664167916), (62937, 0.11578947368421053), (94936, 0.11494252873563218), (97319, 0.11363636363636363), (95196, 0.11261261261261261)]\n",
      "[(94936, 0.12643678160919541), (3453, 0.11875000000000001), (32476, 0.11656671664167916), (97319, 0.11363636363636363), (33546, 0.11182108626198083), (95196, 0.10810810810810811), (37122, 0.10662729658792651), (34869, 0.10542476970317298), (30565, 0.103206106870229), (36068, 0.10318609703113686)]\n",
      "[(94870, 0.1276595744680851), (11790, 0.09090909090909091), (100258, 0.08527131782945736), (97436, 0.08280254777070063), (28599, 0.08163833937029813), (92702, 0.07514450867052024), (97265, 0.07430340557275542), (50112, 0.07235621521335807), (62459, 0.07103825136612021), (49539, 0.07056113902847572)]\n",
      "[(94870, 0.1276595744680851), (92702, 0.12138728323699421), (93604, 0.11695906432748537), (97781, 0.11458333333333334), (93549, 0.10434782608695653), (14571, 0.10204081632653061), (97436, 0.1019108280254777), (100258, 0.10077519379844961), (44382, 0.10015060240963855), (98394, 0.0990990990990991)]\n"
     ]
    }
   ],
   "source": [
    "# adding candidates\n",
    "## without weights\n",
    "# no point using multiplication\n",
    "\n",
    "# summation:\n",
    "## original query\n",
    "score_sum =probab_score_sum(test+topw_list,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_cand = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_cand', 'score'])\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test+ext+top_list,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_ext_cand = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext_cand', 'score'])\n",
    "\n",
    "\n",
    "## original query\n",
    "score_sum =probab_score_sum(test1+topw_list1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_cand1', 'score'])\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "score_sum =probab_score_sum(test1+ext1+top_list1,tokenized_docs,texts)\n",
    "#original + ext gives same score, add global and state gives different score, same order\n",
    "#how many docs have positive score?\n",
    "sorted_positives_top = top_positives(score_sum,10)\n",
    "print(sorted_positives_top)\n",
    "#dataframe\n",
    "df_sum_original_ext_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_sum_original_ext_cand1', 'score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_value(word, alpha, original_tokens, top_expansion, wv):\n",
    "    \"\"\"values word based on whether is in original token set or expanded, if alpha -1 value equals to cosine similarity\"\"\"\n",
    "    only_expanded = []\n",
    "    for token in top_expansion:\n",
    "        if token not in original_tokens:\n",
    "            only_expanded.append(token)\n",
    "            \n",
    "    sum_similarity = 0\n",
    "    for exp_token in only_expanded:\n",
    "            sum_similarity += similarity(exp_token,original_tokens, wv)\n",
    "            \n",
    "    if alpha == -1:\n",
    "        if word in original_tokens:\n",
    "            value = 1\n",
    "        else:\n",
    "            value = similarity(word, original_tokens, wv)/sum_similarity\n",
    "\n",
    "\n",
    "    else:\n",
    "        if word in original_tokens:\n",
    "            value = alpha\n",
    "        else:\n",
    "            value = (1-alpha)*similarity(word, original_tokens, wv)/sum_similarity\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n",
      "0.28172557133554\n",
      "0.7\n",
      "0.27141179615367744\n"
     ]
    }
   ],
   "source": [
    "# ce ni ext zraven je so cudni rezultati, zamenja vrstni red pomembnsti med sewage in undergrounding??\n",
    "top = top[0:4]\n",
    "top_words = [i[0] for i in top]\n",
    "print(word_value(\"water\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"sewage\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"undergrounding\", 0.7, test+ext ,top_words, wv_wiki_en))\n",
    "print(word_value(\"biopollution\", 0.7, test+ext ,top_words, wv_wiki_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probab_score_sum_weights(original_tokens, top_expansion,tokenized_docs,texts, wv, alpha): \n",
    "    '''As probab_score_sum only weighted; usually extention added to original tokens, candidates = top_expansion - have weights'''\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        text = texts.get(k)\n",
    "        for token in original_tokens+top_expansion:\n",
    "            token_frequency = text.count(token)\n",
    "            probability = probability+(token_frequency/n)*word_value(token, alpha, original_tokens, top_expansion, wv)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.35,\n",
       " 0.33091025022915893,\n",
       " 0.31908974977084104]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check word values\n",
    "wvals = []\n",
    "for token in test+ext+top_list:\n",
    "    wvals.append(word_value(token, 0.35, test+ext, top_list, wv_wiki_en))\n",
    "wvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998\n"
     ]
    }
   ],
   "source": [
    "#check word frequences\n",
    "n = len(tokenized_docs1)\n",
    "print(n)\n",
    "t_freqs = []\n",
    "for k, v in tokenized_docs1.items():\n",
    "    n = len(v)\n",
    "    text = texts1.get(k)\n",
    "    for token in test+ext+top_list:\n",
    "        token_frequency = text.count(token)\n",
    "        t_freqs.append(token_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with weights\n",
    "# summation \n",
    "original_query_cand = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    ## original query\n",
    "    score_sum = probab_score_sum_weights(test, topw_list,tokenized_docs, texts, wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_cand = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_cand.append(df_wsum_original_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original query plus ext\n",
    "original_query_ext_cand = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum =probab_score_sum_weights(test+ext, top_list,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_ext_cand = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_ext_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_ext_cand.append(df_wsum_original_ext_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sorting for each alpha\n",
    "doubleframes =[]\n",
    "for i in range(len(original_query_cand)):\n",
    "    frst = original_query_cand[i].take([0], axis=1)\n",
    "    snd = original_query_ext_cand[i].take([0], axis=1)\n",
    "    con = pd.concat([frst,snd], axis=1)\n",
    "    doubleframes.append(con)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94936</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97319</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92986</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33546</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9649</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37122</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand0.4  id_wsum_original_ext_cand0.4\n",
       "0                     32476                         94936\n",
       "1                     12744                         32476\n",
       "2                     92988                          3453\n",
       "3                     94936                         97319\n",
       "4                     97319                         33546\n",
       "5                     92986                         95196\n",
       "6                     33546                         37122\n",
       "7                     95196                         34869\n",
       "8                      9649                         30565\n",
       "9                     37122                         36068"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleframes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand-1</th>\n",
       "      <th>id_wsum_original_cand0.35</th>\n",
       "      <th>id_wsum_original_cand0.4</th>\n",
       "      <th>id_wsum_original_cand0.45</th>\n",
       "      <th>id_wsum_original_cand0.5</th>\n",
       "      <th>id_wsum_original_cand0.6</th>\n",
       "      <th>id_wsum_original_cand0.7</th>\n",
       "      <th>id_wsum_original_cand0.8</th>\n",
       "      <th>id_wsum_original_cand0.9</th>\n",
       "      <th>id_wsum_original_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "      <td>12744</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "      <td>92988</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33546</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92988</td>\n",
       "      <td>94936</td>\n",
       "      <td>97319</td>\n",
       "      <td>12744</td>\n",
       "      <td>92988</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95196</td>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "      <td>33546</td>\n",
       "      <td>95196</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12744</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>95196</td>\n",
       "      <td>12744</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37122</td>\n",
       "      <td>9649</td>\n",
       "      <td>95196</td>\n",
       "      <td>92986</td>\n",
       "      <td>37122</td>\n",
       "      <td>92988</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "      <td>9649</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "      <td>34869</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92986</td>\n",
       "      <td>93921</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "      <td>92986</td>\n",
       "      <td>12744</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand-1  id_wsum_original_cand0.35  \\\n",
       "0                    32476                      12744   \n",
       "1                    94936                      92988   \n",
       "2                    97319                      92986   \n",
       "3                    33546                      32476   \n",
       "4                    92988                      94936   \n",
       "5                    95196                      97319   \n",
       "6                    12744                      33546   \n",
       "7                    37122                       9649   \n",
       "8                     3453                      95196   \n",
       "9                    92986                      93921   \n",
       "\n",
       "   id_wsum_original_cand0.4  id_wsum_original_cand0.45  \\\n",
       "0                     32476                      32476   \n",
       "1                     12744                      94936   \n",
       "2                     92988                      97319   \n",
       "3                     94936                      92988   \n",
       "4                     97319                      12744   \n",
       "5                     92986                      33546   \n",
       "6                     33546                      95196   \n",
       "7                     95196                      92986   \n",
       "8                      9649                      37122   \n",
       "9                     37122                       3453   \n",
       "\n",
       "   id_wsum_original_cand0.5  id_wsum_original_cand0.6  \\\n",
       "0                     32476                     32476   \n",
       "1                     94936                     94936   \n",
       "2                     97319                     97319   \n",
       "3                     33546                     33546   \n",
       "4                     92988                     95196   \n",
       "5                     95196                     37122   \n",
       "6                     12744                      3453   \n",
       "7                     37122                     92988   \n",
       "8                      3453                     34869   \n",
       "9                     92986                     12744   \n",
       "\n",
       "   id_wsum_original_cand0.7  id_wsum_original_cand0.8  \\\n",
       "0                     32476                     32476   \n",
       "1                     94936                     94936   \n",
       "2                     97319                     97319   \n",
       "3                     33546                     33546   \n",
       "4                     95196                     95196   \n",
       "5                     37122                     37122   \n",
       "6                      3453                      3453   \n",
       "7                     34869                     34869   \n",
       "8                     30565                     30565   \n",
       "9                     36068                     36068   \n",
       "\n",
       "   id_wsum_original_cand0.9  id_wsum_original_cand1  \n",
       "0                     32476                   32476  \n",
       "1                     94936                   94936  \n",
       "2                     97319                   97319  \n",
       "3                     33546                   33546  \n",
       "4                     95196                   95196  \n",
       "5                     37122                   37122  \n",
       "6                      3453                    3453  \n",
       "7                     34869                   34869  \n",
       "8                     30565                   30565  \n",
       "9                     36068                   36068  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_cand)):\n",
    "    dataf = original_query_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "con = pd.concat(frames, axis=1)\n",
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha 1 - 0.5 first 4 docs the same, 0.45 first 3 the same, 0.4 1st the same\n",
    "- alpha -1 same as alpha 0.5\n",
    "- alpha 0.35 even 1st doc different than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 10, 94936: 10, 97319: 10, 33546: 10, 95196: 10, 37122: 9, 3453: 8, 12744: 6, 92988: 6, 92986: 5, 34869: 5, 30565: 4, 36068: 4, 9649: 2, 93921: 1})\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#counting number of occurances of  documents\n",
    "values = con.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5 docs in every column \n",
    "- 11 of 15 different docs appear at least in half of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_ext_cand-1</th>\n",
       "      <th>id_wsum_original_ext_cand0.35</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.45</th>\n",
       "      <th>id_wsum_original_ext_cand0.5</th>\n",
       "      <th>id_wsum_original_ext_cand0.6</th>\n",
       "      <th>id_wsum_original_ext_cand0.7</th>\n",
       "      <th>id_wsum_original_ext_cand0.8</th>\n",
       "      <th>id_wsum_original_ext_cand0.9</th>\n",
       "      <th>id_wsum_original_ext_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32476</td>\n",
       "      <td>3453</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97319</td>\n",
       "      <td>32476</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3453</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>3453</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_ext_cand-1  id_wsum_original_ext_cand0.35  \\\n",
       "0                        94936                          94936   \n",
       "1                        32476                           3453   \n",
       "2                        97319                          32476   \n",
       "3                         3453                          97319   \n",
       "4                        33546                          33546   \n",
       "5                        95196                          95196   \n",
       "6                        37122                          37122   \n",
       "7                        34869                          34869   \n",
       "8                        30565                          30565   \n",
       "9                        36068                          36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.4  id_wsum_original_ext_cand0.45  \\\n",
       "0                         94936                          94936   \n",
       "1                         32476                          32476   \n",
       "2                          3453                           3453   \n",
       "3                         97319                          97319   \n",
       "4                         33546                          33546   \n",
       "5                         95196                          95196   \n",
       "6                         37122                          37122   \n",
       "7                         34869                          34869   \n",
       "8                         30565                          30565   \n",
       "9                         36068                          36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.5  id_wsum_original_ext_cand0.6  \\\n",
       "0                         94936                         94936   \n",
       "1                         32476                         32476   \n",
       "2                         97319                         97319   \n",
       "3                          3453                         33546   \n",
       "4                         33546                          3453   \n",
       "5                         95196                         95196   \n",
       "6                         37122                         37122   \n",
       "7                         34869                         34869   \n",
       "8                         30565                         30565   \n",
       "9                         36068                         36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.7  id_wsum_original_ext_cand0.8  \\\n",
       "0                         94936                         32476   \n",
       "1                         32476                         94936   \n",
       "2                         97319                         97319   \n",
       "3                         33546                         33546   \n",
       "4                          3453                         95196   \n",
       "5                         95196                          3453   \n",
       "6                         37122                         37122   \n",
       "7                         34869                         34869   \n",
       "8                         30565                         30565   \n",
       "9                         36068                         36068   \n",
       "\n",
       "   id_wsum_original_ext_cand0.9  id_wsum_original_ext_cand1  \n",
       "0                         32476                       32476  \n",
       "1                         94936                       94936  \n",
       "2                         97319                       97319  \n",
       "3                         33546                       33546  \n",
       "4                         95196                       95196  \n",
       "5                          3453                       37122  \n",
       "6                         37122                        3453  \n",
       "7                         34869                       34869  \n",
       "8                         30565                       30565  \n",
       "9                         36068                       36068  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original +ext + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_ext_cand)):\n",
    "    dataf = original_query_ext_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "conex = pd.concat(frames, axis=1)\n",
    "conex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.8 - 1 1st doc 32476, rest 1st doc 94936\n",
    "- 0.8 - 1 first 5 docs the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94936: 10, 32476: 10, 3453: 10, 97319: 10, 33546: 10, 95196: 10, 37122: 10, 34869: 10, 30565: 10, 36068: 10})\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#counting number of occurances of  documents\n",
    "values = conex.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all columns contain same documents, just order is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n",
      "['pollution', 'pollutions', 'undergrounding', 'earpollution', 'pollution,']\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(ext)\n",
    "print(top_list)\n",
    "# 94936 light pollution -, 32476 fishing quotas o, 97319 light pollution - , 3453 marine pollution o\n",
    "# without weighted sum (below): \n",
    "# 32476 already appeared, 33546 fishing quotas o,37122 fishing quotas o,12744 groundwater protection +,92988 groundwater protection +\n",
    "# 33546 fishing quotas o, 92986 groundwater protection +\n",
    "# id_sum_original_cand best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E1892WRITTEN QUESTION No. 1892/97 by Amedeo AMADEO to the Commission. Integrated groundwater protection and managementOfficial Journal C 045 , 10/02/1998 P. 0120 WRITTEN QUESTION E-1892/97 by Amedeo Amadeo (NI) to the Commission (4 June 1997)Subject: Integrated groundwater protection and managementWith reference to the Commission Proposal for a European Parliament and Council Decision on an action programme for integrated groundwater protection and management (COM(96) 0315 final - 96/0181 COD) ((OJ C 355, 25.11.1996, p. 1.)),the proposed action programme comprises four main lines of action: planning and management of groundwater protection, creating a regulatory framework for fresh water abstraction, development of instruments for control of groundwater polution from diffuse sources and development of instruments for control of point source emissions and discharges.With regard to the first line of action, will the Commission:1. Classify waters according to their use, their different characteristics and the original water table?2. Take measures to reduce the waterproofing of the ground in suburban areas and take preventive measures against earth creep in areas intended for agricultural use?3. Restrict pumping capacities as far as possible to replenishing the water table and encourage the rational use and the re-use of water?4. Cooperate with the third countries preparing to accede to the European Union with the aim of helping them adapt to European quality standards?Answer given by Mrs Bjerregaard on behalf of the Commission (10 July 1997)The objective of the proposal for a Parliament and Council decision on an action programme for integrated groundwater protection and management is to ensure that protection and use of groundwater takes place as part of an integrated management of fresh water resources and that groundwaters on a long term basis will be managed with surface waters within a river basin management approach.In February 1997, the Commission adopted a proposal for a Council directive establishing a framework for Community action in the field of water policy ((COM(97) 49 final. )) which lays down the basic principles for integrated protection and use of groundwaters and surface waters within such a river basin management approach. Whilst part of the actions presented in the proposed groundwater action programme may be pursued through a variety of instruments, some may be strengthened through appropriate legal provisions. The proposed water framework directive is intended as a framework within which inter alia the protection and sustainable use of groundwater may be ensured through such legal provisions.1. It is the objective of the proposed groundwater action programme to ensure protection of all groundwaters and in line with this the proposed groundwater action programme does not classify groundwaters according to their use. On the contrary, in order to ensure appropriate protection and sustainable use the characteristics of a particular groundwater have to be taken into account and therefore the proposed groundwater action programme requires Member States to identify the environmental pressures as well as the particular vulnerability of groundwaters. Such designation of zones therefore is to be used to decide upon the nature of the measures which should be taken to protect a particular groundwater in a particular area.2. The proposed groundwater action programme requests Member States to take into consideration in the planning process that urban development may impair natural replenishment of groundwaters. In order to be targeted, measures to reduce the waterproofing of the ground in suburban areas and to prevent land subsidence due to a lowering of the water table should be adopted as appropriate in response to local circumstances.3. The proposed groundwater action programme requires a sustainable use of groundwaters in order to avoid overexploitation. Controls on abstraction as well as water saving, reuse and general good house-keeping of fresh water resources are encouraged as important elements in achieving this objective. Where appropriate either transiently or permanently restrictions on abstraction could be introduced depending on the local availability and characteristics of the aquifers.4. Approximation of legislation and standards is an integral part of the process within which the Community is preparing the potential enlargement. A wide range of activities and programmes target these questions in the approximation process. Top'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(92986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check word values\n",
    "wvals = []\n",
    "for token in test1+ext1+top_list1:\n",
    "    wvals.append(word_value(token, 0.35, test+ext, top_list, wv_wiki_en))\n",
    "wvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test1:\n",
    "## original query\n",
    "original_query_cand1 = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum = probab_score_sum_weights(test1, topw_list1,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_cand1'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_cand1.append(df_wsum_original_cand1)\n",
    "\n",
    "\n",
    "## original query plus ext\n",
    "original_query_ext_cand1 = []\n",
    "for alpha in [-1,0.35,0.4,0.45,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    score_sum =probab_score_sum_weights(test1+ext1, top_list1,tokenized_docs,texts,  wv_wiki_en, alpha)\n",
    "    #original + ext gives same score, add global and state gives different score, same order\n",
    "    #how many docs have positive score?\n",
    "    sorted_positives_top = top_positives(score_sum,10)\n",
    "    #dataframe\n",
    "    df_wsum_original_ext_cand1 = pd.DataFrame(sorted_positives_top, columns =['id_wsum_original_ext_cand1'+str(alpha), 'score'+str(alpha)])\n",
    "    original_query_ext_cand1.append(df_wsum_original_ext_cand1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing sorting for each alpha\n",
    "doubleframes1 =[]\n",
    "for i in range(len(original_query_cand1)):\n",
    "    frst = original_query_cand1[i].take([0], axis=1)\n",
    "    snd = original_query_ext_cand1[i].take([0], axis=1)\n",
    "    con = pd.concat([frst,snd], axis=1)\n",
    "    doubleframes1.append(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand1-1</th>\n",
       "      <th>id_wsum_original_ext_cand1-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand1-1  id_wsum_original_ext_cand1-1\n",
       "0                     94870                         94870\n",
       "1                     11790                         92702\n",
       "2                    100258                         93604\n",
       "3                     97436                         97781\n",
       "4                     28599                         93549\n",
       "5                     92702                         14571\n",
       "6                     97265                         97436\n",
       "7                     50112                        100258\n",
       "8                     62459                         44382\n",
       "9                     49539                         98394"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubleframes1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_wsum_original_cand1-1</th>\n",
       "      <th>id_wsum_original_cand10.35</th>\n",
       "      <th>id_wsum_original_cand10.4</th>\n",
       "      <th>id_wsum_original_cand10.45</th>\n",
       "      <th>id_wsum_original_cand10.5</th>\n",
       "      <th>id_wsum_original_cand10.6</th>\n",
       "      <th>id_wsum_original_cand10.7</th>\n",
       "      <th>id_wsum_original_cand10.8</th>\n",
       "      <th>id_wsum_original_cand10.9</th>\n",
       "      <th>id_wsum_original_cand11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_wsum_original_cand1-1  id_wsum_original_cand10.35  \\\n",
       "0                     94870                       94870   \n",
       "1                     11790                       11790   \n",
       "2                    100258                      100258   \n",
       "3                     97436                       97436   \n",
       "4                     28599                       28599   \n",
       "5                     92702                       92702   \n",
       "6                     97265                       97265   \n",
       "7                     50112                       50112   \n",
       "8                     62459                       62459   \n",
       "9                     49539                       49539   \n",
       "\n",
       "   id_wsum_original_cand10.4  id_wsum_original_cand10.45  \\\n",
       "0                      94870                       94870   \n",
       "1                      11790                       11790   \n",
       "2                     100258                      100258   \n",
       "3                      97436                       97436   \n",
       "4                      28599                       28599   \n",
       "5                      92702                       92702   \n",
       "6                      97265                       97265   \n",
       "7                      50112                       50112   \n",
       "8                      62459                       62459   \n",
       "9                      49539                       49539   \n",
       "\n",
       "   id_wsum_original_cand10.5  id_wsum_original_cand10.6  \\\n",
       "0                      94870                      94870   \n",
       "1                      11790                      11790   \n",
       "2                     100258                     100258   \n",
       "3                      97436                      97436   \n",
       "4                      28599                      28599   \n",
       "5                      92702                      92702   \n",
       "6                      97265                      97265   \n",
       "7                      50112                      50112   \n",
       "8                      62459                      62459   \n",
       "9                      49539                      49539   \n",
       "\n",
       "   id_wsum_original_cand10.7  id_wsum_original_cand10.8  \\\n",
       "0                      94870                      94870   \n",
       "1                      11790                      11790   \n",
       "2                     100258                     100258   \n",
       "3                      97436                      97436   \n",
       "4                      28599                      28599   \n",
       "5                      92702                      92702   \n",
       "6                      97265                      97265   \n",
       "7                      50112                      50112   \n",
       "8                      62459                      62459   \n",
       "9                      49539                      49539   \n",
       "\n",
       "   id_wsum_original_cand10.9  id_wsum_original_cand11  \n",
       "0                      94870                    94870  \n",
       "1                      11790                    11790  \n",
       "2                     100258                   100258  \n",
       "3                      97436                    97436  \n",
       "4                      28599                    28599  \n",
       "5                      92702                    92702  \n",
       "6                      97265                    97265  \n",
       "7                      50112                    50112  \n",
       "8                      62459                    62459  \n",
       "9                      49539                    49539  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + cand\n",
    "frames =[]\n",
    "for i in range(len(original_query_cand1)):\n",
    "    dataf = original_query_cand1[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "con1 = pd.concat(frames, axis=1)\n",
    "con1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all columns the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n",
      "['earpollution', 'pollution', 'pollutants', 'biopollution', 'potable']\n"
     ]
    }
   ],
   "source": [
    "print(test1)\n",
    "print(ext1)\n",
    "print(top_list1)\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91997E3072WRITTEN QUESTION No. 3072/97 by Amedeo AMADEO to the Commission. Environmental agreementsOfficial Journal C 117 , 16/04/1998 P. 0146 WRITTEN QUESTION E-3072/97 by Amedeo Amadeo (NI) to the Commission (2 October 1997)Subject: Environmental agreementsThe main objective of the Commissions communication on environmental agreements (COM(96) 561 final) is to promote and facilitate the use of effective and acceptable environmental agreements. These agreements are instruments for the integration or implementation of environment law in the Community. The communication should be seen in the light of the strategy outlined in the fifth action programme to extend the range of environment policy instruments and put into practice the concept of shared responsibility.The communication also seeks to clarify certain aspects of how environmental agreements can be used to implement certain provisions of Community directives in the Member States and how environmental agreements can be used at Community level.Does the Commission recommendation on environmental agreements refer only to their transposal into national law or does it also cover the application of the provisions once transposed?Answer given by Mrs Bjerregaard on behalf of the Commission (31 October 1997)The Commission Recommendation concerning environmental agreements implementing Community directives ((OJ L 333, 21.12.1996. )) not only concerns the transposition of certain provisions of directives into national law but also the implementation of the transposed law. The word implementation includes both the transposition into national law and the application of the transposed provisions. Clearly, where national legislation is in place to ensure compliance with a directive, the form of implementing these rules is less important. Nevertheless, the Commission considers the legal status of agreements as an important element of their success and therefore recommends that they be concluded in a legally-binding form. Top'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(93604)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original</th>\n",
       "      <th>id_sum_original_cand</th>\n",
       "      <th>id_sum_original_ext</th>\n",
       "      <th>id_sum_original_ext_cand</th>\n",
       "      <th>id_wsum_original_cand0.4</th>\n",
       "      <th>id_wsum_original_ext_cand0.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>92986</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>12744</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>92988</td>\n",
       "      <td>37122</td>\n",
       "      <td>32476</td>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>9649</td>\n",
       "      <td>34869</td>\n",
       "      <td>97319</td>\n",
       "      <td>94936</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30565</td>\n",
       "      <td>93921</td>\n",
       "      <td>30565</td>\n",
       "      <td>33546</td>\n",
       "      <td>97319</td>\n",
       "      <td>33546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36068</td>\n",
       "      <td>32476</td>\n",
       "      <td>36068</td>\n",
       "      <td>95196</td>\n",
       "      <td>92986</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3867</td>\n",
       "      <td>62937</td>\n",
       "      <td>3867</td>\n",
       "      <td>37122</td>\n",
       "      <td>33546</td>\n",
       "      <td>37122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95196</td>\n",
       "      <td>94936</td>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "      <td>95196</td>\n",
       "      <td>34869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94467</td>\n",
       "      <td>97319</td>\n",
       "      <td>94467</td>\n",
       "      <td>30565</td>\n",
       "      <td>9649</td>\n",
       "      <td>30565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38921</td>\n",
       "      <td>95196</td>\n",
       "      <td>38921</td>\n",
       "      <td>36068</td>\n",
       "      <td>37122</td>\n",
       "      <td>36068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original  id_sum_original_cand  id_sum_original_ext  \\\n",
       "0            32476                 12744                32476   \n",
       "1            33546                 92986                33546   \n",
       "2            37122                 92988                37122   \n",
       "3            34869                  9649                34869   \n",
       "4            30565                 93921                30565   \n",
       "5            36068                 32476                36068   \n",
       "6             3867                 62937                 3867   \n",
       "7            95196                 94936                95196   \n",
       "8            94467                 97319                94467   \n",
       "9            38921                 95196                38921   \n",
       "\n",
       "   id_sum_original_ext_cand  id_wsum_original_cand0.4  \\\n",
       "0                     94936                     32476   \n",
       "1                      3453                     12744   \n",
       "2                     32476                     92988   \n",
       "3                     97319                     94936   \n",
       "4                     33546                     97319   \n",
       "5                     95196                     92986   \n",
       "6                     37122                     33546   \n",
       "7                     34869                     95196   \n",
       "8                     30565                      9649   \n",
       "9                     36068                     37122   \n",
       "\n",
       "   id_wsum_original_ext_cand0.4  \n",
       "0                         94936  \n",
       "1                         32476  \n",
       "2                          3453  \n",
       "3                         97319  \n",
       "4                         33546  \n",
       "5                         95196  \n",
       "6                         37122  \n",
       "7                         34869  \n",
       "8                         30565  \n",
       "9                         36068  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of summation method versions on test set\n",
    "frms = [df_sum_original[\"id_sum_original\"], df_sum_original_cand[\"id_sum_original_cand\"], df_sum_original_ext['id_sum_original_ext'],df_sum_original_ext_cand['id_sum_original_ext_cand'],doubleframes[2]]\n",
    "sum_result = pd.concat(frms, axis=1)\n",
    "sum_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 6, 95196: 6, 33546: 5, 37122: 5, 94936: 4, 34869: 4, 97319: 4, 30565: 4, 36068: 4, 12744: 2, 92986: 2, 3453: 2, 92988: 2, 9649: 2, 3867: 2, 94467: 2, 38921: 2, 93921: 1, 62937: 1})\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "values = sum_result.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter=collections.Counter(flat_vals)\n",
    "print((counter))\n",
    "print(len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- same results for sum original and sum original_ext\n",
    "- slight diff. between original ext cand and original ext cand wsum  \n",
    "- ..\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sum_original1</th>\n",
       "      <th>id_sum_original_cand1</th>\n",
       "      <th>id_sum_original_ext1</th>\n",
       "      <th>id_sum_original_ext_cand1</th>\n",
       "      <th>id_wsum_original_cand10.4</th>\n",
       "      <th>id_wsum_original_ext_cand10.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>11790</td>\n",
       "      <td>92702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>100258</td>\n",
       "      <td>93604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>97436</td>\n",
       "      <td>97781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>28599</td>\n",
       "      <td>93549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>92702</td>\n",
       "      <td>14571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>97265</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50112</td>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>50112</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62459</td>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "      <td>44382</td>\n",
       "      <td>62459</td>\n",
       "      <td>44382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49539</td>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "      <td>98394</td>\n",
       "      <td>49539</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sum_original1  id_sum_original_cand1  id_sum_original_ext1  \\\n",
       "0             94870                  94870                 94870   \n",
       "1             11790                  11790                 92702   \n",
       "2            100258                 100258                 93604   \n",
       "3             97436                  97436                 97781   \n",
       "4             28599                  28599                 93549   \n",
       "5             92702                  92702                 14571   \n",
       "6             97265                  97265                 97436   \n",
       "7             50112                  50112                100258   \n",
       "8             62459                  62459                 44382   \n",
       "9             49539                  49539                 98394   \n",
       "\n",
       "   id_sum_original_ext_cand1  id_wsum_original_cand10.4  \\\n",
       "0                      94870                      94870   \n",
       "1                      92702                      11790   \n",
       "2                      93604                     100258   \n",
       "3                      97781                      97436   \n",
       "4                      93549                      28599   \n",
       "5                      14571                      92702   \n",
       "6                      97436                      97265   \n",
       "7                     100258                      50112   \n",
       "8                      44382                      62459   \n",
       "9                      98394                      49539   \n",
       "\n",
       "   id_wsum_original_ext_cand10.4  \n",
       "0                          94870  \n",
       "1                          92702  \n",
       "2                          93604  \n",
       "3                          97781  \n",
       "4                          93549  \n",
       "5                          14571  \n",
       "6                          97436  \n",
       "7                         100258  \n",
       "8                          44382  \n",
       "9                          98394  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison of summation method versions on test1 set\n",
    "frames = [df_sum_original1[\"id_sum_original1\"], df_sum_original_cand1[\"id_sum_original_cand1\"], df_sum_original_ext1['id_sum_original_ext1'],df_sum_original_ext_cand1['id_sum_original_ext_cand1'],doubleframes1[2]]\n",
    "sum_result1 = pd.concat(frames, axis=1)\n",
    "sum_result1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1st place the same\n",
    "- sum original, sum original cand, wsum original cand same\n",
    "- sum original ext, sum original ext cand, wsum original ext  cand the same\n",
    "  --> having ext or not gives different results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94870: 6, 92702: 6, 100258: 6, 97436: 6, 11790: 3, 93604: 3, 97781: 3, 28599: 3, 93549: 3, 14571: 3, 97265: 3, 50112: 3, 62459: 3, 44382: 3, 49539: 3, 98394: 3})\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "values = sum_result1.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "counter1=collections.Counter(flat_vals)\n",
    "print((counter1))\n",
    "print(len(counter1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4 values appear in all columns, rest of the values appear in half columns (ext/not ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first 5 returned docs no difference between weighted and unweighted for alpha = 0.6,  alpha = 0.8, 1 #if all weight the same is same as\n",
    "# if expansion would not exist\n",
    "# only tokens / tokens + ext\n",
    "# [(99, 0.048582995951417005), (380, 0.046610169491525424), (244, 0.04477611940298507), (89, 0.04371584699453552), (376, 0.04034065441506051)]\n",
    "# [(244, 0.08955223880597014), (243, 0.08), (903, 0.04964539007092198), (99, 0.048582995951417005), (380, 0.046610169491525424)]\n",
    "# unweighted with candidate exp:\n",
    "# [(565, 0.048730964467005075), (1219, 0.0461864406779661), (12, 0.04042348411934552), (226, 0.039756782039289056), (22, 0.03749147920927062)]\n",
    "# [(565, 0.05177664974619289), (1219, 0.04745762711864407), (12, 0.04138594802694899), (226, 0.04069223573433115), (22, 0.03953646898432175)]\n",
    "# [(99, 0.048582995951417005), (380, 0.046610169491525424), (244, 0.04477611940298507), (89, 0.04371584699453552), (376, 0.04034065441506051)]\n",
    "# [(244, 0.08955223880597014), (243, 0.08), (903, 0.04964539007092198), (99, 0.048582995951417005), (380, 0.046610169491525424)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 10\n",
    "# alpha 0.8, 1\n",
    "# [(161, 0.027947874459039665), (313, 0.027129979796553974), (73, 0.025445292620865142), (402, 0.022429906542056073)]\n",
    "# [(161, 0.027915369391449767), (313, 0.02712754175646111), (73, 0.025570205421714953), (402, 0.022429906542056073)]\n",
    "# [(243, 0.032), (925, 0.031578947368421054), (1212, 0.03118536197295147), (910, 0.031168831168831172), (108, 0.03114754098360656)]\n",
    "# [(1212, 0.036276849642004776), (89, 0.034972677595628415), (376, 0.032989690721649485), (925, 0.031578947368421054), (910, 0.031168831168831172)]\n",
    "# for alpha 0.6 one change in one case\n",
    "# only tokens/tokens+ext\n",
    "# [(243, 0.04), (925, 0.039473684210526314), (1212, 0.03898170246618934), (910, 0.03896103896103896), (108, 0.0389344262295082)]\n",
    "# [(1212, 0.045346062052505964), (89, 0.04371584699453552), (376, 0.041237113402061855), (925, 0.039473684210526314), (910, 0.03896103896103896)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 2.TFIDF evaluation\n",
    "# texts_keys = []\n",
    "# texts_values = []\n",
    "# for key in sorted(texts.keys()) :\n",
    "#     texts_keys.append(key)\n",
    "#     texts_values.append(texts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "# vectors_t = vectorizer.fit_transform(texts_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first vector out (for the first document)\n",
    "# vector_t = vectors_t[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # place tf-idf values in a pandas data frame\n",
    "# vector_dframe_t = pd.DataFrame(vector_t.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "# vector_dframe_t = vector_dframe_t.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dframe_t.head(50) #treaty ne sesteje lepo, lahko bi text olepsal preden gre v vectorizer, a pojavitev pomeni istost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to solve with transformation into string of tokenized text:\n",
    "# strings_keys = []\n",
    "# strings = []\n",
    "# for key in sorted(tokenized_docs.keys()) :\n",
    "#     strings_keys.append(key)\n",
    "#     list_tokens = tokenized_docs[key]\n",
    "#     corrected = \" \".join(list_tokens)\n",
    "#     strings.append(corrected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = vectorizer.fit_transform(strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the first vector out (for the first document)\n",
    "# vector = vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # place tf-idf values in a pandas data frame\n",
    "# vector_dframe = pd.DataFrame(vector.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "# vector_dframe = vector_dframe.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_dframe.head(50) #not much difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tfidf only for query words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_docs_tokens_appear(tokensI,tokenized_docsI,textsI):\n",
    "    '''For each token in tokensI counts the number of documents the token has appeared'''\n",
    "    docs_per_token = []\n",
    "    for i in range(len(tokensI)):\n",
    "        docs_per_token.append(0)\n",
    "    for k, v in tokenized_docsI.items():\n",
    "        content = tokenized_docsI.get(k)\n",
    "        text = textsI.get(k)\n",
    "        for i in range(len(tokensI)):\n",
    "            token = tokensI[i]\n",
    "            if token in text:\n",
    "                docs_per_token[i] = docs_per_token[i]+1\n",
    "    return docs_per_token\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_sum(tokensI,tokenized_docsI, textsI):\n",
    "    '''First tuple argument similar to probab_score_sum function but different metric - tfidf, second returns words that did not occure in any document'''\n",
    "    nb_docs_tokens_appeared = nb_docs_tokens_appear(tokensI,tokenized_docsI,textsI)\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokensI[i])\n",
    "        else:\n",
    "            appear.append(tokensI[i])    \n",
    "    l = len(tokenized_docsI)\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docsI.items():\n",
    "        n = len(v)\n",
    "        text = textsI.get(k)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = text.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            probability = probability+((token_frequency/n)*idf)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab, not_appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>0.197593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>0.189548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>0.180744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>0.178706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>0.178279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30565</td>\n",
       "      <td>0.174945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36068</td>\n",
       "      <td>0.174911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3867</td>\n",
       "      <td>0.174496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63388</td>\n",
       "      <td>0.167434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94467</td>\n",
       "      <td>0.166841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original     score\n",
       "0                  32476  0.197593\n",
       "1                  33546  0.189548\n",
       "2                  37122  0.180744\n",
       "3                  34869  0.178706\n",
       "4                  95196  0.178279\n",
       "5                  30565  0.174945\n",
       "6                  36068  0.174911\n",
       "7                   3867  0.174496\n",
       "8                  63388  0.167434\n",
       "9                  94467  0.166841"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf metric for test set\n",
    "tf = tfidf_sum(test,tokenized_docs, texts)\n",
    "df_tfidf_sum_original = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original', 'score'])\n",
    "tf[1] #query words that did not appear in any doc\n",
    "df_tfidf_sum_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+ext,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_ext = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earpollution']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+ext+top_list,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_ext_cand = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext_cand', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_ext_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earpollution']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = tfidf_sum(test+topw_list,tokenized_docs, texts)\n",
    "df_tfidf_sum_original_cand = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_cand', 'score'])\n",
    "tf[1]\n",
    "#df_tfidf_sum_original_cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original</th>\n",
       "      <th>id_tfidf_sum_original_ext</th>\n",
       "      <th>id_tfidf_sum_original_ext_cand</th>\n",
       "      <th>id_tfidf_sum_original_cand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32476</td>\n",
       "      <td>32476</td>\n",
       "      <td>94936</td>\n",
       "      <td>92988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33546</td>\n",
       "      <td>33546</td>\n",
       "      <td>3453</td>\n",
       "      <td>12744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37122</td>\n",
       "      <td>37122</td>\n",
       "      <td>97319</td>\n",
       "      <td>92986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34869</td>\n",
       "      <td>34869</td>\n",
       "      <td>93533</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95196</td>\n",
       "      <td>95196</td>\n",
       "      <td>97320</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30565</td>\n",
       "      <td>30565</td>\n",
       "      <td>4505</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36068</td>\n",
       "      <td>36068</td>\n",
       "      <td>94953</td>\n",
       "      <td>92987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3867</td>\n",
       "      <td>3867</td>\n",
       "      <td>59175</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63388</td>\n",
       "      <td>63388</td>\n",
       "      <td>93921</td>\n",
       "      <td>47944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94467</td>\n",
       "      <td>94467</td>\n",
       "      <td>92988</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original  id_tfidf_sum_original_ext  \\\n",
       "0                  32476                      32476   \n",
       "1                  33546                      33546   \n",
       "2                  37122                      37122   \n",
       "3                  34869                      34869   \n",
       "4                  95196                      95196   \n",
       "5                  30565                      30565   \n",
       "6                  36068                      36068   \n",
       "7                   3867                       3867   \n",
       "8                  63388                      63388   \n",
       "9                  94467                      94467   \n",
       "\n",
       "   id_tfidf_sum_original_ext_cand  id_tfidf_sum_original_cand  \n",
       "0                           94936                       92988  \n",
       "1                            3453                       12744  \n",
       "2                           97319                       92986  \n",
       "3                           93533                        9649  \n",
       "4                           97320                       94936  \n",
       "5                            4505                       97319  \n",
       "6                           94953                       92987  \n",
       "7                           59175                       93921  \n",
       "8                           93921                       47944  \n",
       "9                           92988                        3453  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare results of tfidf sum for different input sets\n",
    "frames = [df_tfidf_sum_original['id_tfidf_sum_original'], df_tfidf_sum_original_ext['id_tfidf_sum_original_ext'], df_tfidf_sum_original_ext_cand['id_tfidf_sum_original_ext_cand'],df_tfidf_sum_original_cand['id_tfidf_sum_original_cand']]\n",
    "tfidf_sum_result = pd.concat(frames, axis=1)\n",
    "tfidf_sum_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tfifd sum original and tfidf sum original ext the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({32476: 2, 94936: 2, 92988: 2, 33546: 2, 3453: 2, 37122: 2, 97319: 2, 34869: 2, 95196: 2, 30565: 2, 36068: 2, 3867: 2, 93921: 2, 63388: 2, 94467: 2, 12744: 1, 92986: 1, 93533: 1, 9649: 1, 97320: 1, 4505: 1, 94953: 1, 92987: 1, 59175: 1, 47944: 1})\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#count number of appearances for each doument in upper dataframe\n",
    "values = tfidf_sum_result.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "countertf=collections.Counter(flat_vals)\n",
    "print((countertf))\n",
    "print(len(countertf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'pollution', 'underground']\n",
      "['pollutions', 'undergrounding']\n",
      "['pollution', 'pollutions', 'undergrounding', 'earpollution', 'pollution,']\n"
     ]
    }
   ],
   "source": [
    "#evaluating different merics\n",
    "print(test)\n",
    "print(ext)\n",
    "print(top_list)\n",
    "##############################################\n",
    "#SUM\n",
    "###############################################\n",
    "# 94936 light pollution -, 32476 fishing quotas o, 97319 light pollution - , 3453 marine pollution o\n",
    "# without weighted sum (below): \n",
    "# 32476 already appeared, 33546 fishing quotas o,37122 fishing quotas o,12744 groundwater protection +,92988 groundwater protection +\n",
    "# 33546 fishing quotas o, 92986 groundwater protection +\n",
    "# id_sum_original_cand best choice\n",
    "##############################################\n",
    "# TFIDF\n",
    "##########################################\n",
    "# 32476, 94936, 92988, 33546, 3453, 12744, ... \n",
    "# id_tfidf_sum_original_ext_cand -, id_tfidf_sum_original_cand +, id_tfidf_sum_original and id_tfidf_sum_original_ext o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91998E2572WRITTEN QUESTION No. 2572/98 by John McCARTIN Fishing agreement with the Comores 1994-1997Official Journal C 320 , 06/11/1999 P. 0008 WRITTEN QUESTION E-2572/98by John McCartin (PPE) to the Commission(1 September 1998)Subject: Fishing agreement with the Comores 1994-1997Can the Commission state how many fishing vessels were involved in the 1994-1997 EU fishing agreement with the Comores, what was the tonnage of these vessels and how many days they fished under the agreement? Top'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(94870)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original_cand</th>\n",
       "      <th>id_sum_original_cand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92988</td>\n",
       "      <td>12744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12744</td>\n",
       "      <td>92986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92986</td>\n",
       "      <td>92988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9649</td>\n",
       "      <td>9649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94936</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97319</td>\n",
       "      <td>32476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>92987</td>\n",
       "      <td>62937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93921</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47944</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3453</td>\n",
       "      <td>95196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original_cand  id_sum_original_cand\n",
       "0                       92988                 12744\n",
       "1                       12744                 92986\n",
       "2                       92986                 92988\n",
       "3                        9649                  9649\n",
       "4                       94936                 93921\n",
       "5                       97319                 32476\n",
       "6                       92987                 62937\n",
       "7                       93921                 94936\n",
       "8                       47944                 97319\n",
       "9                        3453                 95196"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing best sum and best tfidf metric/combination of input data\n",
    "best_test = pd.concat([tfidf_sum_result['id_tfidf_sum_original_cand'], sum_result['id_sum_original_cand']], axis=1)\n",
    "best_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({92988: 2, 12744: 2, 92986: 2, 9649: 2, 94936: 2, 93921: 2, 97319: 2, 32476: 1, 92987: 1, 62937: 1, 47944: 1, 3453: 1, 95196: 1})\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "values = best_test.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "countbestTest=collections.Counter(flat_vals)\n",
    "print((countbestTest))\n",
    "print(len(countbestTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different docs in dataframe best_test:\n",
    "# sum probab:32476 o, 62937 +, 95196 o+\n",
    "# tfidf sum :92987 +,47944 +, 3453 o,\n",
    "# tfidf better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|91998E3492WRITTEN QUESTION No. 3492/98 by Luigi MORETTI to the Commission. Pollution of surface waterOfficial Journal C 207 , 21/07/1999 P. 0077 WRITTEN QUESTION E-3492/98by Luigi Moretti (NI) to the Commission(25 November 1998)Subject: Pollution of surface waterThe drainage systems in built-up areas are often not designed to convey surface water, or water from recent rainfall, to water treatment plants. As a result, these waters flow into rivers, streams and lakes.To my knowledge there are currently no laws or provisions requiring these waters to be treated before they enter waterways.In view of the fact that surface water and water from recent rainfall are more polluted than sewage, since they contain over 2010 exhaust gases and heavy metals, can the Commission say what measures it intends to adopt in this area?Answer given by Mrs Bjerregaard on behalf of the Commission(12 January 1999)Rainwater on impermeable urban surfaces can be collected either separately from the domestic and industrial waste water of the built-up area (this is known as a separate sewer system) or in the same sewer as the waste water (a combined system). Two-thirds of urban areas have combined systems. Council Directive 91/271/EEC of 21 May 1991 concerning urban waste-water treatment(1) requires Member States to provide for the collection and treatment of the mixture of waste water and run-off rainwater in a combined sewer system. However, given that it is not possible in practice to construct collecting systems and treatment plants in a way such that all waste water can be treated during situations such as unusually heavy rainfall, the Directive lays down that Member States must decide on measures to limit pollution from storm water overflows. Such measures could be based on dilution rates or capacity in relation to dry weather flow, or could specify a certain acceptable number of overflows per year.As regards direct discharges of run-off water from separate sewer systems, the proposal for a Directive establishing a framework for Community action in the field of water policy(2), in providing that account should be taken of all major sources of pollution in each catchment area, will make it possible to regulate such discharges.(1) OJ L 135, 30.5.1991.(2) OJ C 108, 7.4.1998. Top'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(95196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['flwfishing']\n",
      "['flwfishing', 'earpollution', 'biopollution']\n",
      "['earpollution', 'biopollution']\n"
     ]
    }
   ],
   "source": [
    "# test1 set, query words that do not occure in any of documents\n",
    "tf = tfidf_sum(test1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original1', 'score'])\n",
    "tf = tfidf_sum(test1+ext1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_ext1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext1', 'score'])\n",
    "tf = tfidf_sum(test1+ext1+top_list1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_ext_cand1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_ext_cand1', 'score'])\n",
    "tf = tfidf_sum(test1+topw_list1,tokenized_docs, texts)\n",
    "print(tf[1])\n",
    "df_tfidf_sum_original_cand1 = pd.DataFrame(top_positives(tf[0],10), columns =['id_tfidf_sum_original_cand1', 'score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_sum_original1</th>\n",
       "      <th>id_tfidf_sum_original_ext1</th>\n",
       "      <th>id_tfidf_sum_original_ext_cand1</th>\n",
       "      <th>id_tfidf_sum_original_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94870</td>\n",
       "      <td>92702</td>\n",
       "      <td>92702</td>\n",
       "      <td>94870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11790</td>\n",
       "      <td>94870</td>\n",
       "      <td>94870</td>\n",
       "      <td>11790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97436</td>\n",
       "      <td>93604</td>\n",
       "      <td>93604</td>\n",
       "      <td>97436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100258</td>\n",
       "      <td>97781</td>\n",
       "      <td>97781</td>\n",
       "      <td>100258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28599</td>\n",
       "      <td>97436</td>\n",
       "      <td>97436</td>\n",
       "      <td>38528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50112</td>\n",
       "      <td>93549</td>\n",
       "      <td>93549</td>\n",
       "      <td>28599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97265</td>\n",
       "      <td>100258</td>\n",
       "      <td>100258</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39238</td>\n",
       "      <td>14571</td>\n",
       "      <td>14571</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49539</td>\n",
       "      <td>96942</td>\n",
       "      <td>96942</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>96093</td>\n",
       "      <td>11790</td>\n",
       "      <td>11790</td>\n",
       "      <td>50112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_sum_original1  id_tfidf_sum_original_ext1  \\\n",
       "0                   94870                       92702   \n",
       "1                   11790                       94870   \n",
       "2                   97436                       93604   \n",
       "3                  100258                       97781   \n",
       "4                   28599                       97436   \n",
       "5                   50112                       93549   \n",
       "6                   97265                      100258   \n",
       "7                   39238                       14571   \n",
       "8                   49539                       96942   \n",
       "9                   96093                       11790   \n",
       "\n",
       "   id_tfidf_sum_original_ext_cand1  id_tfidf_sum_original_cand1  \n",
       "0                            92702                        94870  \n",
       "1                            94870                        11790  \n",
       "2                            93604                        97436  \n",
       "3                            97781                       100258  \n",
       "4                            97436                        38528  \n",
       "5                            93549                        28599  \n",
       "6                           100258                         3455  \n",
       "7                            14571                        94936  \n",
       "8                            96942                        97319  \n",
       "9                            11790                        50112  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_tfidf_sum_original1['id_tfidf_sum_original1'], df_tfidf_sum_original_ext1['id_tfidf_sum_original_ext1'], df_tfidf_sum_original_ext_cand1['id_tfidf_sum_original_ext_cand1'],df_tfidf_sum_original_cand1['id_tfidf_sum_original_cand1']]\n",
    "tfidf_sum_result1 = pd.concat(frames, axis=1)\n",
    "tfidf_sum_result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sum_original_ext and sum_original_ext_cand same, the other two columns same in first 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({94870: 4, 11790: 4, 97436: 4, 100258: 4, 92702: 2, 93604: 2, 97781: 2, 28599: 2, 50112: 2, 93549: 2, 14571: 2, 96942: 2, 38528: 1, 97265: 1, 3455: 1, 39238: 1, 94936: 1, 49539: 1, 97319: 1, 96093: 1})\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "values = tfidf_sum_result1.values.tolist()\n",
    "flat_vals = []\n",
    "for sublist in values:\n",
    "    for item in sublist:\n",
    "        flat_vals.append(item)\n",
    "countertf1=collections.Counter(flat_vals)\n",
    "print((countertf1))\n",
    "print(len(countertf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annex', 'fishing', 'agreement', 'europe']\n",
      "['agreements', 'flwfishing']\n",
      "['earpollution', 'pollution', 'pollutants', 'biopollution', 'potable']\n"
     ]
    }
   ],
   "source": [
    "# comparing results for test1 set\n",
    "print(test1)\n",
    "print(ext1)\n",
    "print(top_list1)\n",
    "############\n",
    "#SUM\n",
    "############################################################\n",
    "#94870 fishing agreement EU +, 11790 fishing agreement EU +, 100258 fishing agreement +\n",
    "#94870 11790, 100258 already, 92702 fishing agreement +, 93604 environmental agreement o ;better without extention\n",
    "############################################################\n",
    "# TFIDF\n",
    "#94870, 92702, 11790, 94870,97436 overfishing, 93604\n",
    "# better without ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avis juridique important|92000E3661WRITTEN QUESTION E-3661/00 by Glenys Kinnock (PSE) to the Commission. Coastal fishing in ACP countries.Official Journal 174 E , 19/06/2001 P. 0104 - 0105 WRITTEN QUESTION E-3661/00by Glenys Kinnock (PSE) to the Commission(27 November 2000)Subject: Coastal fishing in ACP countriesWould the Commission outline what measures it is taking to ensure that Community fishing vessels, operating under EU-ACP fishing agreements, respect the needs and rights of small-scale, coastal fishing communities in ACP countries and do not damage the local ACP fisheries sector?What action is the Commission taking to improve the capacity of ACP countries to patrol the waters under their jurisdiction, so as to control the activities of both Community and ACP fishing fleets and thereby prevent overfishing?Answer given by Mr Fischler on behalf of the Commission(5 January 2001)The Commission thanks the Honourable Member for her question and informs her that, in order to avoid clashes with small-scale traditional fishermen, protocols to fisheries agreements specify fishing zones for the Community which differ from those for local vessels.As for improving the capacity of African, Caribbean and Pacific (ACP) countries to control fishing activities, the Commission is pleased to inform the Honourable Member that, since 1997 the majority of fisheries agreements concluded between the Community and third countries (namely ACP countries) stipulate that an important part of the financial compensation paid in exchange for fishing possibilities be devoted to targeted actions, amongst which are monitoring, control and surveillance activities, including the setting up of satellite based vessel monitoring systems. Top'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.get(97436)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_sum_weights(original_tokens, top_expansion,tokenized_docs,texts, wv, alpha): \n",
    "    tokens_together = original_tokens+top_expansion\n",
    "    nb_docs_tokens_appeared = nb_docs_tokens_appear(tokens_together,tokenized_docs,texts)\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokens_together[i])\n",
    "        else:\n",
    "            appear.append(tokens_together[i])  \n",
    "    l = len(tokenized_docs)\n",
    "    doc_probab = {}\n",
    "    for k, v in tokenized_docs.items():\n",
    "        n = len(v)\n",
    "        text = texts.get(k)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = text.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            probability = probability+((token_frequency/n)*idf)*word_value(appear[i], alpha, original_tokens, top_expansion, wv)\n",
    "        doc_probab.update({k: probability})\n",
    "    return doc_probab,not_appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_original_query_ext_cand = []\n",
    "for alpha in [0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    tfw = tfidf_sum_weights(test+ext, top_list,tokenized_docs,texts, wv_wiki_en, alpha)\n",
    "    df_tfidf_wsum_original_ext_cand = pd.DataFrame(top_positives(tfw[0],10), columns =['id_tfidf_wsum_original_ext_cand'+str(alpha), 'score'+str(alpha)])\n",
    "    tfidf_original_query_ext_cand.append(df_tfidf_wsum_original_ext_cand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.5</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.6</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.7</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.8</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand0.9</th>\n",
       "      <th>id_tfidf_wsum_original_ext_cand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "      <td>94936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "      <td>97319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "      <td>3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "      <td>93533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "      <td>97320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4505</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "      <td>59175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59175</td>\n",
       "      <td>4505</td>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93921</td>\n",
       "      <td>93921</td>\n",
       "      <td>4505</td>\n",
       "      <td>4505</td>\n",
       "      <td>4505</td>\n",
       "      <td>4505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "      <td>94953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "      <td>62286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_tfidf_wsum_original_ext_cand0.5  id_tfidf_wsum_original_ext_cand0.6  \\\n",
       "0                               94936                               94936   \n",
       "1                               97319                               97319   \n",
       "2                                3453                                3453   \n",
       "3                               93533                               93533   \n",
       "4                               97320                               97320   \n",
       "5                                4505                               59175   \n",
       "6                               59175                                4505   \n",
       "7                               93921                               93921   \n",
       "8                               94953                               94953   \n",
       "9                               62286                               62286   \n",
       "\n",
       "   id_tfidf_wsum_original_ext_cand0.7  id_tfidf_wsum_original_ext_cand0.8  \\\n",
       "0                               94936                               94936   \n",
       "1                               97319                               97319   \n",
       "2                                3453                                3453   \n",
       "3                               93533                               93533   \n",
       "4                               97320                               97320   \n",
       "5                               59175                               59175   \n",
       "6                               93921                               93921   \n",
       "7                                4505                                4505   \n",
       "8                               94953                               94953   \n",
       "9                               62286                               62286   \n",
       "\n",
       "   id_tfidf_wsum_original_ext_cand0.9  id_tfidf_wsum_original_ext_cand1  \n",
       "0                               94936                             94936  \n",
       "1                               97319                             97319  \n",
       "2                                3453                              3453  \n",
       "3                               93533                             93533  \n",
       "4                               97320                             97320  \n",
       "5                               59175                             59175  \n",
       "6                               93921                             93921  \n",
       "7                                4505                              4505  \n",
       "8                               94953                             94953  \n",
       "9                               62286                             62286  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing sorting for different alphas, original + ext + cand\n",
    "frames =[]\n",
    "for i in range(len(tfidf_original_query_ext_cand)):\n",
    "    dataf = tfidf_original_query_ext_cand[i].take([0], axis=1)\n",
    "    frames.append(dataf)\n",
    "tfidfcon = pd.concat(frames, axis=1)\n",
    "tfidfcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########################\n",
    "# #set json format in readable form (starting wih multiple objec format, need list)\n",
    "# annotation_dir='D:/Users/sarab/work/enviroLens/files/'\n",
    "# print('Loading annotations')\n",
    "# annotations=[]\n",
    "# for filename in os.listdir(annotation_dir):\n",
    "#     print('loading file ',filename)\n",
    "#     lines = [line.rstrip('\\n') for line in open(annotation_dir+filename,encoding='utf-8')]\n",
    "#     for line in lines:\n",
    "#         js=json.loads(line)\n",
    "#         annotations.append(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
